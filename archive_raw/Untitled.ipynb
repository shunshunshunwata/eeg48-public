{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f50cdb3-ad9b-4cda-9237-2ce868d33da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded epochs: 1728\n",
      "Aligned epochs after keep: 1728\n",
      "   subject_id  run_id  trial_in_run  number\n",
      "0           1       1             1      37\n",
      "1           1       1             2      44\n",
      "2           1       1             3       7\n",
      "3           1       1             4      25\n",
      "4           1       1             5       6\n",
      "EEG ch_names: ['Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'T7', 'C3', 'Cz', 'C4', 'T8', 'P7', 'P3', 'Pz', 'P4', 'P8', 'O1', 'O2']\n",
      "After crop/baseline: -0.2 0.998 n= 1728\n",
      "NaN rate in attached labels (top):\n",
      "emo_arousal          0.0\n",
      "emo_approach         0.0\n",
      "emo_valence          0.0\n",
      "emo_arousal_high     0.0\n",
      "emo_approach_high    0.0\n",
      "emo_valence_high     0.0\n",
      "is_ambiguous         0.0\n",
      "dtype: float64\n",
      "emo_arousal_high {np.int64(0): np.int64(864), np.int64(1): np.int64(864)}\n",
      "emo_approach_high {np.int64(0): np.int64(864), np.int64(1): np.int64(864)}\n",
      "emo_valence_high {np.int64(0): np.int64(864), np.int64(1): np.int64(864)}\n",
      "is_ambiguous {np.int64(0): np.int64(1368), np.int64(1): np.int64(360)}\n",
      "Available conds: ['emo_arousal_high', 'emo_approach_high', 'emo_valence_high', 'is_ambiguous']\n",
      "ROIs used: {'frontal': ['Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8'], 'central': ['C3', 'Cz', 'C4'], 'parietal': ['P7', 'P3', 'Pz', 'P4', 'P8'], 'occipital': ['O1', 'O2']}\n",
      "Scale factor to uV: 1.0\n",
      "\n",
      "[SAVED] /Users/shunsuke/EEG_48sounds/moduleB_outputs/tables/ERP_onset_under1000ms/ERP_onset_under1000ms_perm.csv\n",
      "                 cond              contrast        roi window_ms  n_subjects  \\\n",
      "0   emo_approach_high  Approach High vs Low    central      0-80          12   \n",
      "1   emo_approach_high  Approach High vs Low    central   140-220          12   \n",
      "2   emo_approach_high  Approach High vs Low    central   220-350          12   \n",
      "3   emo_approach_high  Approach High vs Low    central   350-500          12   \n",
      "4   emo_approach_high  Approach High vs Low    central   500-800          12   \n",
      "5   emo_approach_high  Approach High vs Low    central    80-140          12   \n",
      "6   emo_approach_high  Approach High vs Low    central  800-1000          12   \n",
      "7   emo_approach_high  Approach High vs Low    frontal      0-80          12   \n",
      "8   emo_approach_high  Approach High vs Low    frontal   140-220          12   \n",
      "9   emo_approach_high  Approach High vs Low    frontal   220-350          12   \n",
      "10  emo_approach_high  Approach High vs Low    frontal   350-500          12   \n",
      "11  emo_approach_high  Approach High vs Low    frontal   500-800          12   \n",
      "12  emo_approach_high  Approach High vs Low    frontal    80-140          12   \n",
      "13  emo_approach_high  Approach High vs Low    frontal  800-1000          12   \n",
      "14  emo_approach_high  Approach High vs Low  occipital      0-80          12   \n",
      "15  emo_approach_high  Approach High vs Low  occipital   140-220          12   \n",
      "16  emo_approach_high  Approach High vs Low  occipital   220-350          12   \n",
      "17  emo_approach_high  Approach High vs Low  occipital   350-500          12   \n",
      "18  emo_approach_high  Approach High vs Low  occipital   500-800          12   \n",
      "19  emo_approach_high  Approach High vs Low  occipital    80-140          12   \n",
      "20  emo_approach_high  Approach High vs Low  occipital  800-1000          12   \n",
      "21  emo_approach_high  Approach High vs Low   parietal      0-80          12   \n",
      "22  emo_approach_high  Approach High vs Low   parietal   140-220          12   \n",
      "23  emo_approach_high  Approach High vs Low   parietal   220-350          12   \n",
      "24  emo_approach_high  Approach High vs Low   parietal   350-500          12   \n",
      "25  emo_approach_high  Approach High vs Low   parietal   500-800          12   \n",
      "26  emo_approach_high  Approach High vs Low   parietal    80-140          12   \n",
      "27  emo_approach_high  Approach High vs Low   parietal  800-1000          12   \n",
      "28   emo_arousal_high   Arousal High vs Low    central      0-80          12   \n",
      "29   emo_arousal_high   Arousal High vs Low    central   140-220          12   \n",
      "\n",
      "      hi_uV_mean    lo_uV_mean  mean_diff_uV    sd_diff_uV     T_obs  \\\n",
      "0   2.144839e-08 -2.822760e-08  4.967600e-08  2.868922e-07  0.599817   \n",
      "1   3.358174e-08 -1.252455e-07  1.588272e-07  6.368407e-07  0.863942   \n",
      "2   8.168319e-08 -2.385822e-07  3.202654e-07  9.698129e-07  1.143965   \n",
      "3   7.126526e-08 -2.324068e-07  3.036721e-07  1.189925e-06  0.884048   \n",
      "4   1.111766e-07 -2.011482e-07  3.123248e-07  1.350592e-06  0.801075   \n",
      "5   8.638419e-08  3.431103e-09  8.295309e-08  4.217150e-07  0.681403   \n",
      "6   9.505439e-08 -9.512209e-08  1.901765e-07  1.438378e-06  0.458009   \n",
      "7   9.146672e-07 -6.293313e-07  1.543999e-06  2.209380e-06  2.420846   \n",
      "8   1.659953e-06 -1.717956e-08  1.677133e-06  2.852931e-06  2.036417   \n",
      "9   1.918177e-06  1.240068e-06  6.781093e-07  3.090696e-06  0.760036   \n",
      "10  2.187695e-06  2.785987e-06 -5.982927e-07  4.481194e-06 -0.462499   \n",
      "11  1.952184e-06  5.064655e-06 -3.112471e-06  5.712591e-06 -1.887395   \n",
      "12  1.399099e-06 -6.519708e-07  2.051070e-06  2.920700e-06  2.432675   \n",
      "13  1.828768e-06  6.522987e-06 -4.694219e-06  8.292936e-06 -1.960856   \n",
      "14  2.031739e-07  6.889510e-07 -4.857771e-07  1.625672e-06 -1.035130   \n",
      "15  4.902696e-07  1.174202e-06 -6.839322e-07  2.784847e-06 -0.850751   \n",
      "16  4.701944e-07  1.688830e-06 -1.218635e-06  4.354945e-06 -0.969352   \n",
      "17  6.894020e-07  2.486510e-06 -1.797108e-06  5.621514e-06 -1.107417   \n",
      "18  8.049412e-07  3.419703e-06 -2.614762e-06  7.805735e-06 -1.160403   \n",
      "19  1.680477e-07  7.441538e-07 -5.761061e-07  2.615832e-06 -0.762927   \n",
      "20  1.121859e-06  4.803081e-06 -3.681222e-06  8.513705e-06 -1.497835   \n",
      "21 -2.803294e-07  1.246074e-07 -4.049367e-07  1.147384e-06 -1.222557   \n",
      "22 -3.940228e-07  4.891131e-07 -8.831359e-07  2.219332e-06 -1.378466   \n",
      "23 -5.778725e-07  9.763102e-07 -1.554183e-06  3.326844e-06 -1.618304   \n",
      "24 -5.713131e-07  1.739296e-06 -2.310609e-06  4.438009e-06 -1.803553   \n",
      "25 -5.416991e-07  2.769812e-06 -3.311511e-06  6.302521e-06 -1.820130   \n",
      "26 -4.854993e-07  1.263606e-07 -6.118599e-07  1.939864e-06 -1.092626   \n",
      "27 -2.613379e-09  4.032236e-06 -4.034849e-06  7.147477e-06 -1.955533   \n",
      "28 -5.330190e-08  4.652269e-08 -9.982458e-08  2.570461e-07 -1.345294   \n",
      "29 -1.508072e-07  5.914342e-08 -2.099506e-07  5.678914e-07 -1.280685   \n",
      "\n",
      "      p_perm        dz  \n",
      "0   0.550490  0.173152  \n",
      "1   0.426515  0.249399  \n",
      "2   0.306539  0.330234  \n",
      "3   0.385723  0.255203  \n",
      "4   0.422515  0.231250  \n",
      "5   0.496901  0.196704  \n",
      "6   0.672266  0.132216  \n",
      "7   0.040192  0.698838  \n",
      "8   0.067187  0.587863  \n",
      "9   0.467906  0.219403  \n",
      "10  0.649870 -0.133512  \n",
      "11  0.100580 -0.544844  \n",
      "12  0.037193  0.702253  \n",
      "13  0.083383 -0.566050  \n",
      "14  0.325535 -0.298816  \n",
      "15  0.471506 -0.245591  \n",
      "16  0.403519 -0.279828  \n",
      "17  0.303939 -0.319684  \n",
      "18  0.275745 -0.334980  \n",
      "19  0.506099 -0.220238  \n",
      "20  0.170766 -0.432388  \n",
      "21  0.262348 -0.352922  \n",
      "22  0.184163 -0.397929  \n",
      "23  0.112977 -0.467164  \n",
      "24  0.108778 -0.520641  \n",
      "25  0.107179 -0.525426  \n",
      "26  0.324735 -0.315414  \n",
      "27  0.088782 -0.564514  \n",
      "28  0.224155 -0.388353  \n",
      "29  0.222156 -0.369702  \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import math\n",
    "\n",
    "# =========================\n",
    "# PATHS（必要ならここだけ修正）\n",
    "# =========================\n",
    "ROOT = Path(\"~/EEG_48sounds\").expanduser()\n",
    "EPOCHS_PATH   = ROOT / \"derivatives/epochs_all/epochs_all-epo.fif\"\n",
    "TRIAL_FEAT    = ROOT / \"moduleB_outputs/tables/moduleB_trial_eeg_features.csv\"\n",
    "MASTER_PC     = ROOT / \"derivatives/master_tables/master_sound_level_with_PC.csv\"   # ←あなたの実パスに合わせる\n",
    "OUT_DIR       = ROOT / \"moduleB_outputs/tables/ERP_onset_under1000ms\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# util\n",
    "# =========================\n",
    "def _to_int_like(s: pd.Series) -> pd.Series:\n",
    "    x = pd.to_numeric(s, errors=\"coerce\")\n",
    "    if x.isna().mean() > 0.5:\n",
    "        x = pd.to_numeric(s.astype(str).str.extract(r\"(\\d+)\")[0], errors=\"coerce\")\n",
    "    return x.astype(\"Int64\")\n",
    "\n",
    "def ensure_key(df: pd.DataFrame, dst: str, cands: list) -> pd.DataFrame:\n",
    "    if dst in df.columns:\n",
    "        df[dst] = _to_int_like(df[dst])\n",
    "        return df\n",
    "    for c in cands:\n",
    "        if c in df.columns:\n",
    "            df[dst] = _to_int_like(df[c])\n",
    "            return df\n",
    "    raise RuntimeError(f\"'{dst}' を作れません。候補 {cands} がありません: cols={list(df.columns)}\")\n",
    "\n",
    "def add_highlow(df):\n",
    "    \"\"\"emo_* があれば median split を作る（*_high を生成）\"\"\"\n",
    "    df = df.copy()\n",
    "    for col in [\"emo_arousal\",\"emo_approach\",\"emo_valence\"]:\n",
    "        if col in df.columns:\n",
    "            v = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "            med = float(v.median())\n",
    "            df[f\"{col}_high\"] = (v >= med).astype(int)\n",
    "    return df\n",
    "\n",
    "def add_is_ambiguous(df):\n",
    "    \"\"\"is_ambiguous が無ければ、候補列から作る（無ければ0で埋める）\"\"\"\n",
    "    df = df.copy()\n",
    "    if \"is_ambiguous\" in df.columns:\n",
    "        df[\"is_ambiguous\"] = pd.to_numeric(df[\"is_ambiguous\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "        return df\n",
    "\n",
    "    cand = None\n",
    "    for c in [\"is_ambiguous_approach_sd_top10\",\"ambiguous\",\"is_ambiguous_flag\",\"is_ambiguous_top10\"]:\n",
    "        if c in df.columns:\n",
    "            cand = c\n",
    "            break\n",
    "    if cand is None:\n",
    "        df[\"is_ambiguous\"] = 0\n",
    "    else:\n",
    "        x = df[cand]\n",
    "        if x.dtype == bool:\n",
    "            df[\"is_ambiguous\"] = x.astype(int)\n",
    "        else:\n",
    "            df[\"is_ambiguous\"] = pd.to_numeric(x, errors=\"coerce\").fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "# =========================\n",
    "# 1) Load epochs (preload必須)\n",
    "# =========================\n",
    "epochs = mne.read_epochs(EPOCHS_PATH, preload=True, verbose=\"ERROR\")\n",
    "print(\"Loaded epochs:\", len(epochs))\n",
    "if epochs.metadata is None:\n",
    "    raise RuntimeError(\"epochs.metadata が None です。\")\n",
    "\n",
    "meta = epochs.metadata.reset_index(drop=True).copy()\n",
    "\n",
    "# metadata列名の揺れ対応：subject_id/run_id を作る\n",
    "meta = ensure_key(meta, \"subject_id\", [\"subject_id\",\"participant\",\"subject\",\"sub\",\"sub_id\",\"participant_id\"])\n",
    "meta = ensure_key(meta, \"run_id\", [\"run_id\",\"run\",\"block\",\"session\"])\n",
    "meta = ensure_key(meta, \"trial_in_run\", [\"trial_in_run\",\"trial\",\"trial_index\",\"trial_num\"])\n",
    "meta = ensure_key(meta, \"number\", [\"number\",\"sound_id\",\"stim_id\",\"stimulus_id\"])\n",
    "epochs.metadata = meta\n",
    "\n",
    "# =========================\n",
    "# 2) keep（ModuleB基準）で整列\n",
    "# =========================\n",
    "df_feat = pd.read_csv(TRIAL_FEAT)\n",
    "df_feat = ensure_key(df_feat, \"subject_id\", [\"subject_id\",\"participant\",\"subject\"])\n",
    "df_feat = ensure_key(df_feat, \"run_id\", [\"run_id\",\"run\"])\n",
    "df_feat = ensure_key(df_feat, \"trial_in_run\", [\"trial_in_run\",\"trial\"])\n",
    "\n",
    "keys3 = [\"subject_id\",\"run_id\",\"trial_in_run\"]\n",
    "keep = df_feat[keys3].drop_duplicates().copy()\n",
    "keep[\"_keep\"] = True\n",
    "\n",
    "meta2 = epochs.metadata.merge(keep, on=keys3, how=\"left\")\n",
    "keep_mask = meta2[\"_keep\"].fillna(False).to_numpy(dtype=bool)\n",
    "\n",
    "epochs = epochs[keep_mask]\n",
    "meta2 = meta2.loc[keep_mask].reset_index(drop=True)\n",
    "epochs.metadata = meta2.drop(columns=[\"_keep\"], errors=\"ignore\")\n",
    "\n",
    "print(\"Aligned epochs after keep:\", len(epochs))\n",
    "print(epochs.metadata[keys3 + [\"number\"]].head())\n",
    "\n",
    "# =========================\n",
    "# 3) 19ch 正規化\n",
    "# =========================\n",
    "CANON_19 = [\"Fp1\",\"Fp2\",\"F7\",\"F3\",\"Fz\",\"F4\",\"F8\",\"T7\",\"C3\",\"Cz\",\"C4\",\"T8\",\"P7\",\"P3\",\"Pz\",\"P4\",\"P8\",\"O1\",\"O2\"]\n",
    "\n",
    "def _norm_ch(name: str) -> str:\n",
    "    s = name.upper().replace(\"EEG\",\"\").replace(\" \",\"\")\n",
    "    s = s.replace(\"-REF\",\"\").replace(\"REF\",\"\")\n",
    "    s = s.replace(\"-\", \"\")\n",
    "    s = s.replace(\"A1\",\"\").replace(\"A2\",\"\").replace(\"M1\",\"\").replace(\"M2\",\"\")\n",
    "    s = s.replace(\"T3\",\"T7\").replace(\"T4\",\"T8\").replace(\"T5\",\"P7\").replace(\"T6\",\"P8\")\n",
    "    return s\n",
    "\n",
    "def pick_and_rename_19ch(ep: mne.Epochs) -> mne.Epochs:\n",
    "    ep = ep.copy().pick_types(eeg=True, eog=False, stim=False, misc=False)\n",
    "    cur = list(ep.ch_names)\n",
    "    norm_map = {_norm_ch(c): c for c in cur}\n",
    "\n",
    "    rename = {}\n",
    "    keep_ch = []\n",
    "    for canon in CANON_19:\n",
    "        key = canon.upper()\n",
    "        if key in norm_map:\n",
    "            orig = norm_map[key]\n",
    "            rename[orig] = canon\n",
    "            keep_ch.append(orig)\n",
    "\n",
    "    if not keep_ch:\n",
    "        raise RuntimeError(f\"[channels] 19ch が1つも一致しません: {cur}\")\n",
    "\n",
    "    ep = ep.copy().pick_channels(keep_ch, ordered=True)\n",
    "    ep.rename_channels(rename)\n",
    "    ordered = [c for c in CANON_19 if c in ep.ch_names]\n",
    "    ep = ep.copy().reorder_channels(ordered)\n",
    "    return ep\n",
    "\n",
    "epochs = pick_and_rename_19ch(epochs)\n",
    "print(\"EEG ch_names:\", epochs.ch_names)\n",
    "\n",
    "# =========================\n",
    "# 4) Crop + baseline（<1000ms）\n",
    "# =========================\n",
    "epochs = epochs.copy().crop(tmin=-0.2, tmax=1.0, include_tmax=False)\n",
    "epochs = epochs.copy().apply_baseline((-0.2, 0.0))\n",
    "print(\"After crop/baseline:\", epochs.tmin, epochs.tmax, \"n=\", len(epochs))\n",
    "\n",
    "# =========================\n",
    "# 5) ★ここが今回の追加：master_sound を number で付与\n",
    "# =========================\n",
    "ms = pd.read_csv(MASTER_PC)\n",
    "\n",
    "# master_soundの number 列を作る\n",
    "ms = ensure_key(ms, \"number\", [\"number\",\"sound_id\",\"SoundID\",\"stim_id\",\"stimulus_id\",\"sound\"])\n",
    "ms[\"number\"] = _to_int_like(ms[\"number\"])\n",
    "\n",
    "# emo_* が無い場合の候補（あなたの列名が違う可能性に備える）\n",
    "# もし列名が一致しているなら何もしない\n",
    "rename_map = {}\n",
    "for dst, cands in {\n",
    "    \"emo_arousal\":  [\"emo_arousal\",\"arousal\",\"Arousal\",\"PC_arousal\",\"arousal_score\"],\n",
    "    \"emo_approach\":[\"emo_approach\",\"approach\",\"Approach\",\"PC_approach\",\"approach_score\"],\n",
    "    \"emo_valence\": [\"emo_valence\",\"valence\",\"Valence\",\"PC_valence\",\"valence_score\"],\n",
    "}.items():\n",
    "    if dst not in ms.columns:\n",
    "        for c in cands:\n",
    "            if c in ms.columns:\n",
    "                rename_map[c] = dst\n",
    "                break\n",
    "if rename_map:\n",
    "    ms = ms.rename(columns=rename_map)\n",
    "\n",
    "ms = add_highlow(ms)\n",
    "ms = add_is_ambiguous(ms)\n",
    "\n",
    "label_cols = [c for c in [\n",
    "    \"emo_arousal\",\"emo_approach\",\"emo_valence\",\n",
    "    \"emo_arousal_high\",\"emo_approach_high\",\"emo_valence_high\",\n",
    "    \"is_ambiguous\"\n",
    "] if c in ms.columns]\n",
    "\n",
    "if len(label_cols) == 0:\n",
    "    raise RuntimeError(f\"master_sound にラベル列が見つかりません: cols={list(ms.columns)}\")\n",
    "\n",
    "# epochs.metadata に付与\n",
    "meta3 = epochs.metadata.merge(ms[[\"number\"] + label_cols].drop_duplicates(\"number\"), on=\"number\", how=\"left\")\n",
    "\n",
    "# NaNチェック（ここでNaNが多いなら、numberの定義が違う）\n",
    "nan_rate = meta3[label_cols].isna().mean().sort_values(ascending=False)\n",
    "print(\"NaN rate in attached labels (top):\")\n",
    "print(nan_rate.head(10))\n",
    "\n",
    "epochs.metadata = meta3\n",
    "\n",
    "# *_high / is_ambiguous を int化\n",
    "for c in [\"emo_arousal_high\",\"emo_approach_high\",\"emo_valence_high\",\"is_ambiguous\"]:\n",
    "    if c in epochs.metadata.columns:\n",
    "        epochs.metadata[c] = pd.to_numeric(epochs.metadata[c], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# 条件一覧\n",
    "cond_specs = [\n",
    "    (\"emo_arousal_high\", 1, 0, \"Arousal High vs Low\"),\n",
    "    (\"emo_approach_high\", 1, 0, \"Approach High vs Low\"),\n",
    "    (\"emo_valence_high\", 1, 0, \"Valence High vs Low\"),\n",
    "    (\"is_ambiguous\", 1, 0, \"Ambiguous vs Non-ambiguous\"),\n",
    "]\n",
    "available = []\n",
    "for col, hi, lo, label in cond_specs:\n",
    "    if col in epochs.metadata.columns:\n",
    "        vc = epochs.metadata[col].value_counts(dropna=False)\n",
    "        print(col, dict(vc))\n",
    "        # 0/1両方あるときだけ採用\n",
    "        u = set(epochs.metadata[col].dropna().astype(int).unique().tolist())\n",
    "        if hi in u and lo in u:\n",
    "            available.append((col, hi, lo, label))\n",
    "\n",
    "print(\"Available conds:\", [a[0] for a in available])\n",
    "if len(available) == 0:\n",
    "    raise RuntimeError(\"High/Low比較が成立する条件がありません（0/1の片方しか無い可能性）。\")\n",
    "\n",
    "# =========================\n",
    "# 6) ROI\n",
    "# =========================\n",
    "ROI_DEF = {\n",
    "    \"frontal\":  [\"Fp1\",\"Fp2\",\"F7\",\"F3\",\"Fz\",\"F4\",\"F8\"],\n",
    "    \"central\":  [\"C3\",\"Cz\",\"C4\"],\n",
    "    \"parietal\": [\"P7\",\"P3\",\"Pz\",\"P4\",\"P8\"],\n",
    "    \"occipital\":[\"O1\",\"O2\"],\n",
    "}\n",
    "rois = {roi: [ch for ch in chs if ch in epochs.ch_names] for roi, chs in ROI_DEF.items()}\n",
    "rois = {roi: chs for roi, chs in rois.items() if len(chs) > 0}\n",
    "print(\"ROIs used:\", rois)\n",
    "\n",
    "# =========================\n",
    "# 7) windows (<1000ms)\n",
    "# =========================\n",
    "windows_ms = [(0,80),(80,140),(140,220),(220,350),(350,500),(500,800),(800,1000)]\n",
    "\n",
    "# =========================\n",
    "# 8) 平均振幅（被験者内差）→ sign-flip permutation\n",
    "# =========================\n",
    "def mean_amp_by_mask(ep: mne.Epochs, mask: np.ndarray, chs: list, t0_ms: int, t1_ms: int) -> float:\n",
    "    if mask.sum() == 0:\n",
    "        return np.nan\n",
    "    e2 = ep[mask].copy().pick_channels(chs)\n",
    "    data = e2.get_data()              # (n, ch, t) in V usually\n",
    "    roi = data.mean(axis=1)           # (n, t)\n",
    "    times_ms = e2.times * 1000.0\n",
    "    tm = (times_ms >= t0_ms) & (times_ms < t1_ms)\n",
    "    if not tm.any():\n",
    "        return np.nan\n",
    "    return float(roi[:, tm].mean())\n",
    "\n",
    "sample = epochs.get_data(picks=[epochs.ch_names[0]]).ravel()\n",
    "scale_to_uV = 1e6 if np.nanmax(np.abs(sample)) < 1e-3 else 1.0\n",
    "print(\"Scale factor to uV:\", scale_to_uV)\n",
    "\n",
    "def signflip_perm_test(diff: np.ndarray, n_perm: int = 5000, seed: int = 2026):\n",
    "    diff = np.asarray(diff, dtype=float)\n",
    "    diff = diff[np.isfinite(diff)]\n",
    "    n = len(diff)\n",
    "    if n < 2:\n",
    "        return np.nan, np.nan, np.nan, n\n",
    "    sd = diff.std(ddof=1)\n",
    "    if sd == 0:\n",
    "        return np.nan, np.nan, np.nan, n\n",
    "\n",
    "    obs_mean = diff.mean()\n",
    "    obs_t = obs_mean / (sd / math.sqrt(n))\n",
    "    dz = obs_mean / sd\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    cnt = 0\n",
    "    for _ in range(n_perm):\n",
    "        signs = rng.choice([-1.0, 1.0], size=n)\n",
    "        d = diff * signs\n",
    "        s = d.std(ddof=1)\n",
    "        if s == 0:\n",
    "            continue\n",
    "        t = d.mean() / (s / math.sqrt(n))\n",
    "        if abs(t) >= abs(obs_t):\n",
    "            cnt += 1\n",
    "    p = (cnt + 1) / (n_perm + 1)\n",
    "    return float(obs_t), float(p), float(dz), int(n)\n",
    "\n",
    "rows = []\n",
    "subs = np.sort(epochs.metadata[\"subject_id\"].dropna().astype(int).unique())\n",
    "\n",
    "for cond_col, hi_val, lo_val, cond_label in available:\n",
    "    valid = epochs.metadata[cond_col].notna().to_numpy()\n",
    "    epc = epochs[valid]\n",
    "    mdc = epc.metadata.reset_index(drop=True)\n",
    "\n",
    "    for roi, chs in rois.items():\n",
    "        for (t0, t1) in windows_ms:\n",
    "            diffs, his, los = [], [], []\n",
    "\n",
    "            for sid in subs:\n",
    "                sid_mask = (mdc[\"subject_id\"].astype(int).to_numpy() == int(sid))\n",
    "                if sid_mask.sum() == 0:\n",
    "                    continue\n",
    "\n",
    "                y = mdc.loc[sid_mask, cond_col].astype(int).to_numpy()\n",
    "                idx = np.where(sid_mask)[0]\n",
    "\n",
    "                hi_mask = np.zeros(len(mdc), dtype=bool)\n",
    "                lo_mask = np.zeros(len(mdc), dtype=bool)\n",
    "                hi_mask[idx[y == hi_val]] = True\n",
    "                lo_mask[idx[y == lo_val]] = True\n",
    "\n",
    "                hi_uV = mean_amp_by_mask(epc, hi_mask, chs, t0, t1)\n",
    "                lo_uV = mean_amp_by_mask(epc, lo_mask, chs, t0, t1)\n",
    "\n",
    "                if np.isfinite(hi_uV) and np.isfinite(lo_uV):\n",
    "                    hi_uV *= scale_to_uV\n",
    "                    lo_uV *= scale_to_uV\n",
    "                    diffs.append(hi_uV - lo_uV)\n",
    "                    his.append(hi_uV)\n",
    "                    los.append(lo_uV)\n",
    "\n",
    "            if len(diffs) == 0:\n",
    "                continue\n",
    "\n",
    "            diff = np.array(diffs, dtype=float)\n",
    "            t_obs, p_perm, dz, n_sub = signflip_perm_test(diff, n_perm=5000, seed=2026)\n",
    "\n",
    "            rows.append({\n",
    "                \"cond\": cond_col,\n",
    "                \"contrast\": cond_label,\n",
    "                \"roi\": roi,\n",
    "                \"window_ms\": f\"{t0}-{t1}\",\n",
    "                \"n_subjects\": n_sub,\n",
    "                \"hi_uV_mean\": float(np.nanmean(his)),\n",
    "                \"lo_uV_mean\": float(np.nanmean(los)),\n",
    "                \"mean_diff_uV\": float(np.nanmean(diff)),\n",
    "                \"sd_diff_uV\": float(np.nanstd(diff, ddof=1)) if len(diff) > 1 else np.nan,\n",
    "                \"T_obs\": t_obs,\n",
    "                \"p_perm\": p_perm,\n",
    "                \"dz\": dz,\n",
    "            })\n",
    "\n",
    "res = pd.DataFrame(rows)\n",
    "if len(res) == 0:\n",
    "    raise RuntimeError(\n",
    "        \"結果が0件です。\\n\"\n",
    "        \"→ master_sound ラベル付与が失敗（NaN率が高い）か、High/Lowが被験者内で成立していない可能性。\"\n",
    "    )\n",
    "\n",
    "res = res.sort_values([\"cond\",\"roi\",\"window_ms\"]).reset_index(drop=True)\n",
    "\n",
    "out_csv = OUT_DIR / \"ERP_onset_under1000ms_perm.csv\"\n",
    "res.to_csv(out_csv, index=False)\n",
    "\n",
    "print(\"\\n[SAVED]\", out_csv)\n",
    "print(res.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e45ddb-294d-4efd-9020-f1af74d65d87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
