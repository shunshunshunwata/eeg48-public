{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40324642-b2ce-4798-8a17-7a9b0df9f33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_DIR : /Users/shunsuke/EEG_48sounds\n",
      "DERIV_DIR: /Users/shunsuke/EEG_48sounds/derivatives\n",
      "AUDIT_DIR: /Users/shunsuke/EEG_48sounds/output/integration_audit\n",
      "MASTER_DIR: /Users/shunsuke/EEG_48sounds/derivatives/master_tables\n",
      "\n",
      "=== LOAD: HCU subset (48 sounds) ===\n",
      "  try: /Users/shunsuke/EEG_48sounds/HCU400_48sounds_subset.csv\n",
      "  -> FOUND: /Users/shunsuke/EEG_48sounds/HCU400_48sounds_subset.csv  shape=(48, 10103)\n",
      "\n",
      "=== LOAD: Physical sound features (48 sounds) ===\n",
      "  try: /Users/shunsuke/EEG_48sounds/sound_features_48.csv\n",
      "  try: /Users/shunsuke/EEG_48sounds/derivatives/sound_features_48.csv\n",
      "  try: /Users/shunsuke/EEG_48sounds/derivatives/sound_features/sound_features_48.csv\n",
      "  -> FOUND: /Users/shunsuke/EEG_48sounds/derivatives/sound_features/sound_features_48.csv  shape=(48, 71)\n",
      "\n",
      "=== LOAD: Subjective summary per sound ===\n",
      "  try: /Users/shunsuke/EEG_48sounds/output/ratings/sound_summary.csv\n",
      "  try: /Users/shunsuke/EEG_48sounds/derivatives/behavioral/sound_summary.csv\n",
      "  -> FOUND: /Users/shunsuke/EEG_48sounds/derivatives/behavioral/sound_summary.csv  shape=(48, 28)\n",
      "\n",
      "=== LOAD: participant x sound ratings (canonical) ===\n",
      "  try: /Users/shunsuke/EEG_48sounds/output/ratings/participant_sound_long.csv\n",
      "  try: /Users/shunsuke/EEG_48sounds/derivatives/behavioral/participant_sound_long.csv\n",
      "  -> FOUND: /Users/shunsuke/EEG_48sounds/derivatives/behavioral/participant_sound_long.csv  shape=(576, 31)\n",
      "\n",
      "=== LOAD: participant summary ===\n",
      "  try: /Users/shunsuke/EEG_48sounds/output/ratings/participant_summary.csv\n",
      "  try: /Users/shunsuke/EEG_48sounds/derivatives/behavioral/participant_summary.csv\n",
      "  -> FOUND: /Users/shunsuke/EEG_48sounds/derivatives/behavioral/participant_summary.csv  shape=(12, 7)\n",
      "\n",
      "=== LOAD: ratings_long (for reference) ===\n",
      "  try: /Users/shunsuke/EEG_48sounds/output/ratings/ratings_long.csv\n",
      "  try: /Users/shunsuke/EEG_48sounds/derivatives/behavioral/ratings_long.csv\n",
      "  -> FOUND: /Users/shunsuke/EEG_48sounds/derivatives/behavioral/ratings_long.csv  shape=(576, 31)\n",
      "\n",
      "=== LOAD: ambiguous (Approach SD top10) ===\n",
      "  try: /Users/shunsuke/EEG_48sounds/output/ratings/ambiguous_sounds_by_Approach_sd_top10.csv\n",
      "  try: /Users/shunsuke/EEG_48sounds/derivatives/behavioral/ambiguous_sounds_by_Approach_sd_top10.csv\n",
      "  -> FOUND: /Users/shunsuke/EEG_48sounds/derivatives/behavioral/ambiguous_sounds_by_Approach_sd_top10.csv  shape=(10, 28)\n",
      "\n",
      "=== LOAD: ambiguous_negative ===\n",
      "  try: /Users/shunsuke/EEG_48sounds/output/ratings/ambiguous_negative_sounds.csv\n",
      "  try: /Users/shunsuke/EEG_48sounds/derivatives/behavioral/ambiguous_negative_sounds.csv\n",
      "  -> FOUND: /Users/shunsuke/EEG_48sounds/derivatives/behavioral/ambiguous_negative_sounds.csv  shape=(4, 28)\n",
      "\n",
      "=== LOAD: EEG sound-level features (optional) ===\n",
      "  try: /Users/shunsuke/EEG_48sounds/derivatives/eeg_features_sound.csv\n",
      "  -> FOUND: /Users/shunsuke/EEG_48sounds/derivatives/eeg_features_sound.csv  shape=(48, 2370)\n",
      "\n",
      "=== LOAD: EEG subject-level features (optional) ===\n",
      "  try: /Users/shunsuke/EEG_48sounds/derivatives/eeg_features_subject.csv\n",
      "  -> FOUND: /Users/shunsuke/EEG_48sounds/derivatives/eeg_features_subject.csv  shape=(12, 1186)\n",
      "\n",
      "=== LOAD: EEG trial-level features (optional) ===\n",
      "  try: /Users/shunsuke/EEG_48sounds/derivatives/eeg_features_trial.csv\n",
      "  -> FOUND: /Users/shunsuke/EEG_48sounds/derivatives/eeg_features_trial.csv  shape=(1728, 1194)\n",
      "\n",
      "=== LOAD: master_epoch_index (highly recommended) ===\n",
      "  try: /Users/shunsuke/EEG_48sounds/derivatives/master_epoch_index.csv\n",
      "  -> FOUND: /Users/shunsuke/EEG_48sounds/derivatives/master_epoch_index.csv  shape=(1728, 32)\n",
      "Merged HCU: (48, 10104)\n",
      "Merged physical: (48, 71)\n",
      "Merged EEG sound-level: (48, 2370)\n",
      "\n",
      "=== SAVE: master_sound_level (48 sounds) ===\n",
      "  path : /Users/shunsuke/EEG_48sounds/derivatives/master_tables/master_sound_level.csv\n",
      "  shape: (48, 12573)\n",
      "Merged EEG subject-level: (12, 1186)\n",
      "\n",
      "=== SAVE: master_participant_level ===\n",
      "  path : /Users/shunsuke/EEG_48sounds/derivatives/master_tables/master_participant_level.csv\n",
      "  shape: (12, 1193)\n",
      "\n",
      "Base df_ps_master (behavior + HCU + physical): (576, 10207)\n",
      "[EEG trial] qc_pass filter: 1588 -> 1588\n",
      "\n",
      "EEG feature columns n=1184 (first 15): ['ERP_N1_FC_80_130ms', 'ERP_P2_FC_150_250ms', 'ERP_N2_FC_250_350ms', 'ERP_P3_P_300_500ms', 'ERP_LPP_P_400_800ms', 'ERP_P2off_FC_0_300ms_postOff', 'ERP_LPPoff_P_300_800ms_postOff', 'SPN_Cz_pre', 'SPN_Pz_pre', 'SP_D_Cz', 'SP_D_Pz', 'SP_E_Cz', 'SP_E_Pz', 'SP_F_Cz', 'SP_F_Pz']\n",
      "[STEP] start groupby mean ...\n",
      "[STEP] done groupby mean\n",
      "[CHECK] df_eeg_psound rows (trim by number): 576 -> 576\n",
      "\n",
      "=== SAVE: eeg_features_participant_sound (aggregated from trials) ===\n",
      "  path : /Users/shunsuke/EEG_48sounds/derivatives/eeg_features_participant_sound.csv\n",
      "  shape: (576, 1187)\n",
      "\n",
      "[CHECK] EEG merge missing rate (n_trials_eeg is NaN): 0.000\n",
      "missing EEG rows log: /Users/shunsuke/EEG_48sounds/output/integration_audit/missing_eeg_psound_rows_head500.csv\n",
      "\n",
      "=== SAVE: master_participant_sound_level ===\n",
      "  path : /Users/shunsuke/EEG_48sounds/derivatives/master_tables/master_participant_sound_level.csv\n",
      "  shape: (576, 11392)\n",
      "\n",
      "=== ALL DONE ===\n",
      " sound-level       : /Users/shunsuke/EEG_48sounds/derivatives/master_tables/master_sound_level.csv\n",
      " participant-level : /Users/shunsuke/EEG_48sounds/derivatives/master_tables/master_participant_level.csv\n",
      " participant×sound : /Users/shunsuke/EEG_48sounds/derivatives/master_tables/master_participant_sound_level.csv\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 0. 基本設定（まずここだけ合わせればOK）\n",
    "# =========================================================\n",
    "\n",
    "ROOT_DIR = Path(\"/Users/shunsuke/EEG_48sounds\")\n",
    "if not ROOT_DIR.exists():\n",
    "    ROOT_DIR = Path.cwd() / \"EEG_48sounds\"\n",
    "\n",
    "DERIV_DIR = ROOT_DIR / \"derivatives\"\n",
    "DERIV_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUT_DIR = ROOT_DIR / \"output\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "AUDIT_DIR = OUT_DIR / \"integration_audit\"\n",
    "AUDIT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MASTER_DIR = DERIV_DIR / \"master_tables\"\n",
    "MASTER_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- master 出力 ----\n",
    "MASTER_SOUND_CSV = MASTER_DIR / \"master_sound_level.csv\"\n",
    "MASTER_PARTICIPANT_CSV = MASTER_DIR / \"master_participant_level.csv\"\n",
    "MASTER_PARTICIPANT_SOUND_CSV = MASTER_DIR / \"master_participant_sound_level.csv\"\n",
    "# ---- 超おすすめ：EEG participant×sound 集約（⑥の中間成果物として保存）----\n",
    "EEG_PARTICIPANT_SOUND_CSV = DERIV_DIR / \"eeg_features_participant_sound.csv\"\n",
    "\n",
    "\n",
    "print(\"ROOT_DIR :\", ROOT_DIR)\n",
    "print(\"DERIV_DIR:\", DERIV_DIR)\n",
    "print(\"AUDIT_DIR:\", AUDIT_DIR)\n",
    "print(\"MASTER_DIR:\", MASTER_DIR)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 1. 小ユーティリティ（読み込み・保存・正規化）\n",
    "# =========================================================\n",
    "\n",
    "def load_csv_candidates(candidates: list[Path], desc: str, required: bool = False) -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    置き場所が揺れても拾えるように、候補パスを順に探して最初に見つかったものを読む。\n",
    "    required=True なら見つからない時点で停止。\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== LOAD: {desc} ===\")\n",
    "    for p in candidates:\n",
    "        print(\"  try:\", p)\n",
    "        if p.exists():\n",
    "            df = pd.read_csv(p, low_memory=False)\n",
    "            print(f\"  -> FOUND: {p}  shape={df.shape}\")\n",
    "            return df\n",
    "    print(\"  -> NOT FOUND\")\n",
    "    if required:\n",
    "        raise FileNotFoundError(f\"[MISSING] {desc} が見つかりません。候補: {[str(x) for x in candidates]}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def save_csv(df: pd.DataFrame, path: Path, desc: str):\n",
    "    \"\"\"保存時に shape とパスを表示。文字化けしやすいので utf-8-sig を標準に。\"\"\"\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"\\n=== SAVE: {desc} ===\")\n",
    "    print(f\"  path : {path}\")\n",
    "    print(f\"  shape: {df.shape}\")\n",
    "    df.to_csv(path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "\n",
    "def normalize_run(x) -> str:\n",
    "    \"\"\"run表記ゆれ（1, run1, Run1, RUN1）を run1 形式へ統一\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    s = str(x).strip().lower().replace(\" \", \"\")\n",
    "    if s.startswith(\"run\"):\n",
    "        s = s[3:]\n",
    "    m = re.search(r\"(\\d+)\", s)\n",
    "    return f\"run{int(m.group(1))}\" if m else str(x)\n",
    "\n",
    "\n",
    "def to_int_safe(x):\n",
    "    \"\"\"int化（\"1.0\" などもOK）。失敗はNaN。\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    try:\n",
    "        return int(float(x))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def normalize_filename_like_hcu(x: str) -> str:\n",
    "    \"\"\"\n",
    "    HCU/主観/物理/EEGをJOINするための FileName 正規化。\n",
    "    - \"1：flute_-9dBA_final.wav\" → \"flute.wav\"\n",
    "    - \"flute_-9dBA.wav\" → \"flute.wav\"\n",
    "    - 全角/半角ゆれも NFKC で吸収\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    s = unicodedata.normalize(\"NFKC\", str(x)).strip()\n",
    "    s = re.sub(r\"^\\s*\\d+\\s*[:：]\\s*\", \"\", s)  # 先頭番号 \"1：\" を除去\n",
    "    s = re.sub(r\"(_-?\\d+dBA.*)\\.wav$\", \".wav\", s, flags=re.IGNORECASE)  # -9dBA等を除去\n",
    "    return s\n",
    "\n",
    "\n",
    "def subject_to_participant(subject: str) -> str | None:\n",
    "    \"\"\"\n",
    "    EEGの subject 名が '1_高見' / '01_高見' / 'P01' / 'sub-01' などでも Pxx に揃える。\n",
    "    \"\"\"\n",
    "    if subject is None or (isinstance(subject, float) and np.isnan(subject)):\n",
    "        return None\n",
    "\n",
    "    s = str(subject).strip()\n",
    "\n",
    "    # 既に P01 形式\n",
    "    m = re.search(r\"[Pp](\\d{1,3})\", s)\n",
    "    if m:\n",
    "        return f\"P{int(m.group(1)):02d}\"\n",
    "\n",
    "    # 先頭数字\n",
    "    m2 = re.match(r\"(\\d{1,3})\", s)\n",
    "    if m2:\n",
    "        return f\"P{int(m2.group(1)):02d}\"\n",
    "\n",
    "    # どこかに数字がある\n",
    "    m3 = re.search(r\"(\\d{1,3})\", s)\n",
    "    if m3:\n",
    "        return f\"P{int(m3.group(1)):02d}\"\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def make_subject_id_series(participant_series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    participant (P01, P02, ...) から数値ID(subject_id)を作る。\n",
    "    取れない場合はカテゴリコードで振る（落ちないようにする）。\n",
    "    \"\"\"\n",
    "    p = participant_series.astype(str)\n",
    "    digits = p.str.extract(r\"(\\d+)\", expand=False)\n",
    "    n_ok = digits.notna().sum()\n",
    "\n",
    "    if n_ok >= max(2, int(0.5 * len(p))):\n",
    "        return digits.astype(\"Int64\")\n",
    "\n",
    "    # 数字がほぼ取れない場合 → 新規割当\n",
    "    codes = p.astype(\"category\").cat.codes + 1\n",
    "    return codes.astype(\"Int64\")\n",
    "\n",
    "\n",
    "def assert_unique(df: pd.DataFrame, keys: list[str], name: str):\n",
    "    \"\"\"キー重複があると統合解析で致命傷なので、ここで止める\"\"\"\n",
    "    dup = df.duplicated(subset=keys).sum()\n",
    "    if dup > 0:\n",
    "        ex = df[df.duplicated(subset=keys, keep=False)].sort_values(keys).head(50)\n",
    "        ex.to_csv(AUDIT_DIR / f\"dup_{name}.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "        raise ValueError(f\"[{name}] キー重複があります: keys={keys}, dup_rows={dup}\\nログ: {AUDIT_DIR / f'dup_{name}.csv'}\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 2. 入力CSVの候補（置き場所の揺れを吸収）\n",
    "# =========================================================\n",
    "\n",
    "# ---- HCU / 物理特徴 ----\n",
    "HCU_CANDIDATES = [\n",
    "    ROOT_DIR / \"HCU400_48sounds_subset.csv\",\n",
    "    DERIV_DIR / \"HCU400_48sounds_subset.csv\",\n",
    "]\n",
    "SOUND_FEATURE_CANDIDATES = [\n",
    "    ROOT_DIR / \"sound_features_48.csv\",\n",
    "    DERIV_DIR / \"sound_features_48.csv\",\n",
    "    DERIV_DIR / \"sound_features\" / \"sound_features_48.csv\", \n",
    "]\n",
    "\n",
    "# ---- 主観評価（候補ディレクトリを増やして“置き場所の揺れ”を吸収）----\n",
    "RATINGS_DIRS = [\n",
    "    ROOT_DIR / \"output\" / \"ratings\",\n",
    "    DERIV_DIR / \"behavioral\",          # ★ここがあなたの実体\n",
    "    DERIV_DIR / \"ratings\",\n",
    "    ROOT_DIR,\n",
    "    DERIV_DIR,\n",
    "]\n",
    "\n",
    "def cand(*names):\n",
    "    out = []\n",
    "    for d in RATINGS_DIRS:\n",
    "        for n in names:\n",
    "            out.append(d / n)\n",
    "    return out\n",
    "\n",
    "SOUND_SUMMARY_CANDIDATES = cand(\"sound_summary.csv\")\n",
    "PARTICIPANT_SOUND_LONG_CANDIDATES = cand(\"participant_sound_long.csv\")\n",
    "PARTICIPANT_SUMMARY_CANDIDATES = cand(\"participant_summary.csv\")\n",
    "RATINGS_LONG_CANDIDATES = cand(\"ratings_long.csv\")\n",
    "\n",
    "AMB_APPR_CANDIDATES = cand(\"ambiguous_sounds_by_Approach_sd_top10.csv\")\n",
    "AMB_NEG_CANDIDATES  = cand(\"ambiguous_negative_sounds.csv\")\n",
    "\n",
    "\n",
    "# ---- EEG特徴量（⑤の出力想定：置き場所が揺れても拾う）----\n",
    "EEG_SOUND_CANDIDATES = [\n",
    "    DERIV_DIR / \"eeg_features_sound.csv\",\n",
    "    DERIV_DIR / \"eeg_features\" / \"eeg_features_sound.csv\",\n",
    "]\n",
    "EEG_SUBJECT_CANDIDATES = [\n",
    "    DERIV_DIR / \"eeg_features_subject.csv\",\n",
    "    DERIV_DIR / \"eeg_features\" / \"eeg_features_subject.csv\",\n",
    "]\n",
    "EEG_TRIAL_CANDIDATES = [\n",
    "    DERIV_DIR / \"eeg_features_trial.csv\",\n",
    "    DERIV_DIR / \"eeg_features\" / \"eeg_features_trial.csv\",\n",
    "]\n",
    "\n",
    "# ---- EEG index（⑥で最強のJOIN基盤になる）----\n",
    "MASTER_EPOCH_INDEX_CANDIDATES = [\n",
    "    DERIV_DIR / \"master_epoch_index.csv\",\n",
    "    DERIV_DIR / \"master_epoch_index_run1_with_sound.csv\",  # 過去に作った場合も救済\n",
    "]\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 3. main（ここから本体）\n",
    "# =========================================================\n",
    "\n",
    "def main():\n",
    "    # -----------------------------------------------------\n",
    "    # 3-1) 読み込み\n",
    "    # -----------------------------------------------------\n",
    "    df_hcu = load_csv_candidates(HCU_CANDIDATES, \"HCU subset (48 sounds)\", required=False)\n",
    "    df_sound_feat = load_csv_candidates(SOUND_FEATURE_CANDIDATES, \"Physical sound features (48 sounds)\", required=False)\n",
    "\n",
    "    df_sound_sum = load_csv_candidates(SOUND_SUMMARY_CANDIDATES, \"Subjective summary per sound\", required=True)\n",
    "    df_ps_long = load_csv_candidates(PARTICIPANT_SOUND_LONG_CANDIDATES, \"participant x sound ratings (canonical)\", required=True)\n",
    "    df_ps_summary = load_csv_candidates(PARTICIPANT_SUMMARY_CANDIDATES, \"participant summary\", required=True)\n",
    "    df_ratings_long = load_csv_candidates(RATINGS_LONG_CANDIDATES, \"ratings_long (for reference)\", required=False)\n",
    "\n",
    "    df_amb_appr = load_csv_candidates(AMB_APPR_CANDIDATES, \"ambiguous (Approach SD top10)\", required=False)\n",
    "    df_amb_neg = load_csv_candidates(AMB_NEG_CANDIDATES, \"ambiguous_negative\", required=False)\n",
    "\n",
    "    df_eeg_sound = load_csv_candidates(EEG_SOUND_CANDIDATES, \"EEG sound-level features (optional)\", required=False)\n",
    "    df_eeg_subject = load_csv_candidates(EEG_SUBJECT_CANDIDATES, \"EEG subject-level features (optional)\", required=False)\n",
    "    df_eeg_trial = load_csv_candidates(EEG_TRIAL_CANDIDATES, \"EEG trial-level features (optional)\", required=False)\n",
    "\n",
    "    df_master_epoch = load_csv_candidates(MASTER_EPOCH_INDEX_CANDIDATES, \"master_epoch_index (highly recommended)\", required=False)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 3-2) 最低限の正規化（FileName / number / participant）\n",
    "    # -----------------------------------------------------\n",
    "    # sound_summary は \"48音が揃っていること\" が前提なので、ここで確認する\n",
    "    if len(df_sound_sum) != 48:\n",
    "        (df_sound_sum.head(200)).to_csv(AUDIT_DIR / \"sound_summary_head200.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "        raise ValueError(f\"sound_summary が48行ではありません: {len(df_sound_sum)}行。ログ: {AUDIT_DIR/'sound_summary_head200.csv'}\")\n",
    "\n",
    "    # FileName / FileName_norm の揺れを吸収（sound_summaryは FileName_norm だけのことがある）\n",
    "    for _df, name in [\n",
    "        (df_sound_sum, \"sound_summary\"),\n",
    "        (df_ps_long, \"participant_sound_long\"),\n",
    "    ]:\n",
    "        # すでに FileName_norm があるならそれを採用\n",
    "        if \"FileName_norm\" in _df.columns:\n",
    "            pass\n",
    "        # FileName があるなら正規化して FileName_norm を作る\n",
    "        elif \"FileName\" in _df.columns:\n",
    "            _df[\"FileName_norm\"] = _df[\"FileName\"].map(normalize_filename_like_hcu)\n",
    "        # filename という列名の可能性も救済\n",
    "        elif \"filename\" in _df.columns:\n",
    "            _df[\"FileName_norm\"] = _df[\"filename\"].map(normalize_filename_like_hcu)\n",
    "        else:\n",
    "            raise ValueError(f\"{name} に FileName/FileName_norm/filename がありません。列名を確認してください。\")\n",
    "\n",
    "        # 後段で FileName を参照しても落ちないように保険（ログ出力・監査用）\n",
    "        if \"FileName\" not in _df.columns:\n",
    "            _df[\"FileName\"] = _df[\"FileName_norm\"]\n",
    "\n",
    "\n",
    "    if df_hcu is not None:\n",
    "        # HCU側は filename 列のことが多い → FileNameに揃える\n",
    "        if \"filename\" in df_hcu.columns and \"FileName\" not in df_hcu.columns:\n",
    "            df_hcu = df_hcu.rename(columns={\"filename\": \"FileName\"})\n",
    "        if \"FileName\" in df_hcu.columns:\n",
    "            df_hcu[\"FileName_norm\"] = df_hcu[\"FileName\"].map(normalize_filename_like_hcu)\n",
    "\n",
    "    if df_sound_feat is not None:\n",
    "        # 物理特徴量のキーが sound_no の場合がある → numberへ\n",
    "        if \"sound_no\" in df_sound_feat.columns and \"number\" not in df_sound_feat.columns:\n",
    "            df_sound_feat = df_sound_feat.rename(columns={\"sound_no\": \"number\"})\n",
    "        if \"number\" in df_sound_feat.columns:\n",
    "            df_sound_feat[\"number\"] = df_sound_feat[\"number\"].map(to_int_safe)\n",
    "\n",
    "    # participant 列の存在チェック（ここがズレると後段全滅する）\n",
    "    if \"participant\" not in df_ps_long.columns:\n",
    "        raise ValueError(\"participant_sound_long.csv に participant 列がありません。主観評価スクリプトの出力を確認してください。\")\n",
    "    if \"participant\" not in df_ps_summary.columns:\n",
    "        raise ValueError(\"participant_summary.csv に participant 列がありません。主観評価スクリプトの出力を確認してください。\")\n",
    "\n",
    "    # number を int化（主観側）\n",
    "    if \"number\" in df_ps_long.columns:\n",
    "        df_ps_long[\"number\"] = df_ps_long[\"number\"].map(to_int_safe)\n",
    "    if \"number\" in df_sound_sum.columns:\n",
    "        df_sound_sum[\"number\"] = df_sound_sum[\"number\"].map(to_int_safe)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 3-3) 曖昧さフラグ（なければ空集合）\n",
    "    # -----------------------------------------------------\n",
    "    amb_appr_files = set(df_amb_appr[\"FileName_norm\"]) if (df_amb_appr is not None and \"FileName_norm\" in df_amb_appr.columns) else set()\n",
    "    amb_neg_files = set(df_amb_neg[\"FileName_norm\"]) if (df_amb_neg is not None and \"FileName_norm\" in df_amb_neg.columns) else set()\n",
    "\n",
    "    # df_amb_* が FileName_norm を持っていない場合に備え、FileName から生成して救済\n",
    "    if df_amb_appr is not None and len(amb_appr_files) == 0 and \"FileName\" in df_amb_appr.columns:\n",
    "        amb_appr_files = set(df_amb_appr[\"FileName\"].map(normalize_filename_like_hcu))\n",
    "    if df_amb_neg is not None and len(amb_neg_files) == 0 and \"FileName\" in df_amb_neg.columns:\n",
    "        amb_neg_files = set(df_amb_neg[\"FileName\"].map(normalize_filename_like_hcu))\n",
    "\n",
    "    # =====================================================\n",
    "    # 4. master_sound_level（1行=1音）\n",
    "    #   - ベース：主観 sound_summary（48行保証）\n",
    "    #   - 追加：HCU, 物理, 曖昧さフラグ, EEG音特徴（あれば）\n",
    "    # =====================================================\n",
    "    df_sound_master = df_sound_sum.copy()\n",
    "\n",
    "    # HCU結合：FileName_norm で合わせる（FileName表記揺れ対策）\n",
    "    if df_hcu is not None and \"FileName_norm\" in df_hcu.columns:\n",
    "        # HCU側で重複があったら危険なので先に落とす（48音なら基本1つずつのはず）\n",
    "        assert_unique(df_hcu, [\"FileName_norm\"], \"hcu(FileName_norm)\")\n",
    "        df_sound_master = df_sound_master.merge(df_hcu, on=\"FileName_norm\", how=\"left\", suffixes=(\"\", \"_hcu\"))\n",
    "        print(\"Merged HCU:\", df_hcu.shape)\n",
    "    else:\n",
    "        print(\"[INFO] HCUが無い or FileName_normが無い → HCU統合をスキップ\")\n",
    "\n",
    "    # 物理特徴結合：numberで合わせる（numberは安定キー）\n",
    "    if df_sound_feat is not None and \"number\" in df_sound_feat.columns:\n",
    "        # 物理特徴が number で重複してたら事故る\n",
    "        assert_unique(df_sound_feat, [\"number\"], \"sound_features(number)\")\n",
    "        df_sound_master = df_sound_master.merge(df_sound_feat, on=\"number\", how=\"left\", suffixes=(\"\", \"_phys\"))\n",
    "        print(\"Merged physical:\", df_sound_feat.shape)\n",
    "    else:\n",
    "        print(\"[INFO] 物理特徴が無い → 統合をスキップ\")\n",
    "\n",
    "    # 曖昧フラグ\n",
    "    df_sound_master[\"is_ambiguous_approach_sd_top10\"] = df_sound_master[\"FileName_norm\"].isin(amb_appr_files)\n",
    "    df_sound_master[\"is_ambiguous_negative\"] = df_sound_master[\"FileName_norm\"].isin(amb_neg_files)\n",
    "\n",
    "    # EEG音特徴（任意）：numberで合わせる\n",
    "    if df_eeg_sound is not None:\n",
    "        # ⑤の出力が sound_id の場合もあるので救済\n",
    "        if \"sound_id\" in df_eeg_sound.columns and \"number\" not in df_eeg_sound.columns:\n",
    "            df_eeg_sound = df_eeg_sound.rename(columns={\"sound_id\": \"number\"})\n",
    "        if \"number\" in df_eeg_sound.columns:\n",
    "            df_eeg_sound[\"number\"] = df_eeg_sound[\"number\"].map(to_int_safe)\n",
    "            # number重複があれば危険（ただし複数run集約等で出るなら平均済みにするべき）\n",
    "            if df_eeg_sound.duplicated(subset=[\"number\"]).any():\n",
    "                df_eeg_sound.to_csv(AUDIT_DIR / \"eeg_sound_dup_number.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "                raise ValueError(\"EEG sound-level features に number 重複があります。先に⑤側で集約してください。\")\n",
    "            df_sound_master = df_sound_master.merge(df_eeg_sound, on=\"number\", how=\"left\", suffixes=(\"\", \"_eeg\"))\n",
    "            print(\"Merged EEG sound-level:\", df_eeg_sound.shape)\n",
    "        else:\n",
    "            print(\"[INFO] eeg_features_sound に number/sound_id が無い → 音レベルEEG統合をスキップ\")\n",
    "    else:\n",
    "        print(\"[INFO] eeg_features_sound が無い → 音レベルEEG統合をスキップ\")\n",
    "\n",
    "    # 監査：48音から欠落していないか\n",
    "    if len(df_sound_master) != 48:\n",
    "        df_sound_master.to_csv(AUDIT_DIR / \"sound_master_not_48.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "        raise ValueError(\"master_sound_level が48行になっていません。ログを確認してください。\")\n",
    "\n",
    "    save_csv(df_sound_master, MASTER_SOUND_CSV, \"master_sound_level (48 sounds)\")\n",
    "\n",
    "    # =====================================================\n",
    "    # 5. master_participant_level（1行=1参加者）\n",
    "    #   - ベース：participant_summary（主観）\n",
    "    #   - 追加：EEG被験者特徴（あれば）\n",
    "    # =====================================================\n",
    "    df_participant_master = df_ps_summary.copy()\n",
    "\n",
    "    # subject_id（数値ID）を追加：統計モデルで便利\n",
    "    df_participant_master[\"subject_id\"] = make_subject_id_series(df_participant_master[\"participant\"])\n",
    "\n",
    "    if df_eeg_subject is not None:\n",
    "        # EEG側のID列が subject / subj_id など揺れるので吸収\n",
    "        id_col = None\n",
    "        for c in [\"participant\", \"subject\", \"subj_id\", \"subject_id\"]:\n",
    "            if c in df_eeg_subject.columns:\n",
    "                id_col = c\n",
    "                break\n",
    "\n",
    "        if id_col is None:\n",
    "            print(\"[INFO] eeg_features_subject にID列が見当たらない → 統合スキップ\")\n",
    "        else:\n",
    "            if id_col != \"participant\":\n",
    "                df_eeg_subject[\"participant\"] = df_eeg_subject[id_col].apply(subject_to_participant)\n",
    "            df_eeg_subject = df_eeg_subject.dropna(subset=[\"participant\"]).copy()\n",
    "\n",
    "            # participant重複があれば危険（run別に出ているなど）→ ここで集約してから統合\n",
    "            if df_eeg_subject.duplicated(subset=[\"participant\"]).any():\n",
    "                # 数値列だけ平均して participant単位に落とす\n",
    "                num_cols = [c for c in df_eeg_subject.columns if pd.api.types.is_numeric_dtype(df_eeg_subject[c])]\n",
    "                df_eeg_subject = df_eeg_subject.groupby(\"participant\")[num_cols].mean().reset_index()\n",
    "\n",
    "            df_participant_master = df_participant_master.merge(\n",
    "                df_eeg_subject,\n",
    "                on=\"participant\",\n",
    "                how=\"left\",\n",
    "                suffixes=(\"\", \"_eeg\"),\n",
    "            )\n",
    "            print(\"Merged EEG subject-level:\", df_eeg_subject.shape)\n",
    "    else:\n",
    "        print(\"[INFO] eeg_features_subject が無い → participant-level EEG統合をスキップ\")\n",
    "\n",
    "    save_csv(df_participant_master, MASTER_PARTICIPANT_CSV, \"master_participant_level\")\n",
    "\n",
    "    # =====================================================\n",
    "    # 6. master_participant_sound_level（1行=参加者×音）\n",
    "    #   - ベース：participant_sound_long（主観）\n",
    "    #   - 追加：HCU / 物理 / 曖昧フラグ\n",
    "    #   - 追加：EEG trial特徴を participant×sound に集約して統合（あれば）\n",
    "    #\n",
    "    # 重要：EEG trialの「キー揺れ」を master_epoch_index で吸収すると強い\n",
    "    # =====================================================\n",
    "    df_ps_master = df_ps_long.copy()\n",
    "\n",
    "    # subject_id 追加（参加者を数値化）\n",
    "    df_ps_master[\"subject_id\"] = make_subject_id_series(df_ps_master[\"participant\"])\n",
    "\n",
    "    # HCU/物理を付与（音側の情報なので participantsound にも入れる）\n",
    "    if df_hcu is not None and \"FileName_norm\" in df_hcu.columns:\n",
    "        assert_unique(df_hcu, [\"FileName_norm\"], \"hcu(FileName_norm)\")\n",
    "        df_ps_master = df_ps_master.merge(df_hcu, on=\"FileName_norm\", how=\"left\", suffixes=(\"\", \"_hcu\"))\n",
    "\n",
    "    if df_sound_feat is not None and \"number\" in df_sound_feat.columns and \"number\" in df_ps_master.columns:\n",
    "        assert_unique(df_sound_feat, [\"number\"], \"sound_features(number)\")\n",
    "        df_ps_master = df_ps_master.merge(df_sound_feat, on=\"number\", how=\"left\", suffixes=(\"\", \"_phys\"))\n",
    "\n",
    "    df_ps_master[\"is_ambiguous_approach_sd_top10\"] = df_ps_master[\"FileName_norm\"].isin(amb_appr_files)\n",
    "    df_ps_master[\"is_ambiguous_negative\"] = df_ps_master[\"FileName_norm\"].isin(amb_neg_files)\n",
    "\n",
    "    print(\"\\nBase df_ps_master (behavior + HCU + physical):\", df_ps_master.shape)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 6-1) EEG trial特徴（任意）を participant×sound に集約して統合\n",
    "    # -----------------------------------------------------\n",
    "    if df_eeg_trial is None:\n",
    "        print(\"[INFO] eeg_features_trial が無い → participant×sound EEG統合をスキップ\")\n",
    "        save_csv(df_ps_master, MASTER_PARTICIPANT_SOUND_CSV, \"master_participant_sound_level (no EEG trial)\")\n",
    "        print(\"\\nSaved masters.\")\n",
    "        return\n",
    "\n",
    "    # feature_ok があるなら True のみ（解析に使えるtrialだけ残す）\n",
    "    if \"feature_ok\" in df_eeg_trial.columns:\n",
    "        df_eeg_trial = df_eeg_trial[df_eeg_trial[\"feature_ok\"] == True].copy()\n",
    "\n",
    "    # run / trial_in_run を揃える（存在する場合のみ）\n",
    "    if \"run\" in df_eeg_trial.columns:\n",
    "        df_eeg_trial[\"run\"] = df_eeg_trial[\"run\"].map(normalize_run)\n",
    "    if \"trial_in_run\" in df_eeg_trial.columns:\n",
    "        df_eeg_trial[\"trial_in_run\"] = df_eeg_trial[\"trial_in_run\"].map(to_int_safe)\n",
    "\n",
    "    # participant を作る（subject列から作れるなら作る）\n",
    "    if \"participant\" not in df_eeg_trial.columns:\n",
    "        id_col = None\n",
    "        for c in [\"subject\", \"subj_id\", \"subject_id\"]:\n",
    "            if c in df_eeg_trial.columns:\n",
    "                id_col = c\n",
    "                break\n",
    "        if id_col is not None:\n",
    "            df_eeg_trial[\"participant\"] = df_eeg_trial[id_col].apply(subject_to_participant)\n",
    "\n",
    "    df_eeg_trial = df_eeg_trial.dropna(subset=[\"participant\"]).copy()\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 6-2) ここが “最強に重要”\n",
    "    # master_epoch_index があれば、EEG trial に音情報(number, FileName_norm等)を正確に付与できる\n",
    "    # -----------------------------------------------------\n",
    "    if df_master_epoch is not None:\n",
    "        # master_epoch_index 側を正規化\n",
    "        need_cols = [\"participant\", \"run\", \"trial_in_run\", \"number\", \"FileName_norm\", \"qc_pass\"]\n",
    "        for c in need_cols:\n",
    "            if c not in df_master_epoch.columns:\n",
    "                print(\"[WARN] master_epoch_index に列が足りない:\", c)\n",
    "\n",
    "        if \"run\" in df_master_epoch.columns:\n",
    "            df_master_epoch[\"run\"] = df_master_epoch[\"run\"].map(normalize_run)\n",
    "        if \"trial_in_run\" in df_master_epoch.columns:\n",
    "            df_master_epoch[\"trial_in_run\"] = df_master_epoch[\"trial_in_run\"].map(to_int_safe)\n",
    "        if \"number\" in df_master_epoch.columns:\n",
    "            df_master_epoch[\"number\"] = df_master_epoch[\"number\"].map(to_int_safe)\n",
    "        if \"FileName_norm\" not in df_master_epoch.columns and \"FileName\" in df_master_epoch.columns:\n",
    "            df_master_epoch[\"FileName_norm\"] = df_master_epoch[\"FileName\"].map(normalize_filename_like_hcu)\n",
    "\n",
    "        if \"participant\" not in df_master_epoch.columns and \"subject\" in df_master_epoch.columns:\n",
    "            df_master_epoch[\"participant\"] = df_master_epoch[\"subject\"].apply(subject_to_participant)\n",
    "\n",
    "        need_join_keys = [\"participant\", \"run\", \"trial_in_run\"]\n",
    "        ok_trial_side = all(k in df_eeg_trial.columns for k in need_join_keys)\n",
    "        ok_master_side = all(k in df_master_epoch.columns for k in need_join_keys)\n",
    "\n",
    "        if ok_trial_side and ok_master_side:\n",
    "            attach_cols = [c for c in [\"number\", \"FileName_norm\", \"qc_pass\"] if c in df_master_epoch.columns]\n",
    "\n",
    "            df_eeg_trial = df_eeg_trial.merge(\n",
    "                df_master_epoch[need_join_keys + attach_cols].drop_duplicates(subset=need_join_keys),\n",
    "                on=need_join_keys,\n",
    "                how=\"left\",\n",
    "                validate=\"many_to_one\",\n",
    "                suffixes=(\"\", \"_epoch\"),\n",
    "            )\n",
    "\n",
    "            # epoch側を正として採用（列名ぶれ・_x/_y事故を潰す）\n",
    "            for c in [\"number\", \"FileName_norm\", \"qc_pass\"]:\n",
    "                ce = f\"{c}_epoch\"\n",
    "                if ce in df_eeg_trial.columns:\n",
    "                    df_eeg_trial[c] = df_eeg_trial[ce]\n",
    "                    df_eeg_trial.drop(columns=[ce], inplace=True)\n",
    "        else:\n",
    "            print(\"[INFO] master_epoch_index と結合する3キーが不足 → 音同定の精度が落ちます（推奨：列を揃える）\")\n",
    "    else:\n",
    "        print(\"[INFO] master_epoch_index が無い → EEG trialから音同定できない可能性あり（推奨：先に作る）\")\n",
    "\n",
    "\n",
    "\n",
    "    # qc_pass が付与できていれば、passのみへ（EEGノイズ混入を防ぐ）\n",
    "    if \"qc_pass\" in df_eeg_trial.columns:\n",
    "        before = len(df_eeg_trial)\n",
    "        df_eeg_trial = df_eeg_trial[df_eeg_trial[\"qc_pass\"] == True].copy()\n",
    "        print(f\"[EEG trial] qc_pass filter: {before} -> {len(df_eeg_trial)}\")\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 6-3) 集約：participant × sound（number or FileName_norm）\n",
    "    # -----------------------------------------------------\n",
    "    # どのキーが揃っているかで最適なgroupキーを選ぶ\n",
    "    group_keys = [\"participant\"]\n",
    "    if \"number\" in df_eeg_trial.columns and df_eeg_trial[\"number\"].notna().any():\n",
    "        group_keys.append(\"number\")\n",
    "    elif \"FileName_norm\" in df_eeg_trial.columns and df_eeg_trial[\"FileName_norm\"].notna().any():\n",
    "        group_keys.append(\"FileName_norm\")\n",
    "    elif \"FileName\" in df_eeg_trial.columns:\n",
    "        df_eeg_trial[\"FileName_norm\"] = df_eeg_trial[\"FileName\"].map(normalize_filename_like_hcu)\n",
    "        group_keys.append(\"FileName_norm\")\n",
    "    else:\n",
    "        df_eeg_trial.head(200).to_csv(AUDIT_DIR / \"eeg_trial_cannot_identify_sound.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "        raise ValueError(\"EEG trialから音を同定する列がありません（number/FileNameが無い）。ログを確認してください。\")\n",
    "\n",
    "     # ---- meta判定を強化（number_x / qc_pass_x なども除外）----\n",
    "    def is_meta(c: str) -> bool:\n",
    "        base_meta = {\n",
    "            \"subject\",\"subj_id\",\"subject_id\",\"participant\",\n",
    "            \"run\",\"run_id\",\"trial_index\",\"trial_in_run\",\n",
    "            \"FileName\",\"FileName_norm\",\"category\",\n",
    "            \"qc_pass\",\"feature_ok\",\"number\",\"sound_id\",\n",
    "        }\n",
    "        if c in base_meta:\n",
    "            return True\n",
    "        # mergeで生まれる suffix付き（number_x, qc_pass_x など）もメタ扱い\n",
    "        for p in [\"number\", \"qc_pass\", \"FileName\", \"FileName_norm\"]:\n",
    "            if c.startswith(p + \"_\"):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # 数値列だけから EEG特徴量を作る（メタ列は落とす）\n",
    "    num_cols = df_eeg_trial.select_dtypes(include=[np.number]).columns\n",
    "    eeg_feat_cols = [c for c in num_cols if not is_meta(c)]\n",
    "\n",
    "    if len(eeg_feat_cols) == 0:\n",
    "        df_eeg_trial.head(200).to_csv(AUDIT_DIR / \"eeg_trial_no_numeric_features.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "        raise ValueError(\"EEG trial特徴量として使える数値列がありません。⑤の出力を確認してください。\")\n",
    "\n",
    "    print(f\"\\nEEG feature columns n={len(eeg_feat_cols)} (first 15): {eeg_feat_cols[:15]}\")\n",
    "\n",
    "    print(\"[STEP] start groupby mean ...\")\n",
    "    grouped = df_eeg_trial.groupby(group_keys)\n",
    "    df_eeg_psound = grouped[eeg_feat_cols].mean().reset_index()\n",
    "    df_eeg_psound[\"n_trials_eeg\"] = grouped.size().values\n",
    "    print(\"[STEP] done groupby mean\")\n",
    "\n",
    "        # --- 余計な participant×sound を落とす（主観側に存在する組だけ残す）---\n",
    "    before = len(df_eeg_psound)\n",
    "\n",
    "    if (\"number\" in df_eeg_psound.columns) and (\"number\" in df_ps_master.columns):\n",
    "        key_keep = df_ps_master[[\"participant\", \"number\"]].drop_duplicates()\n",
    "        df_eeg_psound = df_eeg_psound.merge(key_keep, on=[\"participant\", \"number\"], how=\"inner\")\n",
    "        print(f\"[CHECK] df_eeg_psound rows (trim by number): {before} -> {len(df_eeg_psound)}\")\n",
    "\n",
    "    elif (\"FileName_norm\" in df_eeg_psound.columns) and (\"FileName_norm\" in df_ps_master.columns):\n",
    "        key_keep = df_ps_master[[\"participant\", \"FileName_norm\"]].drop_duplicates()\n",
    "        df_eeg_psound = df_eeg_psound.merge(key_keep, on=[\"participant\", \"FileName_norm\"], how=\"inner\")\n",
    "        print(f\"[CHECK] df_eeg_psound rows (trim by FileName_norm): {before} -> {len(df_eeg_psound)}\")\n",
    "\n",
    "    else:\n",
    "        print(\"[INFO] df_eeg_psound trim skipped (no common key: number/FileName_norm)\")\n",
    "\n",
    "\n",
    "    grouped = df_eeg_trial.groupby(group_keys)\n",
    "\n",
    "    # ★超おすすめ：EEG participant×sound 集約を単体でも保存（⑥の成果物）\n",
    "    save_csv(df_eeg_psound, EEG_PARTICIPANT_SOUND_CSV, \"eeg_features_participant_sound (aggregated from trials)\")\n",
    "\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 6-4) 主観df_ps_master へ統合\n",
    "    # -----------------------------------------------------\n",
    "    join_keys = [\"participant\"]\n",
    "    if (\"number\" in df_eeg_psound.columns) and (\"number\" in df_ps_master.columns):\n",
    "        join_keys.append(\"number\")\n",
    "    elif (\"FileName_norm\" in df_eeg_psound.columns) and (\"FileName_norm\" in df_ps_master.columns):\n",
    "        join_keys.append(\"FileName_norm\")\n",
    "    else:\n",
    "        df_eeg_psound.to_csv(AUDIT_DIR / \"eeg_psound_join_key_missing.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "        raise ValueError(\"participant×sound EEG集約のJOINキーが主観側と合いません。ログを確認してください。\")\n",
    "\n",
    "\n",
    "    df_ps_master = df_ps_master.merge(df_eeg_psound, on=join_keys, how=\"left\")\n",
    "\n",
    "    # 監査：EEGが付かなかった割合\n",
    "    miss_eeg = df_ps_master[\"n_trials_eeg\"].isna().mean()\n",
    "    print(f\"\\n[CHECK] EEG merge missing rate (n_trials_eeg is NaN): {miss_eeg:.3f}\")\n",
    "    df_ps_master[df_ps_master[\"n_trials_eeg\"].isna()][[\"participant\",\"number\",\"FileName\",\"FileName_norm\"]].head(500).to_csv(\n",
    "        AUDIT_DIR / \"missing_eeg_psound_rows_head500.csv\",\n",
    "        index=False, encoding=\"utf-8-sig\"\n",
    "    )\n",
    "    print(\"missing EEG rows log:\", AUDIT_DIR / \"missing_eeg_psound_rows_head500.csv\")\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # 6-5) 保存\n",
    "    # -----------------------------------------------------\n",
    "    save_csv(df_ps_master, MASTER_PARTICIPANT_SOUND_CSV, \"master_participant_sound_level\")\n",
    "\n",
    "    print(\"\\n=== ALL DONE ===\")\n",
    "    print(\" sound-level       :\", MASTER_SOUND_CSV)\n",
    "    print(\" participant-level :\", MASTER_PARTICIPANT_CSV)\n",
    "    print(\" participant×sound :\", MASTER_PARTICIPANT_SOUND_CSV)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f341a58-5d63-46cc-b6bf-03b46804c824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fb4c95-c9e7-4911-bd65-af674c9f6152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:EEG48]",
   "language": "python",
   "name": "conda-env-EEG48-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
