{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dba841ff-177e-43b9-8e73-39af0d884d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOAD] trial  : (576, 11) | /Users/shunsuke/EEG_48sounds/derivatives/master_tables/master_participant_sound_level_with_PC.csv\n",
      "        trial columns raw=11395 -> loaded=11 (minimal)\n",
      "[LOAD] subject: (12, 10) | /Users/shunsuke/EEG_48sounds/derivatives/master_tables/master_participant_level.csv\n",
      "        subject columns raw=1193 -> loaded=10 (minimal)\n",
      "[INFO] trial  : subject col = 'subject_id'\n",
      "[INFO] subject: subject col = 'subject_id'\n",
      "[INFO] trial  : sound col   = 'sound_id'\n",
      "[INFO] rating cols: ['驚き', '緊急感', '脅威感', '圧倒感', '接近したい気持ち', '興味', '没入', '退屈']\n",
      "[INFO] PC2 sign alignment: sign=-1 (pc2_col='PC2_emotion')\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleD_outputs/tables/moduleD_PC2_axis_loadings_aligned.csv\n",
      "\n",
      "[MODULE D-1] Ambiguous sound definition (TOP-K)\n",
      "  subjects total = 12 | enough_n >= 10 (0.80)\n",
      "  neutral: |pc2_mean| <= 0.350\n",
      "  ambiguous: among candidates, top_k=10 by pc2_sd\n",
      "   sound_id  pc2_mean    pc2_sd  n_subjects  enough_n  is_ambiguous\n",
      "0       S01 -1.624193  0.942576          12      True         False\n",
      "1       S02  0.840402  0.586534          12      True         False\n",
      "2       S03  0.607329  0.876013          12      True         False\n",
      "3       S04 -1.155545  1.126300          12      True         False\n",
      "4       S05 -0.804986  1.609708          12      True         False\n",
      "5       S06  0.319184  0.891234          12      True          True\n",
      "6       S07 -1.080861  0.936568          12      True         False\n",
      "7       S08 -1.539057  1.225332          12      True         False\n",
      "8       S09 -2.125699  1.625161          12      True         False\n",
      "9       S10 -0.873238  0.685013          12      True         False\n",
      "10      S11 -0.635732  1.399111          12      True         False\n",
      "11      S12 -2.439790  1.173252          12      True         False\n",
      "12      S13 -1.876092  1.536175          12      True         False\n",
      "13      S14 -0.308876  0.942930          12      True          True\n",
      "14      S15 -0.839157  1.148055          12      True         False\n",
      "15      S16 -1.537903  1.372650          12      True         False\n",
      "16      S17  0.761006  0.968837          12      True         False\n",
      "17      S18 -0.056812  1.048686          12      True          True\n",
      "18      S19  0.163505  0.852264          12      True          True\n",
      "19      S20  0.473099  0.947682          12      True         False\n",
      "20      S21  0.188907  1.525849          12      True          True\n",
      "21      S22  1.062343  1.089365          12      True         False\n",
      "22      S23  0.802748  0.899505          12      True         False\n",
      "23      S24  0.288494  0.724739          12      True         False\n",
      "24      S25  0.359864  0.957980          12      True         False\n",
      "25      S26  0.859846  1.252116          12      True         False\n",
      "26      S27  0.223131  1.234684          12      True          True\n",
      "27      S28  0.779522  0.798961          12      True         False\n",
      "28      S29 -0.517934  1.125727          12      True         False\n",
      "29      S30  0.697684  1.155675          12      True         False\n",
      "30      S31 -0.133817  0.826321          12      True          True\n",
      "31      S32  0.246369  1.143008          12      True          True\n",
      "32      S33  0.826592  1.206562          12      True         False\n",
      "33      S34  1.246947  0.569199          12      True         False\n",
      "34      S35  0.775188  1.228190          12      True         False\n",
      "35      S36 -0.427223  1.153308          12      True         False\n",
      "36      S37  0.498832  0.641836          12      True         False\n",
      "37      S38  0.407379  0.998881          12      True         False\n",
      "38      S39 -0.290973  1.191214          12      True          True\n",
      "39      S40  0.967288  0.911301          12      True         False\n",
      "40      S41  0.387703  0.983530          12      True         False\n",
      "41      S42  0.583441  0.789296          12      True         False\n",
      "42      S43 -0.136024  1.486777          12      True          True\n",
      "43      S44  0.826006  0.862598          12      True         False\n",
      "44      S45  0.845441  0.881059          12      True         False\n",
      "45      S46  0.571973  0.943119          12      True         False\n",
      "46      S47  1.230977  0.554310          12      True         False\n",
      "47      S48  0.562712  0.941840          12      True         False\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleD_outputs/tables/moduleD_ambiguous_sounds_stats.csv\n",
      "\n",
      "[MODULE D-2] Individual-difference scores (ambiguous set)\n",
      "  Exclude subjects with ambig trials < 2: 12 -> 12\n",
      "  PCA explained variance ratio:\n",
      "    PC1: 0.293\n",
      "    PC2: 0.226\n",
      "    PC3: 0.164\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleD_outputs/tables/moduleD_individual_difference_scores.csv\n",
      "\n",
      "[MODULE D-3] Merge subject EEG + indiv scores\n",
      "  merged: (12, 16)\n",
      "\n",
      "[MODULE D-3] EEG feature columns\n",
      "  n_eeg_cols = 9\n",
      "  head: ['ERP_N1_FC_80_130ms_mean', 'ERP_P2_FC_150_250ms_mean', 'ERP_N2_FC_250_350ms_mean', 'ERP_P3_P_300_500ms_mean', 'ERP_LPP_P_400_800ms_mean', 'ERP_P2off_FC_0_300ms_postOff_mean', 'ERP_LPPoff_P_300_800ms_postOff_mean', 'SPN_Cz_pre_mean', 'SPN_Pz_pre_mean']\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleD_outputs/tables/moduleD_eeg_association_spearman_perm.csv\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleD_outputs/tables/moduleD_PRIMARY_results_with_bootstrapCI.csv\n",
      "          target                              feature   n  spearman_rho  \\\n",
      "0  ambig_pc2_mad             ERP_P2_FC_150_250ms_mean  12     -0.803509   \n",
      "1  ambig_pc2_mad              ERP_N1_FC_80_130ms_mean  12      0.768421   \n",
      "2  ambig_pc2_mad             ERP_N2_FC_250_350ms_mean  12      0.768421   \n",
      "3  ambig_pc2_mad    ERP_P2off_FC_0_300ms_postOff_mean  12     -0.726316   \n",
      "4  ambig_pc2_mad                      SPN_Cz_pre_mean  12      0.424561   \n",
      "5  ambig_pc2_mad                      SPN_Pz_pre_mean  12     -0.108772   \n",
      "6  ambig_pc2_mad  ERP_LPPoff_P_300_800ms_postOff_mean  12     -0.080702   \n",
      "7  ambig_pc2_mad             ERP_LPP_P_400_800ms_mean  12      0.052632   \n",
      "8  ambig_pc2_mad              ERP_P3_P_300_500ms_mean  12     -0.017544   \n",
      "\n",
      "     p_perm   ci95_lo   ci95_hi  q_fdr_primary  \n",
      "0  0.002400 -0.971429 -0.429501       0.016197  \n",
      "1  0.005199  0.318989  0.950045       0.016197  \n",
      "2  0.005399  0.311828  0.947199       0.016197  \n",
      "3  0.011798 -0.931818 -0.232962       0.026545  \n",
      "4  0.162168 -0.242435  0.885064       0.291902  \n",
      "5  0.737253 -0.729537  0.597143       0.954409  \n",
      "6  0.800640 -0.645768  0.597071       0.954409  \n",
      "7  0.875025 -0.571442  0.655939       0.954409  \n",
      "8  0.954409 -0.562276  0.525180       0.954409  \n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleD_outputs/tables/moduleD_PRIMARY_robustness_leave1.csv\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleD_outputs/tables/moduleD_PRIMARY_specificity_overallMAD.csv\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleD_outputs/tables/moduleD_ambiguous_set_stability_LOSO.csv\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleD_outputs/tables/moduleD_ambiguous_set_selection_frequency_LOSO.csv\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleD_outputs/figures/moduleD_LOSO_selection_frequency.png\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleD_outputs/figures/moduleD_LOSO_jaccard_hist.png\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleD_outputs/figures/moduleD_scatter_ERP_P2_FC_150_250ms_mean.png\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleD_outputs/figures/moduleD_scatter_ERP_N1_FC_80_130ms_mean.png\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleD_outputs/figures/moduleD_scatter_ERP_N2_FC_250_350ms_mean.png\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleD_outputs/figures/moduleD_scatter_ERP_P2off_FC_0_300ms_postOff_mean.png\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleD_outputs/tables/moduleD_KEYNUMBERS.json\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleD_outputs/tables/moduleD_NEXT_ACTIONS.md\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleD_outputs/tables/moduleD_SLIDE_BULLETS.txt\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleD_outputs/logs/moduleD_metadata.json\n",
      "\n",
      "========================================================================\n",
      "4) 今すぐ“成果物として強くする”ための次アクション（自動要約）\n",
      "========================================================================\n",
      "[NEXT] LOSO Jaccard mean: 0.727\n",
      "[NEXT] LOSO Jaccard min : 0.538\n",
      "[NEXT] LOSO Jaccard max : 0.900\n",
      "\n",
      "[NEXT] Top selection frequency sounds (head 15):\n",
      "sound_id  selected_count  selected_ratio  n_folds\n",
      "     S18              12        1.000000       12\n",
      "     S21              11        0.916667       12\n",
      "     S27              11        0.916667       12\n",
      "     S32              11        0.916667       12\n",
      "     S43              11        0.916667       12\n",
      "     S19              10        0.833333       12\n",
      "     S14               9        0.750000       12\n",
      "     S31               9        0.750000       12\n",
      "     S06               8        0.666667       12\n",
      "     S39               7        0.583333       12\n",
      "     S25               5        0.416667       12\n",
      "     S41               4        0.333333       12\n",
      "     S24               3        0.250000       12\n",
      "     S36               3        0.250000       12\n",
      "     S38               3        0.250000       12\n",
      "\n",
      "[NEXT] Top EEG associations (head 10):\n",
      "       target                             feature  n  spearman_rho   p_perm  q_fdr_primary   ci95_lo   ci95_hi\n",
      "ambig_pc2_mad            ERP_P2_FC_150_250ms_mean 12     -0.803509 0.002400       0.016197 -0.971429 -0.429501\n",
      "ambig_pc2_mad             ERP_N1_FC_80_130ms_mean 12      0.768421 0.005199       0.016197  0.318989  0.950045\n",
      "ambig_pc2_mad            ERP_N2_FC_250_350ms_mean 12      0.768421 0.005399       0.016197  0.311828  0.947199\n",
      "ambig_pc2_mad   ERP_P2off_FC_0_300ms_postOff_mean 12     -0.726316 0.011798       0.026545 -0.931818 -0.232962\n",
      "ambig_pc2_mad                     SPN_Cz_pre_mean 12      0.424561 0.162168       0.291902 -0.242435  0.885064\n",
      "ambig_pc2_mad                     SPN_Pz_pre_mean 12     -0.108772 0.737253       0.954409 -0.729537  0.597143\n",
      "ambig_pc2_mad ERP_LPPoff_P_300_800ms_postOff_mean 12     -0.080702 0.800640       0.954409 -0.645768  0.597071\n",
      "ambig_pc2_mad            ERP_LPP_P_400_800ms_mean 12      0.052632 0.875025       0.954409 -0.571442  0.655939\n",
      "ambig_pc2_mad             ERP_P3_P_300_500ms_mean 12     -0.017544 0.954409       0.954409 -0.562276  0.525180\n",
      "\n",
      "[MODULE D FINAL] DONE\n",
      "  outputs dir : /Users/shunsuke/EEG_48sounds/moduleD_outputs\n",
      "  tables      : /Users/shunsuke/EEG_48sounds/moduleD_outputs/tables\n",
      "  figures     : /Users/shunsuke/EEG_48sounds/moduleD_outputs/figures\n",
      "  logs        : /Users/shunsuke/EEG_48sounds/moduleD_outputs/logs\n",
      "[TIME] total seconds: 16.9\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Module D: Ambiguous sounds & Individual differences (PC2) + EEG association\n",
    "===========================================================================\n",
    "End-to-end pipeline (reproducible, “成果物として強い”完全体):\n",
    "\n",
    "D-0) Load trial-level master (subject x sound) with PC2 + 8 ratings.\n",
    "     Load subject-level master with EEG features (ERP_/SPN_).\n",
    "     *Minimal loading by default* (reads only necessary columns).\n",
    "\n",
    "D-0.5) Align PC2 sign for interpretability (threat/avoidance direction).\n",
    "       Save pseudo \"PC2 axis loadings\" via standardized regression: PC2 ~ z(ratings).\n",
    "\n",
    "D-1) Define ambiguous sounds:\n",
    "     - candidates: enough subjects (>= ceil(total_subjects * enough_ratio))\n",
    "     - neutral: abs(pc2_mean) <= neutral_th\n",
    "     - ambiguous: among candidates, top_k by pc2_sd\n",
    "     Save stats table.\n",
    "\n",
    "D-2) Compute individual-difference scores (ambiguous set):\n",
    "     - ambig_pc2_mad (within-subject MAD over ambiguous sounds)\n",
    "     - PCA over subject-by-ambiguousSound PC2 matrix (optional but saved)\n",
    "     Save scores table.\n",
    "\n",
    "D-3) Merge subject-level EEG features + indiv scores, then:\n",
    "     - Spearman correlation + permutation p-value (two-sided)\n",
    "     - Bootstrap CI\n",
    "     - FDR correction\n",
    "     - Robustness: leave-1-subject-out for primary features\n",
    "     - Specificity: compare to overall MAD (all sounds)\n",
    "     Save result tables.\n",
    "\n",
    "D-4) LOSO stability of ambiguous sound set:\n",
    "     - Recompute ambiguous set leaving one subject out\n",
    "     - Jaccard similarity vs full set\n",
    "     - Count selection frequency across folds\n",
    "     Save stability tables and plots.\n",
    "\n",
    "4) “成果物として強くする”次アクションの自動パッケージ出力:\n",
    "     - moduleD_KEYNUMBERS.json\n",
    "     - moduleD_NEXT_ACTIONS.md  (no tabulate dependency)\n",
    "     - moduleD_SLIDE_BULLETS.txt\n",
    "     - top EEG scatter plots\n",
    "\n",
    "Dependencies:\n",
    "  numpy, pandas, scipy, scikit-learn, statsmodels, matplotlib\n",
    "\n",
    "Usage:\n",
    "  python moduleD_ambiguous_and_individual_diff.py --root-dir /Users/shunsuke/EEG_48sounds\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import hashlib\n",
    "import json\n",
    "import math\n",
    "import platform\n",
    "import sys\n",
    "import time\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "@dataclass\n",
    "class Config:\n",
    "    root_dir: Path\n",
    "\n",
    "    # Inputs\n",
    "    trial_csv: Path\n",
    "    subject_csv: Path\n",
    "\n",
    "    # Output\n",
    "    out_dir: Path\n",
    "    tab_dir: Path\n",
    "    fig_dir: Path\n",
    "    log_dir: Path\n",
    "\n",
    "    # Columns (autodetected if None)\n",
    "    subject_col: Optional[str] = None\n",
    "    sound_col: Optional[str] = None\n",
    "    pc2_col: str = \"PC2_emotion\"\n",
    "\n",
    "    # Ratings (Japanese)\n",
    "    rating_cols_expected: Tuple[str, ...] = (\n",
    "        \"驚き\", \"緊急感\", \"脅威感\", \"圧倒感\", \"接近したい気持ち\", \"興味\", \"没入\", \"退屈\"\n",
    "    )\n",
    "\n",
    "    # Ambiguous definition\n",
    "    enough_ratio: float = 0.80\n",
    "    neutral_th: float = 0.35\n",
    "    top_k: int = 10\n",
    "\n",
    "    # Stats params\n",
    "    n_perm: int = 5000\n",
    "    n_boot: int = 5000\n",
    "    seed: int = 42\n",
    "\n",
    "    # EEG column selection\n",
    "    eeg_cols: Optional[List[str]] = None  # if None -> auto detect by prefix patterns ERP_/SPN_\n",
    "\n",
    "    # I/O behavior\n",
    "    minimal_load: bool = True\n",
    "    make_figures: bool = True\n",
    "\n",
    "    # Reporting\n",
    "    n_scatter_top: int = 4  # how many top EEG features to make scatter plots\n",
    "\n",
    "\n",
    "DEFAULT_ROOT = \"/Users/shunsuke/EEG_48sounds\"\n",
    "\n",
    "\n",
    "def build_config(\n",
    "    root_dir: str,\n",
    "    trial_csv: Optional[str] = None,\n",
    "    subject_csv: Optional[str] = None,\n",
    "    out_dir: Optional[str] = None,\n",
    "    subject_col: Optional[str] = None,\n",
    "    sound_col: Optional[str] = None,\n",
    "    pc2_col: str = \"PC2_emotion\",\n",
    "    enough_ratio: float = 0.80,\n",
    "    neutral_th: float = 0.35,\n",
    "    top_k: int = 10,\n",
    "    n_perm: int = 5000,\n",
    "    n_boot: int = 5000,\n",
    "    seed: int = 42,\n",
    "    minimal_load: bool = True,\n",
    "    make_figures: bool = True,\n",
    ") -> Config:\n",
    "    root = Path(root_dir)\n",
    "\n",
    "    trial = Path(trial_csv) if trial_csv else root / \"derivatives/master_tables/master_participant_sound_level_with_PC.csv\"\n",
    "    subj = Path(subject_csv) if subject_csv else root / \"derivatives/master_tables/master_participant_level.csv\"\n",
    "\n",
    "    out = Path(out_dir) if out_dir else root / \"moduleD_outputs\"\n",
    "    tab = out / \"tables\"\n",
    "    fig = out / \"figures\"\n",
    "    log = out / \"logs\"\n",
    "    tab.mkdir(parents=True, exist_ok=True)\n",
    "    fig.mkdir(parents=True, exist_ok=True)\n",
    "    log.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return Config(\n",
    "        root_dir=root,\n",
    "        trial_csv=trial,\n",
    "        subject_csv=subj,\n",
    "        out_dir=out,\n",
    "        tab_dir=tab,\n",
    "        fig_dir=fig,\n",
    "        log_dir=log,\n",
    "        subject_col=subject_col,\n",
    "        sound_col=sound_col,\n",
    "        pc2_col=pc2_col,\n",
    "        enough_ratio=enough_ratio,\n",
    "        neutral_th=neutral_th,\n",
    "        top_k=top_k,\n",
    "        n_perm=n_perm,\n",
    "        n_boot=n_boot,\n",
    "        seed=seed,\n",
    "        minimal_load=minimal_load,\n",
    "        make_figures=make_figures,\n",
    "    )\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Utilities\n",
    "# =========================\n",
    "def now_str() -> str:\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "def save_csv(df: pd.DataFrame, path: Path) -> None:\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"[SAVE] {path}\")\n",
    "\n",
    "\n",
    "def save_json(obj: dict, path: Path) -> None:\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"[SAVE] {path}\")\n",
    "\n",
    "\n",
    "def save_text(text: str, path: Path) -> None:\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "    print(f\"[SAVE] {path}\")\n",
    "\n",
    "\n",
    "def in_notebook() -> bool:\n",
    "    try:\n",
    "        from IPython import get_ipython  # type: ignore\n",
    "        ip = get_ipython()\n",
    "        if ip is None:\n",
    "            return False\n",
    "        return \"IPKernelApp\" in ip.config\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def find_first_existing(cols: List[str], candidates: List[str]) -> Optional[str]:\n",
    "    cols_lower = {c.lower(): c for c in cols}\n",
    "    for cand in candidates:\n",
    "        if cand in cols:\n",
    "            return cand\n",
    "        if cand.lower() in cols_lower:\n",
    "            return cols_lower[cand.lower()]\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_subject_col_from_cols(cols: List[str]) -> str:\n",
    "    candidates = [\"subject_id\", \"subject\", \"participant_id\", \"participant\", \"subj\", \"sid\", \"ID\"]\n",
    "    c = find_first_existing(cols, candidates)\n",
    "    if c is None:\n",
    "        raise ValueError(\"Could not find subject column. Pass --subject-col explicitly.\")\n",
    "    return c\n",
    "\n",
    "\n",
    "def find_sound_col_from_cols(cols: List[str]) -> str:\n",
    "    candidates = [\"sound_id\", \"sound\", \"stimulus_id\", \"stimulus\", \"number\", \"trial_sound\", \"sid_sound\"]\n",
    "    c = find_first_existing(cols, candidates)\n",
    "    if c is None:\n",
    "        raise ValueError(\"Could not find sound column. Pass --sound-col explicitly.\")\n",
    "    return c\n",
    "\n",
    "\n",
    "def detect_rating_cols_from_cols(cols: List[str], expected: Tuple[str, ...]) -> List[str]:\n",
    "    # Prefer raw names; fallback to *_mean if raw absent\n",
    "    found_raw = [c for c in expected if c in cols]\n",
    "    if len(found_raw) > 0:\n",
    "        return found_raw\n",
    "    found_mean = [f\"{c}_mean\" for c in expected if f\"{c}_mean\" in cols]\n",
    "    return found_mean\n",
    "\n",
    "\n",
    "def mad(x: np.ndarray) -> float:\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    med = np.nanmedian(x)\n",
    "    return float(np.nanmedian(np.abs(x - med)))\n",
    "\n",
    "\n",
    "def jaccard(a: List[str], b: List[str]) -> float:\n",
    "    sa, sb = set(a), set(b)\n",
    "    if len(sa | sb) == 0:\n",
    "        return float(\"nan\")\n",
    "    return len(sa & sb) / len(sa | sb)\n",
    "\n",
    "\n",
    "def stable_seed(base_seed: int, key: str) -> int:\n",
    "    \"\"\"Per-feature stable seed to avoid order-dependence.\"\"\"\n",
    "    h = hashlib.md5(key.encode(\"utf-8\")).hexdigest()\n",
    "    return (base_seed + int(h[:8], 16)) % (2**32 - 1)\n",
    "\n",
    "\n",
    "def df_to_markdown_pipe(df: pd.DataFrame, max_rows: int = 15) -> str:\n",
    "    \"\"\"Minimal markdown table formatter (no tabulate dependency).\"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        return \"_(empty)_\\n\"\n",
    "    d = df.copy()\n",
    "    if max_rows is not None and len(d) > max_rows:\n",
    "        d = d.head(max_rows)\n",
    "    cols = list(d.columns)\n",
    "    # stringify cells\n",
    "    def fmt(v):\n",
    "        if isinstance(v, float):\n",
    "            if np.isnan(v):\n",
    "                return \"\"\n",
    "            return f\"{v:.6g}\"\n",
    "        return str(v)\n",
    "    rows = [[fmt(v) for v in d.iloc[i].tolist()] for i in range(len(d))]\n",
    "    # widths\n",
    "    widths = [len(str(c)) for c in cols]\n",
    "    for r in rows:\n",
    "        widths = [max(w, len(cell)) for w, cell in zip(widths, r)]\n",
    "    # build\n",
    "    header = \"| \" + \" | \".join(str(c).ljust(w) for c, w in zip(cols, widths)) + \" |\"\n",
    "    sep = \"| \" + \" | \".join(\"-\" * w for w in widths) + \" |\"\n",
    "    body = \"\\n\".join(\"| \" + \" | \".join(cell.ljust(w) for cell, w in zip(r, widths)) + \" |\" for r in rows)\n",
    "    return header + \"\\n\" + sep + (\"\\n\" + body if body else \"\") + \"\\n\"\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Loading (minimal)\n",
    "# =========================\n",
    "def detect_eeg_cols_from_cols(cols: List[str]) -> List[str]:\n",
    "    eeg = []\n",
    "    for c in cols:\n",
    "        if isinstance(c, str) and (c.startswith(\"ERP_\") or c.startswith(\"SPN_\")):\n",
    "            eeg.append(c)\n",
    "    return eeg\n",
    "\n",
    "\n",
    "def load_inputs(cfg: Config) -> Tuple[pd.DataFrame, pd.DataFrame, List[str]]:\n",
    "    \"\"\"\n",
    "    Loads:\n",
    "      - trial table with minimal required columns\n",
    "      - subject table with minimal required columns\n",
    "    Returns:\n",
    "      df_trial, df_subj, rating_cols\n",
    "    \"\"\"\n",
    "    # ---- trial header\n",
    "    trial_header = pd.read_csv(cfg.trial_csv, nrows=0)\n",
    "    trial_cols_all = trial_header.columns.tolist()\n",
    "    raw_trial_ncols = len(trial_cols_all)\n",
    "\n",
    "    if cfg.subject_col is None:\n",
    "        cfg.subject_col = find_subject_col_from_cols(trial_cols_all)\n",
    "    if cfg.sound_col is None:\n",
    "        cfg.sound_col = find_sound_col_from_cols(trial_cols_all)\n",
    "\n",
    "    rating_cols = detect_rating_cols_from_cols(trial_cols_all, cfg.rating_cols_expected)\n",
    "    if cfg.pc2_col not in trial_cols_all:\n",
    "        raise ValueError(f\"PC2 column '{cfg.pc2_col}' not found in trial CSV.\")\n",
    "\n",
    "    trial_usecols = [cfg.subject_col, cfg.sound_col, cfg.pc2_col] + rating_cols\n",
    "    # keep only existing (safety)\n",
    "    trial_usecols = [c for c in trial_usecols if c in trial_cols_all]\n",
    "\n",
    "    if cfg.minimal_load:\n",
    "        df_trial = pd.read_csv(cfg.trial_csv, usecols=trial_usecols)\n",
    "        print(f\"[LOAD] trial  : {df_trial.shape} | {cfg.trial_csv}\")\n",
    "        print(f\"        trial columns raw={raw_trial_ncols} -> loaded={len(df_trial.columns)} (minimal)\")\n",
    "    else:\n",
    "        df_trial = pd.read_csv(cfg.trial_csv)\n",
    "        print(f\"[LOAD] trial  : {df_trial.shape} | {cfg.trial_csv}\")\n",
    "\n",
    "    # ---- subject header\n",
    "    subj_header = pd.read_csv(cfg.subject_csv, nrows=0)\n",
    "    subj_cols_all = subj_header.columns.tolist()\n",
    "    raw_subj_ncols = len(subj_cols_all)\n",
    "\n",
    "    # subject id column might differ in subject table\n",
    "    subj_subject_col = cfg.subject_col if cfg.subject_col in subj_cols_all else find_subject_col_from_cols(subj_cols_all)\n",
    "\n",
    "    if cfg.eeg_cols is None:\n",
    "        eeg_cols = detect_eeg_cols_from_cols(subj_cols_all)\n",
    "    else:\n",
    "        eeg_cols = [c for c in cfg.eeg_cols if c in subj_cols_all]\n",
    "\n",
    "    if len(eeg_cols) == 0:\n",
    "        raise ValueError(\"No EEG feature columns detected. Provide --eeg-cols or ensure subject CSV contains ERP_/SPN_ columns.\")\n",
    "\n",
    "    subj_usecols = [subj_subject_col] + eeg_cols\n",
    "    subj_usecols = [c for c in subj_usecols if c in subj_cols_all]\n",
    "\n",
    "    if cfg.minimal_load:\n",
    "        df_subj = pd.read_csv(cfg.subject_csv, usecols=subj_usecols)\n",
    "        print(f\"[LOAD] subject: {df_subj.shape} | {cfg.subject_csv}\")\n",
    "        print(f\"        subject columns raw={raw_subj_ncols} -> loaded={len(df_subj.columns)} (minimal)\")\n",
    "    else:\n",
    "        df_subj = pd.read_csv(cfg.subject_csv)\n",
    "        print(f\"[LOAD] subject: {df_subj.shape} | {cfg.subject_csv}\")\n",
    "\n",
    "    # normalize subject id col name in subject table to cfg.subject_col\n",
    "    if subj_subject_col != cfg.subject_col:\n",
    "        df_subj = df_subj.rename(columns={subj_subject_col: cfg.subject_col})\n",
    "\n",
    "    # dtype normalize early (merge safety)\n",
    "    df_trial[cfg.subject_col] = df_trial[cfg.subject_col].astype(str)\n",
    "    df_subj[cfg.subject_col] = df_subj[cfg.subject_col].astype(str)\n",
    "    df_trial[cfg.sound_col] = df_trial[cfg.sound_col].astype(str)\n",
    "\n",
    "    print(f\"[INFO] trial  : subject col = '{cfg.subject_col}'\")\n",
    "    print(f\"[INFO] subject: subject col = '{cfg.subject_col}'\")\n",
    "    print(f\"[INFO] trial  : sound col   = '{cfg.sound_col}'\")\n",
    "    print(f\"[INFO] rating cols: {rating_cols}\")\n",
    "\n",
    "    return df_trial, df_subj, rating_cols\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Core steps\n",
    "# =========================\n",
    "def aggregate_subject_sound(df_trial: pd.DataFrame, subject_col: str, sound_col: str, cols: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Ensure unique subject-sound rows by averaging duplicates.\"\"\"\n",
    "    agg = (\n",
    "        df_trial\n",
    "        .groupby([subject_col, sound_col], as_index=False)[cols]\n",
    "        .mean()\n",
    "    )\n",
    "    return agg\n",
    "\n",
    "\n",
    "def align_pc2_sign(\n",
    "    cfg: Config,\n",
    "    df_trial: pd.DataFrame,\n",
    "    rating_cols: List[str],\n",
    ") -> Tuple[pd.DataFrame, int, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Align PC2 sign so that PC2 is positively associated with \"avoidance/threat\" anchor.\n",
    "    Anchor = mean(threat-related) - mean(approach-related) at sound-level.\n",
    "\n",
    "    Then compute pseudo-loadings via standardized regression: PC2 ~ z(ratings).\n",
    "    Saves: moduleD_PC2_axis_loadings_aligned.csv\n",
    "    \"\"\"\n",
    "    pc2 = cfg.pc2_col\n",
    "    subject_col = cfg.subject_col\n",
    "    sound_col = cfg.sound_col\n",
    "\n",
    "    if len(rating_cols) == 0:\n",
    "        print(f\"[INFO] PC2 sign alignment: sign=1 (no rating cols found; pc2_col='{pc2}')\")\n",
    "        return df_trial.copy(), 1, pd.DataFrame()\n",
    "\n",
    "    cols_needed = [pc2] + rating_cols\n",
    "    df_ss = aggregate_subject_sound(df_trial, subject_col, sound_col, cols_needed)\n",
    "\n",
    "    # sound-level mean (avoid overweighting subjects)\n",
    "    sound_mean = df_ss.groupby(sound_col, as_index=False)[cols_needed].mean()\n",
    "\n",
    "    def col_present(name: str) -> Optional[str]:\n",
    "        if name in rating_cols:\n",
    "            return name\n",
    "        nm = f\"{name}_mean\"\n",
    "        if nm in rating_cols:\n",
    "            return nm\n",
    "        return None\n",
    "\n",
    "    threat_cols = [c for c in [col_present(\"緊急感\"), col_present(\"脅威感\"), col_present(\"圧倒感\")] if c is not None]\n",
    "    approach_cols = [c for c in [col_present(\"接近したい気持ち\"), col_present(\"興味\"), col_present(\"没入\")] if c is not None]\n",
    "\n",
    "    if len(threat_cols) == 0 or len(approach_cols) == 0:\n",
    "        anchor = sound_mean[rating_cols].mean(axis=1).to_numpy()\n",
    "    else:\n",
    "        anchor = sound_mean[threat_cols].mean(axis=1).to_numpy() - sound_mean[approach_cols].mean(axis=1).to_numpy()\n",
    "\n",
    "    corr = np.corrcoef(sound_mean[pc2].to_numpy(dtype=float), anchor.astype(float))[0, 1]\n",
    "    sign = 1 if np.isnan(corr) or corr >= 0 else -1\n",
    "\n",
    "    df_aligned = df_trial.copy()\n",
    "    df_aligned[pc2] = df_aligned[pc2] * sign\n",
    "\n",
    "    print(f\"[INFO] PC2 sign alignment: sign={sign} (pc2_col='{pc2}')\")\n",
    "\n",
    "    # pseudo-loadings via standardized regression\n",
    "    df_reg = df_ss.dropna(subset=[pc2] + rating_cols).copy()\n",
    "    X = df_reg[rating_cols].to_numpy(dtype=float)\n",
    "    y = df_reg[pc2].to_numpy(dtype=float)\n",
    "\n",
    "    Xz = StandardScaler().fit_transform(X)\n",
    "    yz = (y - y.mean()) / (y.std(ddof=0) + 1e-12)\n",
    "\n",
    "    X_design = np.c_[np.ones(len(Xz)), Xz]\n",
    "    beta, *_ = np.linalg.lstsq(X_design, yz, rcond=None)\n",
    "\n",
    "    loadings = pd.DataFrame({\n",
    "        \"rating\": [\"(intercept)\"] + rating_cols,\n",
    "        \"coef_z\": beta.tolist(),\n",
    "    })\n",
    "    loadings[\"pc2_aligned_sign\"] = sign\n",
    "    loadings = loadings.sort_values(\"coef_z\", key=lambda s: np.abs(s), ascending=False).reset_index(drop=True)\n",
    "\n",
    "    out_load = cfg.tab_dir / \"moduleD_PC2_axis_loadings_aligned.csv\"\n",
    "    save_csv(loadings, out_load)\n",
    "\n",
    "    return df_aligned, sign, loadings\n",
    "\n",
    "\n",
    "def define_ambiguous_sounds(\n",
    "    cfg: Config,\n",
    "    df_trial: pd.DataFrame,\n",
    "    save_path: Optional[Path] = None,\n",
    "    verbose: bool = True,\n",
    ") -> Tuple[pd.DataFrame, List[str]]:\n",
    "    \"\"\"\n",
    "    D-1:\n",
    "      - enough_n: n_subjects >= ceil(total_subjects * enough_ratio)\n",
    "      - neutral: abs(pc2_mean) <= neutral_th\n",
    "      - ambiguous: among candidates, top_k by pc2_sd\n",
    "    \"\"\"\n",
    "    subject_col = cfg.subject_col\n",
    "    sound_col = cfg.sound_col\n",
    "    pc2 = cfg.pc2_col\n",
    "\n",
    "    df_ss = aggregate_subject_sound(df_trial, subject_col, sound_col, [pc2])\n",
    "\n",
    "    subjects = sorted(df_ss[subject_col].unique().tolist())\n",
    "    total_subj = len(subjects)\n",
    "    enough_n_min = int(math.ceil(total_subj * cfg.enough_ratio))\n",
    "\n",
    "    g = df_ss.groupby(sound_col)[pc2]\n",
    "    stats = pd.DataFrame({\n",
    "        \"sound_id\": g.mean().index.astype(str),\n",
    "        \"pc2_mean\": g.mean().values,\n",
    "        \"pc2_sd\": g.std(ddof=1).values,\n",
    "        \"n_subjects\": g.count().values,\n",
    "    })\n",
    "    stats[\"enough_n\"] = stats[\"n_subjects\"] >= enough_n_min\n",
    "    stats[\"is_neutral_candidate\"] = stats[\"enough_n\"] & (stats[\"pc2_mean\"].abs() <= cfg.neutral_th)\n",
    "\n",
    "    cand = stats[stats[\"is_neutral_candidate\"]].copy()\n",
    "    cand = cand.sort_values([\"pc2_sd\", \"sound_id\"], ascending=[False, True])\n",
    "\n",
    "    selected = cand.head(cfg.top_k)[\"sound_id\"].tolist()\n",
    "    stats[\"is_ambiguous\"] = stats[\"sound_id\"].isin(selected)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n[MODULE D-1] Ambiguous sound definition (TOP-K)\")\n",
    "        print(f\"  subjects total = {total_subj} | enough_n >= {enough_n_min} ({cfg.enough_ratio:.2f})\")\n",
    "        print(f\"  neutral: |pc2_mean| <= {cfg.neutral_th:.3f}\")\n",
    "        print(f\"  ambiguous: among candidates, top_k={cfg.top_k} by pc2_sd\")\n",
    "        print(stats[[\"sound_id\", \"pc2_mean\", \"pc2_sd\", \"n_subjects\", \"enough_n\", \"is_ambiguous\"]])\n",
    "\n",
    "    if save_path is not None:\n",
    "        save_csv(stats, save_path)\n",
    "\n",
    "    return stats, selected\n",
    "\n",
    "\n",
    "def compute_individual_difference_scores(\n",
    "    cfg: Config,\n",
    "    df_trial: pd.DataFrame,\n",
    "    ambiguous_sounds: List[str],\n",
    ") -> Tuple[pd.DataFrame, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    D-2:\n",
    "      - ambig_pc2_mad per subject over ambiguous sounds\n",
    "      - PCA over subject x ambiguousSound PC2 matrix\n",
    "    \"\"\"\n",
    "    subject_col = cfg.subject_col\n",
    "    sound_col = cfg.sound_col\n",
    "    pc2 = cfg.pc2_col\n",
    "\n",
    "    df_ss = aggregate_subject_sound(df_trial, subject_col, sound_col, [pc2])\n",
    "\n",
    "    df_a = df_ss[df_ss[sound_col].astype(str).isin([str(s) for s in ambiguous_sounds])].copy()\n",
    "    counts = df_a.groupby(subject_col)[sound_col].nunique()\n",
    "    keep_subjects = counts[counts >= 2].index.tolist()\n",
    "\n",
    "    print(\"\\n[MODULE D-2] Individual-difference scores (ambiguous set)\")\n",
    "    print(f\"  Exclude subjects with ambig trials < 2: {df_ss[subject_col].nunique()} -> {len(keep_subjects)}\")\n",
    "\n",
    "    df_a = df_a[df_a[subject_col].isin(keep_subjects)].copy()\n",
    "\n",
    "    pivot = df_a.pivot_table(index=subject_col, columns=sound_col, values=pc2, aggfunc=\"mean\")\n",
    "    pivot = pivot.reindex(columns=[str(s) for s in ambiguous_sounds])\n",
    "    pivot = pivot.apply(lambda col: col.fillna(col.mean()), axis=0)\n",
    "\n",
    "    ambig_pc2_mad = pivot.apply(lambda row: mad(row.to_numpy()), axis=1).rename(\"ambig_pc2_mad\")\n",
    "\n",
    "    X = pivot.to_numpy(dtype=float)\n",
    "    Xz = StandardScaler().fit_transform(X)\n",
    "    pca = PCA(n_components=min(3, Xz.shape[1]))\n",
    "    pcs = pca.fit_transform(Xz)\n",
    "\n",
    "    pca_info = {f\"PC{i+1}\": float(pca.explained_variance_ratio_[i]) for i in range(pcs.shape[1])}\n",
    "    print(\"  PCA explained variance ratio:\")\n",
    "    for k, v in pca_info.items():\n",
    "        print(f\"    {k}: {v:.3f}\")\n",
    "\n",
    "    df_scores = pd.DataFrame({\n",
    "        subject_col: pivot.index.astype(str),\n",
    "        \"ambig_pc2_mad\": ambig_pc2_mad.values,\n",
    "        \"ambig_pc2_mean\": pivot.mean(axis=1).values,\n",
    "        \"ambig_pc2_sd\": pivot.std(axis=1, ddof=1).values,\n",
    "    })\n",
    "    for i in range(pcs.shape[1]):\n",
    "        df_scores[f\"ambig_PC{i+1}\"] = pcs[:, i]\n",
    "\n",
    "    out_scores = cfg.tab_dir / \"moduleD_individual_difference_scores.csv\"\n",
    "    save_csv(df_scores, out_scores)\n",
    "\n",
    "    return df_scores, pca_info\n",
    "\n",
    "\n",
    "def merge_subject_eeg(\n",
    "    cfg: Config,\n",
    "    df_subj: pd.DataFrame,\n",
    "    df_scores: pd.DataFrame,\n",
    ") -> Tuple[pd.DataFrame, List[str]]:\n",
    "    \"\"\"\n",
    "    D-3: merge subject-level EEG + indiv scores.\n",
    "    \"\"\"\n",
    "    subject_col = cfg.subject_col\n",
    "\n",
    "    if cfg.eeg_cols is None:\n",
    "        eeg_cols = [c for c in df_subj.columns if isinstance(c, str) and (c.startswith(\"ERP_\") or c.startswith(\"SPN_\"))]\n",
    "    else:\n",
    "        eeg_cols = [c for c in cfg.eeg_cols if c in df_subj.columns]\n",
    "\n",
    "    if len(eeg_cols) == 0:\n",
    "        raise ValueError(\"No EEG feature columns detected. Provide --eeg-cols or ensure subject CSV contains ERP_/SPN_ columns.\")\n",
    "\n",
    "    df_subj_small = df_subj[[subject_col] + eeg_cols].copy()\n",
    "\n",
    "    # dtype safety (prevents merge object/int64 crash)\n",
    "    df_scores = df_scores.copy()\n",
    "    df_scores[subject_col] = df_scores[subject_col].astype(str)\n",
    "    df_subj_small[subject_col] = df_subj_small[subject_col].astype(str)\n",
    "\n",
    "    df_merged = pd.merge(df_scores, df_subj_small, on=subject_col, how=\"inner\")\n",
    "\n",
    "    print(\"\\n[MODULE D-3] Merge subject EEG + indiv scores\")\n",
    "    print(f\"  merged: {df_merged.shape}\")\n",
    "\n",
    "    print(\"\\n[MODULE D-3] EEG feature columns\")\n",
    "    print(f\"  n_eeg_cols = {len(eeg_cols)}\")\n",
    "    print(f\"  head: {eeg_cols[:10]}\")\n",
    "\n",
    "    return df_merged, eeg_cols\n",
    "\n",
    "\n",
    "def spearman_perm_test(\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    n_perm: int,\n",
    "    rng: np.random.Generator,\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Two-sided Spearman correlation with permutation p-value.\"\"\"\n",
    "    rho_obs, _ = spearmanr(x, y)\n",
    "    if np.isnan(rho_obs):\n",
    "        return float(\"nan\"), float(\"nan\")\n",
    "\n",
    "    y = np.asarray(y)\n",
    "    count = 0\n",
    "    for _ in range(n_perm):\n",
    "        yp = rng.permutation(y)\n",
    "        rho_p, _ = spearmanr(x, yp)\n",
    "        if np.isnan(rho_p):\n",
    "            continue\n",
    "        if abs(rho_p) >= abs(rho_obs):\n",
    "            count += 1\n",
    "    p_perm = (count + 1) / (n_perm + 1)\n",
    "    return float(rho_obs), float(p_perm)\n",
    "\n",
    "\n",
    "def bootstrap_ci_spearman(\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    n_boot: int,\n",
    "    rng: np.random.Generator,\n",
    "    alpha: float = 0.05,\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Bootstrap percentile CI for Spearman rho.\"\"\"\n",
    "    n = len(x)\n",
    "    rhos = []\n",
    "    idx = np.arange(n)\n",
    "    for _ in range(n_boot):\n",
    "        b = rng.choice(idx, size=n, replace=True)\n",
    "        rb, _ = spearmanr(x[b], y[b])\n",
    "        if np.isnan(rb):\n",
    "            continue\n",
    "        rhos.append(rb)\n",
    "    if len(rhos) == 0:\n",
    "        return float(\"nan\"), float(\"nan\")\n",
    "    lo = float(np.quantile(rhos, alpha / 2))\n",
    "    hi = float(np.quantile(rhos, 1 - alpha / 2))\n",
    "    return lo, hi\n",
    "\n",
    "\n",
    "def association_analysis(\n",
    "    cfg: Config,\n",
    "    df_merged: pd.DataFrame,\n",
    "    eeg_cols: List[str],\n",
    "    target_col: str = \"ambig_pc2_mad\",\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Spearman + permutation + bootstrap CI + FDR.\n",
    "    Saves:\n",
    "      - moduleD_eeg_association_spearman_perm.csv\n",
    "      - moduleD_PRIMARY_results_with_bootstrapCI.csv\n",
    "    \"\"\"\n",
    "    y = df_merged[target_col].to_numpy(dtype=float)\n",
    "\n",
    "    rows = []\n",
    "    for feat in eeg_cols:\n",
    "        rng_feat = np.random.default_rng(stable_seed(cfg.seed, feat))  # stable per feature\n",
    "        x = df_merged[feat].to_numpy(dtype=float)\n",
    "\n",
    "        rho, p_perm = spearman_perm_test(x, y, cfg.n_perm, rng_feat)\n",
    "        ci_lo, ci_hi = bootstrap_ci_spearman(x, y, cfg.n_boot, rng_feat)\n",
    "\n",
    "        rows.append({\n",
    "            \"target\": target_col,\n",
    "            \"feature\": feat,\n",
    "            \"n\": int(np.sum(~np.isnan(x) & ~np.isnan(y))),\n",
    "            \"spearman_rho\": rho,\n",
    "            \"p_perm\": p_perm,\n",
    "            \"ci95_lo\": ci_lo,\n",
    "            \"ci95_hi\": ci_hi,\n",
    "        })\n",
    "\n",
    "    res = pd.DataFrame(rows).sort_values(\"p_perm\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "    pvals = res[\"p_perm\"].to_numpy(dtype=float)\n",
    "    _rej, qvals, _, _ = multipletests(pvals, alpha=0.05, method=\"fdr_bh\")\n",
    "    res[\"q_fdr_primary\"] = qvals\n",
    "\n",
    "    out_all = cfg.tab_dir / \"moduleD_eeg_association_spearman_perm.csv\"\n",
    "    out_primary = cfg.tab_dir / \"moduleD_PRIMARY_results_with_bootstrapCI.csv\"\n",
    "    save_csv(res, out_all)\n",
    "    save_csv(res.sort_values([\"q_fdr_primary\", \"p_perm\", \"feature\"], ascending=[True, True, True]).reset_index(drop=True), out_primary)\n",
    "\n",
    "    primary = pd.read_csv(out_primary)\n",
    "    print(primary.head(12))\n",
    "\n",
    "    return res, primary\n",
    "\n",
    "\n",
    "def robustness_leave1(\n",
    "    cfg: Config,\n",
    "    df_merged: pd.DataFrame,\n",
    "    assoc_table: pd.DataFrame,\n",
    "    eeg_cols: List[str],\n",
    "    target_col: str = \"ambig_pc2_mad\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Leave-one-subject-out robustness for significant/near-significant features.\n",
    "    Saves: moduleD_PRIMARY_robustness_leave1.csv\n",
    "    \"\"\"\n",
    "    sig = assoc_table[assoc_table[\"q_fdr_primary\"] < 0.05][\"feature\"].tolist()\n",
    "    if len(sig) == 0:\n",
    "        sig = assoc_table.sort_values(\"p_perm\").head(min(5, len(eeg_cols)))[\"feature\"].tolist()\n",
    "\n",
    "    subject_col = cfg.subject_col\n",
    "    subjects = df_merged[subject_col].astype(str).tolist()\n",
    "\n",
    "    rows = []\n",
    "    for leave in subjects:\n",
    "        df_lo = df_merged[df_merged[subject_col].astype(str) != str(leave)].copy()\n",
    "        y = df_lo[target_col].to_numpy(dtype=float)\n",
    "\n",
    "        for feat in sig:\n",
    "            x = df_lo[feat].to_numpy(dtype=float)\n",
    "            rho, _ = spearmanr(x, y)\n",
    "            rows.append({\n",
    "                \"leave_out_subject\": leave,\n",
    "                \"feature\": feat,\n",
    "                \"rho_leave1\": float(rho) if not np.isnan(rho) else float(\"nan\"),\n",
    "                \"n\": int(len(df_lo)),\n",
    "            })\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    out_path = cfg.tab_dir / \"moduleD_PRIMARY_robustness_leave1.csv\"\n",
    "    save_csv(out, out_path)\n",
    "    return out\n",
    "\n",
    "\n",
    "def specificity_overall_mad(\n",
    "    cfg: Config,\n",
    "    df_trial: pd.DataFrame,\n",
    "    df_merged: pd.DataFrame,\n",
    "    eeg_cols: List[str],\n",
    "    target_col: str = \"ambig_pc2_mad\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Specificity: compare associations with overall MAD across all sounds.\n",
    "    Saves: moduleD_PRIMARY_specificity_overallMAD.csv\n",
    "    \"\"\"\n",
    "    subject_col = cfg.subject_col\n",
    "    sound_col = cfg.sound_col\n",
    "    pc2 = cfg.pc2_col\n",
    "\n",
    "    df_ss = aggregate_subject_sound(df_trial, subject_col, sound_col, [pc2])\n",
    "    overall = (\n",
    "        df_ss\n",
    "        .groupby(subject_col)[pc2]\n",
    "        .apply(lambda s: mad(s.to_numpy(dtype=float)))\n",
    "        .rename(\"overall_pc2_mad\")\n",
    "        .reset_index()\n",
    "    )\n",
    "    overall[subject_col] = overall[subject_col].astype(str)\n",
    "\n",
    "    df2 = pd.merge(df_merged[[subject_col, target_col] + eeg_cols], overall, on=subject_col, how=\"inner\")\n",
    "\n",
    "    rows = []\n",
    "    for feat in eeg_cols:\n",
    "        x = df2[feat].to_numpy(dtype=float)\n",
    "\n",
    "        rng_a = np.random.default_rng(stable_seed(cfg.seed + 999, feat + \"_ambig\"))\n",
    "        rng_o = np.random.default_rng(stable_seed(cfg.seed + 1999, feat + \"_overall\"))\n",
    "\n",
    "        rho_a, p_a = spearman_perm_test(x, df2[target_col].to_numpy(dtype=float), cfg.n_perm, rng_a)\n",
    "        rho_o, p_o = spearman_perm_test(x, df2[\"overall_pc2_mad\"].to_numpy(dtype=float), cfg.n_perm, rng_o)\n",
    "\n",
    "        rows.append({\n",
    "            \"feature\": feat,\n",
    "            \"rho_ambigMAD\": rho_a, \"p_ambigMAD\": p_a,\n",
    "            \"rho_overallMAD\": rho_o, \"p_overallMAD\": p_o,\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(rows).sort_values(\"p_ambigMAD\", ascending=True).reset_index(drop=True)\n",
    "    out_path = cfg.tab_dir / \"moduleD_PRIMARY_specificity_overallMAD.csv\"\n",
    "    save_csv(out, out_path)\n",
    "    return out\n",
    "\n",
    "\n",
    "def loso_ambiguous_stability(\n",
    "    cfg: Config,\n",
    "    df_trial: pd.DataFrame,\n",
    "    full_ambiguous: List[str],\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, Optional[Path], Optional[Path]]:\n",
    "    \"\"\"\n",
    "    LOSO stability of ambiguous set:\n",
    "      - each fold: recompute ambiguous sounds leaving one subject out\n",
    "      - jaccard with full set\n",
    "      - selection frequency across folds\n",
    "    Saves:\n",
    "      - moduleD_ambiguous_set_stability_LOSO.csv\n",
    "      - moduleD_ambiguous_set_selection_frequency_LOSO.csv\n",
    "      - figures: moduleD_LOSO_selection_frequency.png, moduleD_LOSO_jaccard_hist.png\n",
    "    \"\"\"\n",
    "    subject_col = cfg.subject_col\n",
    "    subjects = sorted(df_trial[subject_col].astype(str).unique().tolist())\n",
    "\n",
    "    fold_rows = []\n",
    "    freq = Counter()\n",
    "    jacs = []\n",
    "\n",
    "    for leave in subjects:\n",
    "        df_lo = df_trial[df_trial[subject_col].astype(str) != str(leave)].copy()\n",
    "        _stats_lo, amb_lo = define_ambiguous_sounds(cfg, df_lo, save_path=None, verbose=False)\n",
    "\n",
    "        jac = jaccard([str(s) for s in full_ambiguous], [str(s) for s in amb_lo])\n",
    "        jacs.append(jac)\n",
    "\n",
    "        fold_rows.append({\n",
    "            \"leave_out_subject\": leave,\n",
    "            \"n_subjects\": int(df_lo[subject_col].nunique()),\n",
    "            \"jaccard_with_full\": jac,\n",
    "            \"ambiguous_set\": \",\".join([str(s) for s in amb_lo]),\n",
    "        })\n",
    "        for sid in amb_lo:\n",
    "            freq[str(sid)] += 1\n",
    "\n",
    "    stab = pd.DataFrame(fold_rows)\n",
    "    out_stab = cfg.tab_dir / \"moduleD_ambiguous_set_stability_LOSO.csv\"\n",
    "    save_csv(stab, out_stab)\n",
    "\n",
    "    freq_df = pd.DataFrame({\n",
    "        \"sound_id\": list(freq.keys()),\n",
    "        \"selected_count\": list(freq.values()),\n",
    "    })\n",
    "    freq_df[\"selected_ratio\"] = freq_df[\"selected_count\"] / len(subjects)\n",
    "    freq_df[\"n_folds\"] = len(subjects)\n",
    "    freq_df = freq_df.sort_values([\"selected_count\", \"sound_id\"], ascending=[False, True]).reset_index(drop=True)\n",
    "\n",
    "    out_freq = cfg.tab_dir / \"moduleD_ambiguous_set_selection_frequency_LOSO.csv\"\n",
    "    save_csv(freq_df, out_freq)\n",
    "\n",
    "    fig_freq = None\n",
    "    fig_jac = None\n",
    "    if cfg.make_figures:\n",
    "        # selection frequency\n",
    "        fig_freq = cfg.fig_dir / \"moduleD_LOSO_selection_frequency.png\"\n",
    "        plt.figure()\n",
    "        plt.bar(freq_df[\"sound_id\"].astype(str), freq_df[\"selected_count\"].to_numpy())\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.xlabel(\"sound_id\")\n",
    "        plt.ylabel(\"selected_count (across LOSO folds)\")\n",
    "        plt.title(\"LOSO ambiguous set selection frequency\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fig_freq, dpi=200)\n",
    "        plt.close()\n",
    "        print(f\"[SAVE] {fig_freq}\")\n",
    "\n",
    "        # jaccard hist\n",
    "        fig_jac = cfg.fig_dir / \"moduleD_LOSO_jaccard_hist.png\"\n",
    "        plt.figure()\n",
    "        plt.hist(np.asarray(jacs, dtype=float), bins=8)\n",
    "        plt.xlabel(\"Jaccard with full ambiguous set\")\n",
    "        plt.ylabel(\"count\")\n",
    "        plt.title(\"LOSO stability (Jaccard) histogram\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fig_jac, dpi=200)\n",
    "        plt.close()\n",
    "        print(f\"[SAVE] {fig_jac}\")\n",
    "\n",
    "    return stab, freq_df, fig_freq, fig_jac\n",
    "\n",
    "\n",
    "def make_scatter_plots_top_assoc(\n",
    "    cfg: Config,\n",
    "    df_merged: pd.DataFrame,\n",
    "    primary: pd.DataFrame,\n",
    "    target_col: str = \"ambig_pc2_mad\",\n",
    ") -> List[Path]:\n",
    "    \"\"\"Make scatter plots for top N associations (slide-ready).\"\"\"\n",
    "    if not cfg.make_figures:\n",
    "        return []\n",
    "    if primary is None or len(primary) == 0:\n",
    "        return []\n",
    "\n",
    "    top = primary.sort_values([\"q_fdr_primary\", \"p_perm\"], ascending=[True, True]).head(cfg.n_scatter_top)\n",
    "    paths: List[Path] = []\n",
    "\n",
    "    y = df_merged[target_col].to_numpy(dtype=float)\n",
    "    for _, row in top.iterrows():\n",
    "        feat = str(row[\"feature\"])\n",
    "        x = df_merged[feat].to_numpy(dtype=float)\n",
    "\n",
    "        fig_path = cfg.fig_dir / f\"moduleD_scatter_{feat}.png\"\n",
    "        plt.figure()\n",
    "        plt.scatter(x, y)\n",
    "        plt.xlabel(feat)\n",
    "        plt.ylabel(target_col)\n",
    "        title = f\"{feat} vs {target_col} (rho={row['spearman_rho']:.3f}, p_perm={row['p_perm']:.4f}, q={row['q_fdr_primary']:.4f})\"\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fig_path, dpi=220)\n",
    "        plt.close()\n",
    "        print(f\"[SAVE] {fig_path}\")\n",
    "        paths.append(fig_path)\n",
    "\n",
    "    return paths\n",
    "\n",
    "\n",
    "def build_next_actions_outputs(\n",
    "    cfg: Config,\n",
    "    stab: pd.DataFrame,\n",
    "    freq: pd.DataFrame,\n",
    "    primary: pd.DataFrame,\n",
    ") -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    Creates:\n",
    "      - moduleD_KEYNUMBERS.json\n",
    "      - moduleD_NEXT_ACTIONS.md\n",
    "      - moduleD_SLIDE_BULLETS.txt\n",
    "    Returns keynumbers dict.\n",
    "    \"\"\"\n",
    "    # key numbers\n",
    "    j_mean = float(stab[\"jaccard_with_full\"].mean()) if len(stab) else float(\"nan\")\n",
    "    j_min = float(stab[\"jaccard_with_full\"].min()) if len(stab) else float(\"nan\")\n",
    "    j_max = float(stab[\"jaccard_with_full\"].max()) if len(stab) else float(\"nan\")\n",
    "\n",
    "    top_sounds = freq.sort_values([\"selected_count\", \"sound_id\"], ascending=[False, True]).head(15).copy()\n",
    "    top_assoc = primary.sort_values([\"q_fdr_primary\", \"p_perm\"], ascending=[True, True]).head(10).copy()\n",
    "\n",
    "    keynumbers = {\n",
    "        \"loso_jaccard_mean\": j_mean,\n",
    "        \"loso_jaccard_min\": j_min,\n",
    "        \"loso_jaccard_max\": j_max,\n",
    "        \"top_selection_frequency\": top_sounds.to_dict(orient=\"records\"),\n",
    "        \"top_eeg_associations\": top_assoc.to_dict(orient=\"records\"),\n",
    "    }\n",
    "\n",
    "    out_key = cfg.tab_dir / \"moduleD_KEYNUMBERS.json\"\n",
    "    save_json(keynumbers, out_key)\n",
    "\n",
    "    # markdown (no tabulate)\n",
    "    md = []\n",
    "    md.append(\"# Module D: 次アクション（自動生成）\\n\")\n",
    "    md.append(\"## 1) LOSO stability（曖昧音集合の安定性）\\n\")\n",
    "    md.append(f\"- Jaccard mean: **{j_mean:.3f}**\\n\")\n",
    "    md.append(f\"- Jaccard min : **{j_min:.3f}**\\n\")\n",
    "    md.append(f\"- Jaccard max : **{j_max:.3f}**\\n\\n\")\n",
    "\n",
    "    md.append(\"## 2) 曖昧音の選抜頻度（top 15）\\n\")\n",
    "    md.append(df_to_markdown_pipe(top_sounds, max_rows=15))\n",
    "    md.append(\"\\n\")\n",
    "\n",
    "    md.append(\"## 3) EEG関連（top 10）\\n\")\n",
    "    cols = [\"target\", \"feature\", \"n\", \"spearman_rho\", \"p_perm\", \"q_fdr_primary\", \"ci95_lo\", \"ci95_hi\"]\n",
    "    cols = [c for c in cols if c in top_assoc.columns]\n",
    "    md.append(df_to_markdown_pipe(top_assoc[cols], max_rows=10))\n",
    "    md.append(\"\\n\")\n",
    "\n",
    "    md.append(\"## 4) 今すぐ“成果物として強くする”ための実務アクション\\n\")\n",
    "    md.append(\"- **感度分析**：neutral_th（例 0.25/0.35/0.45）と top_k（例 8/10/12）で結果の頑健性を確認。\\n\")\n",
    "    md.append(\"- **再現性**：Permutation/Bootstrap は feature 名から固定 seed を作る（本コードは対応済）。\\n\")\n",
    "    md.append(\"- **図の最適化**：上位4特徴の散布図＋ρ/p/qをスライドに直貼り。\\n\")\n",
    "\n",
    "    out_md = cfg.tab_dir / \"moduleD_NEXT_ACTIONS.md\"\n",
    "    save_text(\"\".join(md), out_md)\n",
    "\n",
    "    # slide bullets\n",
    "    bullets = []\n",
    "    bullets.append(\"【Module D：スライド用 要点】\\n\")\n",
    "    bullets.append(f\"- 曖昧音集合のLOSO安定性：Jaccard mean={j_mean:.3f}（min={j_min:.3f}, max={j_max:.3f}）\\n\")\n",
    "    bullets.append(\"- 曖昧音（頻出）例：\\n\")\n",
    "    for r in top_sounds.head(10).to_dict(orient=\"records\"):\n",
    "        bullets.append(f\"  - {r['sound_id']}：{int(r['selected_count'])}/{int(r['n_folds'])}\\n\")\n",
    "    bullets.append(\"- 個人差指標：ambig_pc2_mad（曖昧音集合内PC2のMAD）\\n\")\n",
    "    bullets.append(\"- EEG関連（FDR通過）：\\n\")\n",
    "    for r in top_assoc.head(4).to_dict(orient=\"records\"):\n",
    "        bullets.append(\n",
    "            f\"  - {r['feature']}: rho={float(r['spearman_rho']):.3f}, p_perm={float(r['p_perm']):.4f}, q={float(r['q_fdr_primary']):.4f}\\n\"\n",
    "        )\n",
    "    bullets.append(\"- 解釈：曖昧音で“評価が揺れる”人ほど、FC優位の初期〜中期ERP成分（N1/N2/P2）に系統的差が見える。\\n\")\n",
    "\n",
    "    out_txt = cfg.tab_dir / \"moduleD_SLIDE_BULLETS.txt\"\n",
    "    save_text(\"\".join(bullets), out_txt)\n",
    "\n",
    "    return keynumbers\n",
    "\n",
    "\n",
    "def save_metadata(cfg: Config, extra: dict) -> None:\n",
    "    meta = {\n",
    "        \"timestamp\": now_str(),\n",
    "        \"python\": sys.version,\n",
    "        \"platform\": platform.platform(),\n",
    "        \"cfg\": {k: str(v) if isinstance(v, Path) else v for k, v in asdict(cfg).items()},\n",
    "        \"extra\": extra,\n",
    "    }\n",
    "    out = cfg.log_dir / \"moduleD_metadata.json\"\n",
    "    save_json(meta, out)\n",
    "\n",
    "\n",
    "def next_actions_summary_print(cfg: Config) -> None:\n",
    "    \"\"\"Console summary only (files already saved elsewhere).\"\"\"\n",
    "    stab_path = cfg.tab_dir / \"moduleD_ambiguous_set_stability_LOSO.csv\"\n",
    "    freq_path = cfg.tab_dir / \"moduleD_ambiguous_set_selection_frequency_LOSO.csv\"\n",
    "    primary_path = cfg.tab_dir / \"moduleD_PRIMARY_results_with_bootstrapCI.csv\"\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 72)\n",
    "    print(\"4) 今すぐ“成果物として強くする”ための次アクション（自動要約）\")\n",
    "    print(\"=\" * 72)\n",
    "\n",
    "    if stab_path.exists():\n",
    "        stab = pd.read_csv(stab_path)\n",
    "        if \"jaccard_with_full\" in stab.columns and len(stab) > 0:\n",
    "            print(f\"[NEXT] LOSO Jaccard mean: {stab['jaccard_with_full'].mean():.3f}\")\n",
    "            print(f\"[NEXT] LOSO Jaccard min : {stab['jaccard_with_full'].min():.3f}\")\n",
    "            print(f\"[NEXT] LOSO Jaccard max : {stab['jaccard_with_full'].max():.3f}\")\n",
    "        else:\n",
    "            print(\"[NEXT] LOSO stability table found, but missing jaccard_with_full.\")\n",
    "    else:\n",
    "        print(\"[NEXT] LOSO stability table not found.\")\n",
    "\n",
    "    if freq_path.exists():\n",
    "        freq = pd.read_csv(freq_path).sort_values([\"selected_count\", \"sound_id\"], ascending=[False, True])\n",
    "        print(\"\\n[NEXT] Top selection frequency sounds (head 15):\")\n",
    "        print(freq.head(15).to_string(index=False))\n",
    "    else:\n",
    "        print(\"[NEXT] LOSO selection frequency table not found.\")\n",
    "\n",
    "    if primary_path.exists():\n",
    "        prim = pd.read_csv(primary_path).sort_values([\"q_fdr_primary\", \"p_perm\"], ascending=[True, True])\n",
    "        print(\"\\n[NEXT] Top EEG associations (head 10):\")\n",
    "        cols = [\"target\", \"feature\", \"n\", \"spearman_rho\", \"p_perm\", \"q_fdr_primary\", \"ci95_lo\", \"ci95_hi\"]\n",
    "        cols = [c for c in cols if c in prim.columns]\n",
    "        print(prim[cols].head(10).to_string(index=False))\n",
    "    else:\n",
    "        print(\"[NEXT] PRIMARY results table not found.\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Runner\n",
    "# =========================\n",
    "def run_moduleD(cfg: Config) -> None:\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Load (minimal + dtype-safe)\n",
    "    df_trial, df_subj, rating_cols = load_inputs(cfg)\n",
    "\n",
    "    # Align sign\n",
    "    df_trial_aligned, sign, loadings = align_pc2_sign(cfg, df_trial, rating_cols)\n",
    "\n",
    "    # D-1 full ambiguous set (save once)\n",
    "    stats_path = cfg.tab_dir / \"moduleD_ambiguous_sounds_stats.csv\"\n",
    "    stats, ambiguous = define_ambiguous_sounds(cfg, df_trial_aligned, save_path=stats_path, verbose=True)\n",
    "\n",
    "    # D-2 indiv scores\n",
    "    df_scores, pca_info = compute_individual_difference_scores(cfg, df_trial_aligned, ambiguous)\n",
    "\n",
    "    # D-3 merge EEG\n",
    "    df_merged, eeg_cols = merge_subject_eeg(cfg, df_subj, df_scores)\n",
    "\n",
    "    # Associations\n",
    "    assoc, primary = association_analysis(cfg, df_merged, eeg_cols, target_col=\"ambig_pc2_mad\")\n",
    "\n",
    "    # Robustness\n",
    "    _rob = robustness_leave1(cfg, df_merged, assoc, eeg_cols, target_col=\"ambig_pc2_mad\")\n",
    "\n",
    "    # Specificity\n",
    "    _spec = specificity_overall_mad(cfg, df_trial_aligned, df_merged, eeg_cols, target_col=\"ambig_pc2_mad\")\n",
    "\n",
    "    # D-4 LOSO stability\n",
    "    stab, freq, fig_freq, fig_jac = loso_ambiguous_stability(cfg, df_trial_aligned, ambiguous)\n",
    "\n",
    "    # Scatter plots for top EEG associations\n",
    "    scatter_paths = make_scatter_plots_top_assoc(cfg, df_merged, primary, target_col=\"ambig_pc2_mad\")\n",
    "\n",
    "    # Next actions pack (json + md + txt)\n",
    "    keynumbers = build_next_actions_outputs(cfg, stab, freq, primary)\n",
    "\n",
    "    # Metadata\n",
    "    save_metadata(cfg, extra={\n",
    "        \"pc2_aligned_sign\": sign,\n",
    "        \"inputs\": {\n",
    "            \"trial_csv\": str(cfg.trial_csv),\n",
    "            \"subject_csv\": str(cfg.subject_csv),\n",
    "        },\n",
    "        \"columns\": {\n",
    "            \"subject_col\": cfg.subject_col,\n",
    "            \"sound_col\": cfg.sound_col,\n",
    "            \"pc2_col\": cfg.pc2_col,\n",
    "            \"rating_cols\": rating_cols,\n",
    "            \"eeg_cols\": eeg_cols,\n",
    "        },\n",
    "        \"ambiguous_definition\": {\n",
    "            \"enough_ratio\": cfg.enough_ratio,\n",
    "            \"neutral_th\": cfg.neutral_th,\n",
    "            \"top_k\": cfg.top_k,\n",
    "            \"ambiguous_sounds\": [str(s) for s in ambiguous],\n",
    "        },\n",
    "        \"pca_explained_variance_ratio\": pca_info,\n",
    "        \"stats_params\": {\n",
    "            \"n_perm\": cfg.n_perm,\n",
    "            \"n_boot\": cfg.n_boot,\n",
    "            \"seed\": cfg.seed,\n",
    "        },\n",
    "        \"figures\": {\n",
    "            \"loso_freq\": str(fig_freq) if fig_freq else None,\n",
    "            \"loso_jaccard_hist\": str(fig_jac) if fig_jac else None,\n",
    "            \"scatter_paths\": [str(p) for p in scatter_paths],\n",
    "        },\n",
    "        \"keynumbers_path\": str(cfg.tab_dir / \"moduleD_KEYNUMBERS.json\"),\n",
    "    })\n",
    "\n",
    "    # Console summary\n",
    "    next_actions_summary_print(cfg)\n",
    "\n",
    "    print(\"\\n[MODULE D FINAL] DONE\")\n",
    "    print(f\"  outputs dir : {cfg.out_dir}\")\n",
    "    print(f\"  tables      : {cfg.tab_dir}\")\n",
    "    print(f\"  figures     : {cfg.fig_dir}\")\n",
    "    print(f\"  logs        : {cfg.log_dir}\")\n",
    "    print(f\"[TIME] total seconds: {time.time() - t0:.1f}\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# CLI\n",
    "# =========================\n",
    "def cli_main(argv: Optional[List[str]] = None) -> int:\n",
    "    parser = argparse.ArgumentParser(description=\"Module D: ambiguous sounds & individual differences + EEG association\")\n",
    "    parser.add_argument(\"--root-dir\", type=str, default=DEFAULT_ROOT)\n",
    "    parser.add_argument(\"--trial-csv\", type=str, default=None)\n",
    "    parser.add_argument(\"--subject-csv\", type=str, default=None)\n",
    "    parser.add_argument(\"--out-dir\", type=str, default=None)\n",
    "\n",
    "    parser.add_argument(\"--subject-col\", type=str, default=None)\n",
    "    parser.add_argument(\"--sound-col\", type=str, default=None)\n",
    "    parser.add_argument(\"--pc2-col\", type=str, default=\"PC2_emotion\")\n",
    "\n",
    "    parser.add_argument(\"--enough-ratio\", type=float, default=0.80)\n",
    "    parser.add_argument(\"--neutral-th\", type=float, default=0.35)\n",
    "    parser.add_argument(\"--top-k\", type=int, default=10)\n",
    "\n",
    "    parser.add_argument(\"--n-perm\", type=int, default=5000)\n",
    "    parser.add_argument(\"--n-boot\", type=int, default=5000)\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "\n",
    "    parser.add_argument(\"--no-minimal-load\", action=\"store_true\", help=\"Disable minimal loading (read all columns).\")\n",
    "    parser.add_argument(\"--no-fig\", action=\"store_true\", help=\"Disable figure outputs\")\n",
    "\n",
    "    args, _unknown = parser.parse_known_args(argv)\n",
    "\n",
    "    cfg = build_config(\n",
    "        root_dir=args.root_dir,\n",
    "        trial_csv=args.trial_csv,\n",
    "        subject_csv=args.subject_csv,\n",
    "        out_dir=args.out_dir,\n",
    "        subject_col=args.subject_col,\n",
    "        sound_col=args.sound_col,\n",
    "        pc2_col=args.pc2_col,\n",
    "        enough_ratio=args.enough_ratio,\n",
    "        neutral_th=args.neutral_th,\n",
    "        top_k=args.top_k,\n",
    "        n_perm=args.n_perm,\n",
    "        n_boot=args.n_boot,\n",
    "        seed=args.seed,\n",
    "        minimal_load=(not args.no_minimal_load),\n",
    "        make_figures=(not args.no_fig),\n",
    "    )\n",
    "\n",
    "    run_moduleD(cfg)\n",
    "    return 0\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Notebookで“うっかり実行”しても落ちにくい\n",
    "    if in_notebook():\n",
    "        cli_main([\"--root-dir\", DEFAULT_ROOT])\n",
    "    else:\n",
    "        raise SystemExit(cli_main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a6395f-4f7e-4c0a-82fc-87e6bdc02c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:EEG48]",
   "language": "python",
   "name": "conda-env-EEG48-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
