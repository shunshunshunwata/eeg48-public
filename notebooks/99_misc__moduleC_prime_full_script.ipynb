{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a91d0a12-3504-43c3-aefd-c2c656af89b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Module C FINALIZE (Single OUT + Wipe) START ===\n",
      "[CFG] ROOT_DIR=/Users/shunsuke/EEG_48sounds\n",
      "[CFG] OUT_DIR =/Users/shunsuke/EEG_48sounds/moduleC_outputs\n",
      "[CFG] EEG_DECONFOUND_WITH_ACOUSTICS=True\n",
      "[CFG] ACOUSTIC_USE_PCA=True ncomp=20\n",
      "[CFG] N_PERM=200 | ENC_TOPK=50 ENC_N_PERM=300\n",
      "[INFO] EEG feature list: n=1185\n",
      "[LOAD] master minimal usecols: 1189\n",
      "[LOAD] sound-level: /Users/shunsuke/EEG_48sounds/derivatives/master_tables/master_sound_level_with_PC.csv\n",
      "[INFO] Acoustic features (sound-level, leakage-safe): n=11424\n",
      "[INFO] merged df shape: (576, 12613)\n",
      "[INFO] Acoustic missing rate: 0.000000\n",
      "[INFO] EEG missing rate: 0.027004\n",
      "[INFO] n_acoustic_use=11424 n_eeg_use=1185\n",
      "\n",
      "--- Run: Module C Complete (LOSO + Perm + Deviation) ---\n",
      "[INFO] LOSO folds: 12 | target=PC1_emotion\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC1_emotion][01] held=P01 | R2(ac)=+0.2372 R2(full)=+0.1210 Δ=-0.1162\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC1_emotion][02] held=P02 | R2(ac)=+0.5513 R2(full)=+0.5537 Δ=+0.0025\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC1_emotion][03] held=P03 | R2(ac)=-1.5946 R2(full)=-1.5961 Δ=-0.0015\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC1_emotion][04] held=P04 | R2(ac)=+0.6311 R2(full)=+0.6127 Δ=-0.0184\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC1_emotion][05] held=P05 | R2(ac)=+0.4011 R2(full)=+0.3556 Δ=-0.0454\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC1_emotion][06] held=P06 | R2(ac)=+0.5786 R2(full)=+0.5769 Δ=-0.0017\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC1_emotion][07] held=P07 | R2(ac)=+0.1576 R2(full)=+0.1472 Δ=-0.0103\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC1_emotion][08] held=P08 | R2(ac)=+0.5534 R2(full)=+0.5493 Δ=-0.0040\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC1_emotion][09] held=P09 | R2(ac)=+0.6311 R2(full)=+0.6178 Δ=-0.0134\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC1_emotion][10] held=P10 | R2(ac)=+0.5205 R2(full)=+0.5026 Δ=-0.0179\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC1_emotion][11] held=P11 | R2(ac)=+0.5102 R2(full)=+0.5153 Δ=+0.0050\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC1_emotion][12] held=P12 | R2(ac)=+0.1645 R2(full)=-0.0570 Δ=-0.2215\n",
      "[STAT][PC1_emotion] Wilcoxon ΔR²_full vs 0: p=0.01221, stat=8.0\n",
      "[PERM] start n_perm=200 target=PC1_emotion | obs mean Δ=-0.0369\n",
      "  [PERM] t=50/200 count_ge_abs=5\n",
      "  [PERM] t=100/200 count_ge_abs=8\n",
      "  [PERM] t=150/200 count_ge_abs=12\n",
      "  [PERM] t=200/200 count_ge_abs=17\n",
      "[STAT][PC1_emotion] Permutation p(two-sided)=0.08955 | obs mean Δ=-0.0369\n",
      "[INFO] LOSO folds: 12 | target=PC2_emotion\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC2_emotion][01] held=P01 | R2(ac)=-0.0618 R2(full)=-0.0783 Δ=-0.0165\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC2_emotion][02] held=P02 | R2(ac)=+0.0871 R2(full)=-0.1732 Δ=-0.2604\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC2_emotion][03] held=P03 | R2(ac)=-2.4869 R2(full)=-1.8027 Δ=+0.6841\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC2_emotion][04] held=P04 | R2(ac)=+0.5630 R2(full)=+0.5267 Δ=-0.0363\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC2_emotion][05] held=P05 | R2(ac)=+0.5271 R2(full)=+0.5179 Δ=-0.0093\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC2_emotion][06] held=P06 | R2(ac)=-0.1893 R2(full)=-0.5327 Δ=-0.3434\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC2_emotion][07] held=P07 | R2(ac)=+0.2023 R2(full)=+0.1957 Δ=-0.0065\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC2_emotion][08] held=P08 | R2(ac)=+0.5031 R2(full)=+0.4583 Δ=-0.0448\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC2_emotion][09] held=P09 | R2(ac)=+0.5630 R2(full)=+0.5321 Δ=-0.0309\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC2_emotion][10] held=P10 | R2(ac)=+0.2166 R2(full)=+0.2211 Δ=+0.0045\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC2_emotion][11] held=P11 | R2(ac)=+0.5005 R2(full)=+0.5039 Δ=+0.0034\n",
      "[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: 32/1185\n",
      "[EEG][DECONF] dropped example: ['PLV_theta_T3T4_phaseC', 'COH_theta_T3T4_phaseC', 'PLV_theta_T3T4_phaseD', 'COH_theta_T3T4_phaseD', 'PLV_theta_T3T4_phaseE', 'COH_theta_T3T4_phaseE', 'PLV_theta_T3T4_phaseF', 'COH_theta_T3T4_phaseF', 'PLV_alpha_T3T4_phaseC', 'COH_alpha_T3T4_phaseC']\n",
      "[FOLD][PC2_emotion][12] held=P12 | R2(ac)=+0.3035 R2(full)=+0.4159 Δ=+0.1124\n",
      "[STAT][PC2_emotion] Wilcoxon ΔR²_full vs 0: p=0.2661, stat=24.0\n",
      "[PERM] start n_perm=200 target=PC2_emotion | obs mean Δ=+0.0047\n",
      "  [PERM] t=50/200 count_ge_abs=45\n",
      "  [PERM] t=100/200 count_ge_abs=94\n",
      "  [PERM] t=150/200 count_ge_abs=141\n",
      "  [PERM] t=200/200 count_ge_abs=184\n",
      "[STAT][PC2_emotion] Permutation p(two-sided)=0.9204 | obs mean Δ=+0.0047\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleC_outputs/tables/moduleC_complete_folds.csv\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleC_outputs/tables/moduleC_eeg_deviation_folds.csv\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleC_outputs/tables/moduleC_complete_permutation_summary.csv\n",
      "\n",
      "--- Make: Module C Summary + Figures ---\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleC_outputs/tables/moduleC_summary.csv\n",
      "\n",
      "--- Run: Encoding (Acoustic -> EEG sound-mean) ---\n",
      "[ENC] n_sounds=48 | X_raw=(48, 11424) | Y=(48, 1123) (kept EEG=1123)\n",
      "[ENC] best alpha=10000.0\n",
      "[ENC][PERM] TopK=50 N_PERM=300\n",
      "  [ENC][PERM] t=50/300\n",
      "  [ENC][PERM] t=100/300\n",
      "  [ENC][PERM] t=200/300\n",
      "  [ENC][PERM] t=300/300\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleC_outputs/tables/encoding_feature_r2.csv\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleC_outputs/tables/encoding_topk_with_p.csv\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleC_outputs/tables/encoding_summary.csv\n",
      "\n",
      "--- Optional: QC link (ModuleB trial EEG) ---\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleC_outputs/tables/qc_subject_qc_with_moduleC.csv\n",
      "\n",
      "--- Write: Reports ---\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleC_outputs/reports/ModuleC_task1_summary.md\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleC_outputs/reports/Encoding_text_template.md\n",
      "[SAVE] /Users/shunsuke/EEG_48sounds/moduleC_outputs/logs/moduleC_finalize_run.log\n",
      "=== Module C FINALIZE END ===\n",
      "Outputs saved under: /Users/shunsuke/EEG_48sounds/moduleC_outputs\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Module C Finalize (End-to-End) - Single OUT + Wipe\n",
    "==================================================\n",
    "\n",
    "What this script does (Task 1–3):\n",
    "1) Module C complete 結果の可視化と要約\n",
    "   - 被験者別 R² (Acoustic / Acoustic+Bias / Full)\n",
    "   - ΔR²(Full-Acoustic) ヒストグラム + permutation p\n",
    "   - Acoustic vs Full の散布図\n",
    "   - 要約テーブル（平均/中央値/良化人数/悪化人数/最良/最悪）\n",
    "\n",
    "2) “脳波で語れる”結果をCに追加：Acoustic → EEG Encoding（刺激駆動表現）\n",
    "   - sound-level acoustic features -> sound-mean EEG features\n",
    "   - LOO-CVで multi-output Ridge を実行\n",
    "   - EEG featureごとのR²分布 + Top20\n",
    "   - TopK featureだけ permutation で p値（現実的な計算量）\n",
    "\n",
    "3) “崩れる被験者”説明材料：QCリンク（ModuleB trial-level EEG特徴量があれば）\n",
    "   - 被験者ごとの trial-level EEG feature の NaN率\n",
    "   - Module C の ΔR² と関連を図示\n",
    "\n",
    "Run:\n",
    "  python moduleC_finalize_end_to_end.py --root_dir ... --out_dir_name moduleC_outputs --wipe_outdir 1\n",
    "\n",
    "Notes:\n",
    "- 音響特徴は sound-level table（leakage-safe）\n",
    "- EEG feature列は eeg_features_participant_sound.csv の列名を「正」として master から参照\n",
    "- Encoding permutation は TopK（default 50）だけに絞る\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import sys\n",
    "\n",
    "\n",
    "import argparse\n",
    "import shutil\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GroupKFold, LeaveOneOut\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Utils (safe)\n",
    "# =========================================================\n",
    "def ensure_dir(p: Path) -> None:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def safe_wipe_outdir(root: Path, out_dir: Path) -> None:\n",
    "    \"\"\"\n",
    "    OUT_DIR を削除して作り直す。\n",
    "    誤爆防止：out_dir が root 配下で、かつ名前が 'moduleC' を含むことを要求。\n",
    "    \"\"\"\n",
    "    out_dir = out_dir.resolve()\n",
    "    root = root.resolve()\n",
    "\n",
    "    if not str(out_dir).startswith(str(root) + str(Path(\"/\"))):\n",
    "        raise RuntimeError(f\"[WIPE][ABORT] OUT_DIR is not under ROOT_DIR.\\n  ROOT={root}\\n  OUT ={out_dir}\")\n",
    "\n",
    "    if \"modulec\" not in out_dir.name.lower():\n",
    "        raise RuntimeError(f\"[WIPE][ABORT] OUT_DIR name must contain 'moduleC'.\\n  OUT={out_dir}\")\n",
    "\n",
    "    if out_dir.exists():\n",
    "        shutil.rmtree(out_dir)\n",
    "    ensure_dir(out_dir)\n",
    "\n",
    "\n",
    "def numeric_cols(df: pd.DataFrame) -> List[str]:\n",
    "    return df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", str(s).lower())\n",
    "\n",
    "\n",
    "def pick_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:\n",
    "    \"\"\"Pick the first matching column by normalized name; fallback to contains-match.\"\"\"\n",
    "    norm_cols = {_norm(c): c for c in df.columns}\n",
    "    for cand in candidates:\n",
    "        key = _norm(cand)\n",
    "        if key in norm_cols:\n",
    "            return norm_cols[key]\n",
    "    for cand in candidates:\n",
    "        key = _norm(cand)\n",
    "        for n, orig in norm_cols.items():\n",
    "            if key and key in n:\n",
    "                return orig\n",
    "    return None\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Logger\n",
    "# =========================================================\n",
    "class Logger:\n",
    "    def __init__(self) -> None:\n",
    "        self.lines: List[str] = []\n",
    "\n",
    "    def log(self, msg: str) -> None:\n",
    "        print(msg)\n",
    "        self.lines.append(msg)\n",
    "\n",
    "    def save(self, path: Path) -> None:\n",
    "        ensure_dir(path.parent)\n",
    "        path.write_text(\"\\n\".join(self.lines), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Config\n",
    "# =========================================================\n",
    "@dataclass\n",
    "class Cfg:\n",
    "    ROOT_DIR: Path\n",
    "    OUT_DIR: Path\n",
    "\n",
    "    # --- Inputs ---\n",
    "    MASTER_PS: Path\n",
    "    MASTER_SOUND: Path\n",
    "    EEG_FEATURES_LIST: Path\n",
    "\n",
    "    # --- Optional QC link ---\n",
    "    MODULEB_TRIAL_EEG: Optional[Path] = None\n",
    "\n",
    "    # --- Columns ---\n",
    "    SUB_COL: str = \"subject\"\n",
    "    SOUND_COL: str = \"sound_id\"\n",
    "    EEG_SUB_COL: str = \"participant\"\n",
    "    EEG_SOUND_COL: str = \"number\"\n",
    "    TARGETS: Tuple[str, ...] = (\"PC1_emotion\", \"PC2_emotion\")\n",
    "\n",
    "    # --- Modeling ---\n",
    "    ALPHAS: Tuple[float, ...] = tuple(np.logspace(-3, 4, 24))\n",
    "    INNER_SPLITS: int = 5\n",
    "\n",
    "    EEG_DECONFOUND_WITH_ACOUSTICS: bool = True\n",
    "    ACOUSTIC_USE_PCA: bool = True\n",
    "    ACOUSTIC_PCA_NCOMP: int = 20\n",
    "\n",
    "    USE_STACKING_WEIGHT: bool = True\n",
    "    GAMMA_CLIP: Tuple[float, float] = (-2.0, 2.0)\n",
    "\n",
    "    N_PERM: int = 200\n",
    "    PERM_SEED: int = 123\n",
    "\n",
    "    ENC_TOPK: int = 50\n",
    "    ENC_N_PERM: int = 300\n",
    "    ENC_SEED: int = 7\n",
    "\n",
    "    SAVE_DPI: int = 220\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Models\n",
    "# =========================================================\n",
    "def build_ridge_pipe(alpha: float) -> Pipeline:\n",
    "    # solver=\"svd\" で singular matrix 系の警告を避けやすい\n",
    "    return Pipeline(steps=[\n",
    "        (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scale\", StandardScaler(with_mean=True, with_std=True)),\n",
    "        (\"ridge\", Ridge(alpha=float(alpha), solver=\"svd\"))\n",
    "    ])\n",
    "\n",
    "\n",
    "def tune_alpha_ridge(\n",
    "    X: np.ndarray, y: np.ndarray, groups: np.ndarray,\n",
    "    alphas: Tuple[float, ...], n_splits: int\n",
    ") -> float:\n",
    "    uniq = np.unique(groups)\n",
    "    k = min(len(uniq), n_splits)\n",
    "    if k < 2:\n",
    "        return float(alphas[len(alphas)//2])\n",
    "\n",
    "    gkf = GroupKFold(n_splits=k)\n",
    "    best_a, best_mse = None, np.inf\n",
    "    for a in alphas:\n",
    "        mses = []\n",
    "        for tr, va in gkf.split(X, y, groups):\n",
    "            m = build_ridge_pipe(float(a))\n",
    "            m.fit(X[tr], y[tr])\n",
    "            pred = m.predict(X[va])\n",
    "            mses.append(float(np.mean((y[va] - pred) ** 2)))\n",
    "        mse = float(np.mean(mses))\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_a = float(a)\n",
    "    return float(best_a)\n",
    "\n",
    "\n",
    "def oof_predict_ridge(\n",
    "    X: np.ndarray, y: np.ndarray, groups: np.ndarray,\n",
    "    alpha: float, n_splits: int\n",
    ") -> np.ndarray:\n",
    "    uniq = np.unique(groups)\n",
    "    k = min(len(uniq), n_splits)\n",
    "    if k < 2:\n",
    "        m = build_ridge_pipe(alpha)\n",
    "        m.fit(X, y)\n",
    "        return m.predict(X)\n",
    "\n",
    "    gkf = GroupKFold(n_splits=k)\n",
    "    pred = np.full_like(y, np.nan, dtype=float)\n",
    "    for tr, va in gkf.split(X, y, groups):\n",
    "        m = build_ridge_pipe(alpha)\n",
    "        m.fit(X[tr], y[tr])\n",
    "        pred[va] = m.predict(X[va])\n",
    "\n",
    "    if np.isnan(pred).any():\n",
    "        m = build_ridge_pipe(alpha)\n",
    "        m.fit(X, y)\n",
    "        pred[np.isnan(pred)] = m.predict(X)[np.isnan(pred)]\n",
    "    return pred\n",
    "\n",
    "\n",
    "def fit_predict_ridge(Xtr: np.ndarray, ytr: np.ndarray, Xte: np.ndarray, alpha: float) -> np.ndarray:\n",
    "    m = build_ridge_pipe(alpha)\n",
    "    m.fit(Xtr, ytr)\n",
    "    return m.predict(Xte)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Permutation helper\n",
    "# =========================================================\n",
    "def permute_rows_within_group(X: np.ndarray, groups: np.ndarray, rng: np.random.RandomState) -> np.ndarray:\n",
    "    Xp = X.copy()\n",
    "    for g in np.unique(groups):\n",
    "        idx = np.where(groups == g)[0]\n",
    "        if len(idx) <= 1:\n",
    "            continue\n",
    "        perm = rng.permutation(idx)\n",
    "        Xp[idx] = X[perm]\n",
    "    return Xp\n",
    "\n",
    "\n",
    "def drop_all_nan_cols(X: np.ndarray, colnames: List[str]) -> Tuple[np.ndarray, List[str], np.ndarray, List[str]]:\n",
    "    keep = []\n",
    "    dropped_names = []\n",
    "    for j in range(X.shape[1]):\n",
    "        if np.all(np.isnan(X[:, j])):\n",
    "            dropped_names.append(colnames[j])\n",
    "            continue\n",
    "        keep.append(j)\n",
    "    keep = np.array(keep, dtype=int)\n",
    "    kept_names = [colnames[j] for j in keep.tolist()]\n",
    "    return X[:, keep], kept_names, keep, dropped_names\n",
    "\n",
    "\n",
    "def impute_with_train_median(Xtr: np.ndarray, Xte: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    med = np.nanmedian(Xtr, axis=0)\n",
    "    tr = Xtr.copy()\n",
    "    te = Xte.copy()\n",
    "    it = np.where(np.isnan(tr))\n",
    "    tr[it] = np.take(med, it[1])\n",
    "    ie = np.where(np.isnan(te))\n",
    "    te[ie] = np.take(med, ie[1])\n",
    "    return tr, te\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Load & assemble\n",
    "# =========================================================\n",
    "def load_eeg_feature_names(cfg: Cfg, L: Logger) -> List[str]:\n",
    "    if not cfg.EEG_FEATURES_LIST.exists():\n",
    "        raise FileNotFoundError(f\"Missing: {cfg.EEG_FEATURES_LIST}\")\n",
    "    eeg = pd.read_csv(cfg.EEG_FEATURES_LIST)\n",
    "    num = numeric_cols(eeg)\n",
    "    eeg_cols = [c for c in num if c not in {cfg.EEG_SUB_COL, cfg.EEG_SOUND_COL}]\n",
    "    if len(eeg_cols) == 0:\n",
    "        raise ValueError(\"EEG feature list has no numeric feature columns.\")\n",
    "    L.log(f\"[INFO] EEG feature list: n={len(eeg_cols)}\")\n",
    "    return eeg_cols\n",
    "\n",
    "\n",
    "def load_master_minimal(cfg: Cfg, eeg_cols: List[str], L: Logger) -> pd.DataFrame:\n",
    "    if not cfg.MASTER_PS.exists():\n",
    "        raise FileNotFoundError(f\"Missing: {cfg.MASTER_PS}\")\n",
    "\n",
    "    header = pd.read_csv(cfg.MASTER_PS, nrows=0).columns.tolist()\n",
    "    need = [cfg.SUB_COL, cfg.SOUND_COL, *cfg.TARGETS]\n",
    "    need = [c for c in need if c in header]\n",
    "\n",
    "    eeg_in_master = [c for c in eeg_cols if c in header]\n",
    "    if len(eeg_in_master) == 0:\n",
    "        raise ValueError(\"None of EEG feature columns exist in MASTER_PS.\")\n",
    "    usecols = list(dict.fromkeys(need + eeg_in_master))\n",
    "\n",
    "    L.log(f\"[LOAD] master minimal usecols: {len(usecols)}\")\n",
    "    m = pd.read_csv(cfg.MASTER_PS, usecols=usecols)\n",
    "    m[cfg.SUB_COL] = m[cfg.SUB_COL].astype(str)\n",
    "    m[cfg.SOUND_COL] = m[cfg.SOUND_COL].astype(str)\n",
    "\n",
    "    for t in cfg.TARGETS:\n",
    "        if t not in m.columns:\n",
    "            raise ValueError(f\"MASTER_PS missing target: {t}\")\n",
    "    return m\n",
    "\n",
    "\n",
    "def load_sound(cfg: Cfg, L: Logger) -> pd.DataFrame:\n",
    "    if not cfg.MASTER_SOUND.exists():\n",
    "        raise FileNotFoundError(f\"Missing: {cfg.MASTER_SOUND}\")\n",
    "    L.log(f\"[LOAD] sound-level: {cfg.MASTER_SOUND}\")\n",
    "    s = pd.read_csv(cfg.MASTER_SOUND)\n",
    "    if cfg.SOUND_COL not in s.columns:\n",
    "        raise ValueError(\"MASTER_SOUND missing sound_id.\")\n",
    "    s[cfg.SOUND_COL] = s[cfg.SOUND_COL].astype(str)\n",
    "    return s\n",
    "\n",
    "\n",
    "def choose_acoustic_cols(cfg: Cfg, sound: pd.DataFrame, L: Logger) -> List[str]:\n",
    "    num = numeric_cols(sound)\n",
    "    exclude = {cfg.SOUND_COL, \"Unnamed: 0\", \"index\", \"number\"}\n",
    "    exclude |= set(cfg.TARGETS)\n",
    "    for c in sound.columns:\n",
    "        if c.endswith(\"_mean\"):\n",
    "            exclude.add(c)\n",
    "\n",
    "    cols = [c for c in num if c not in exclude]\n",
    "    cols = [c for c in cols if not sound[c].isna().all()]\n",
    "    L.log(f\"[INFO] Acoustic features (sound-level, leakage-safe): n={len(cols)}\")\n",
    "    return cols\n",
    "\n",
    "\n",
    "def assemble_df(\n",
    "    cfg: Cfg, master: pd.DataFrame, sound: pd.DataFrame,\n",
    "    acoustic_cols: List[str], eeg_cols: List[str], L: Logger\n",
    ") -> Tuple[pd.DataFrame, List[str], List[str]]:\n",
    "    ren = {c: f\"AC__{c}\" for c in acoustic_cols}\n",
    "    s_sub = sound[[cfg.SOUND_COL] + acoustic_cols].drop_duplicates(cfg.SOUND_COL).rename(columns=ren)\n",
    "    df = master.merge(s_sub, on=cfg.SOUND_COL, how=\"left\", validate=\"m:1\")\n",
    "\n",
    "    ac_use = [ren[c] for c in acoustic_cols]\n",
    "    eeg_use = [c for c in eeg_cols if c in df.columns]\n",
    "\n",
    "    miss_ac = float(df[ac_use].isna().mean().mean()) if ac_use else 1.0\n",
    "    miss_eeg = float(df[eeg_use].isna().mean().mean()) if eeg_use else 1.0\n",
    "    L.log(f\"[INFO] merged df shape: {df.shape}\")\n",
    "    L.log(f\"[INFO] Acoustic missing rate: {miss_ac:.6f}\")\n",
    "    L.log(f\"[INFO] EEG missing rate: {miss_eeg:.6f}\")\n",
    "    return df, ac_use, eeg_use\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# EEG deconfound (Xeeg <- Xac) within fold\n",
    "# =========================================================\n",
    "def build_acoustic_transform(cfg: Cfg) -> Pipeline:\n",
    "    steps = [\n",
    "        (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scale\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    ]\n",
    "    if cfg.ACOUSTIC_USE_PCA:\n",
    "        steps.append((\"pca\", PCA(\n",
    "            n_components=cfg.ACOUSTIC_PCA_NCOMP,\n",
    "            svd_solver=\"randomized\",\n",
    "            random_state=0\n",
    "        )))\n",
    "    return Pipeline(steps=steps)\n",
    "\n",
    "\n",
    "def deconfound_eeg_with_acoustics(\n",
    "    cfg: Cfg,\n",
    "    Xac_tr: np.ndarray,\n",
    "    Xac_te: np.ndarray,\n",
    "    Xeeg_tr: np.ndarray,\n",
    "    Xeeg_te: np.ndarray,\n",
    "    eeg_names: List[str],\n",
    "    L: Logger,\n",
    ") -> Tuple[np.ndarray, np.ndarray, List[str]]:\n",
    "    Xeeg_tr2, names2, keep_idx, dropped_names = drop_all_nan_cols(Xeeg_tr, eeg_names)\n",
    "    Xeeg_te2 = Xeeg_te[:, keep_idx]\n",
    "    if len(dropped_names) > 0:\n",
    "        L.log(f\"[EEG][DECONF] Dropping all-NaN EEG cols in TRAIN: {len(dropped_names)}/{len(eeg_names)}\")\n",
    "        L.log(f\"[EEG][DECONF] dropped example: {dropped_names[:10]}\")\n",
    "\n",
    "    Xeeg_tr2, Xeeg_te2 = impute_with_train_median(Xeeg_tr2, Xeeg_te2)\n",
    "\n",
    "    Xpipe = build_acoustic_transform(cfg)\n",
    "    Zac_tr = Xpipe.fit_transform(Xac_tr)\n",
    "    Zac_te = Xpipe.transform(Xac_te)\n",
    "\n",
    "    # solver=\"svd\" で安定寄り\n",
    "    m = Ridge(alpha=10.0, solver=\"svd\")\n",
    "    m.fit(Zac_tr, Xeeg_tr2)\n",
    "    Xeeg_tr_hat = m.predict(Zac_tr)\n",
    "    Xeeg_te_hat = m.predict(Zac_te)\n",
    "\n",
    "    Rtr = (Xeeg_tr2 - Xeeg_tr_hat).astype(np.float32)\n",
    "    Rte = (Xeeg_te2 - Xeeg_te_hat).astype(np.float32)\n",
    "    return Rtr, Rte, names2\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Module C Complete core (LOSO)\n",
    "# =========================================================\n",
    "def safe_wilcoxon_zero_test(x: np.ndarray) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Wilcoxon signed-rank test vs 0.\n",
    "    戻り値: (stat, pvalue)\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    x = x[~np.isnan(x)]\n",
    "    if len(x) < 3:\n",
    "        return np.nan, np.nan\n",
    "    # 全部0なら検定不能に近い → p=1 扱い\n",
    "    if np.all(np.abs(x) < 1e-12):\n",
    "        return 0.0, 1.0\n",
    "    try:\n",
    "        w = wilcoxon(x)\n",
    "        return float(w.statistic), float(w.pvalue)\n",
    "    except Exception:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "\n",
    "def run_moduleC_complete(\n",
    "    cfg: Cfg, df: pd.DataFrame, ac_cols: List[str], eeg_cols: List[str], L: Logger\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    subjects = df[cfg.SUB_COL].astype(str).values\n",
    "    uniq_sub = np.unique(subjects)\n",
    "\n",
    "    all_rows: List[Dict[str, object]] = []\n",
    "    dev_rows: List[Dict[str, object]] = []\n",
    "    perm_rows: List[Dict[str, object]] = []\n",
    "    rng_perm = np.random.RandomState(cfg.PERM_SEED)\n",
    "\n",
    "    for tgt in cfg.TARGETS:\n",
    "        L.log(f\"[INFO] LOSO folds: {len(uniq_sub)} | target={tgt}\")\n",
    "        fold_cache: List[Dict[str, object]] = []\n",
    "\n",
    "        for k, held in enumerate(uniq_sub, start=1):\n",
    "            te_mask = (subjects == held)\n",
    "            tr_mask = ~te_mask\n",
    "\n",
    "            tr = df.loc[tr_mask].copy()\n",
    "            te = df.loc[te_mask].copy()\n",
    "\n",
    "            y_tr = tr[tgt].astype(float).values\n",
    "            y_te = te[tgt].astype(float).values\n",
    "\n",
    "            Xac_tr = tr[ac_cols].replace([np.inf, -np.inf], np.nan).astype(np.float32).values\n",
    "            Xac_te = te[ac_cols].replace([np.inf, -np.inf], np.nan).astype(np.float32).values\n",
    "\n",
    "            Xeeg_tr = tr[eeg_cols].replace([np.inf, -np.inf], np.nan).astype(np.float32).values\n",
    "            Xeeg_te = te[eeg_cols].replace([np.inf, -np.inf], np.nan).astype(np.float32).values\n",
    "\n",
    "            g_tr = tr[cfg.SUB_COL].astype(str).values\n",
    "\n",
    "            # --- acoustic baseline ---\n",
    "            alpha_ac = tune_alpha_ridge(Xac_tr, y_tr, g_tr, cfg.ALPHAS, cfg.INNER_SPLITS)\n",
    "            yhat_tr_oof = oof_predict_ridge(Xac_tr, y_tr, g_tr, alpha_ac, cfg.INNER_SPLITS)\n",
    "            resid_tr = y_tr - yhat_tr_oof\n",
    "            yhat_ac_te = fit_predict_ridge(Xac_tr, y_tr, Xac_te, alpha_ac)\n",
    "\n",
    "            # --- acoustic + bias (補助指標) ---\n",
    "            subj_bias = pd.Series(resid_tr).groupby(tr[cfg.SUB_COL].astype(str).values).mean().to_dict()\n",
    "            bias_te = np.array([subj_bias.get(held, 0.0)] * len(y_te), dtype=float)\n",
    "            yhat_ac_bias_te = yhat_ac_te + bias_te\n",
    "\n",
    "            # --- EEG matrix (optionally deconfounded) ---\n",
    "            if cfg.EEG_DECONFOUND_WITH_ACOUSTICS:\n",
    "                Ee_tr, Ee_te, _ = deconfound_eeg_with_acoustics(\n",
    "                    cfg, Xac_tr, Xac_te, Xeeg_tr, Xeeg_te, eeg_cols, L\n",
    "                )\n",
    "            else:\n",
    "                Ee_tr, Ee_te = impute_with_train_median(Xeeg_tr, Xeeg_te)\n",
    "                Ee_tr = Ee_tr.astype(np.float32)\n",
    "                Ee_te = Ee_te.astype(np.float32)\n",
    "\n",
    "            # --- EEG -> residual(y) ---\n",
    "            alpha_eeg = tune_alpha_ridge(Ee_tr, resid_tr, g_tr, cfg.ALPHAS, cfg.INNER_SPLITS)\n",
    "            rhat_tr_oof = oof_predict_ridge(Ee_tr, resid_tr, g_tr, alpha_eeg, cfg.INNER_SPLITS)\n",
    "\n",
    "            if cfg.USE_STACKING_WEIGHT:\n",
    "                denom = float(np.dot(rhat_tr_oof, rhat_tr_oof)) + 1e-12\n",
    "                gamma = float(np.dot(resid_tr, rhat_tr_oof) / denom)\n",
    "                gamma = float(np.clip(gamma, cfg.GAMMA_CLIP[0], cfg.GAMMA_CLIP[1]))\n",
    "            else:\n",
    "                gamma = 1.0\n",
    "\n",
    "            rhat_te = fit_predict_ridge(Ee_tr, resid_tr, Ee_te, alpha_eeg)\n",
    "            yhat_full_te = yhat_ac_te + gamma * rhat_te\n",
    "\n",
    "            r2_ac = float(r2_score(y_te, yhat_ac_te))\n",
    "            r2_ac_bias = float(r2_score(y_te, yhat_ac_bias_te))\n",
    "            r2_full = float(r2_score(y_te, yhat_full_te))\n",
    "            delta = float(r2_full - r2_ac)\n",
    "\n",
    "            all_rows.append({\n",
    "                \"target\": tgt,\n",
    "                \"fold\": k,\n",
    "                \"held_out\": held,\n",
    "                \"r2_acoustic\": r2_ac,\n",
    "                \"r2_acoustic_plus_bias\": r2_ac_bias,\n",
    "                \"r2_full\": r2_full,\n",
    "                \"delta_r2_full\": delta,\n",
    "                \"alpha_ac\": float(alpha_ac),\n",
    "                \"alpha_eeg\": float(alpha_eeg),\n",
    "                \"gamma\": float(gamma),\n",
    "                \"n_test\": int(te_mask.sum()),\n",
    "            })\n",
    "\n",
    "            L.log(f\"[FOLD][{tgt}][{k:02d}] held={held} | R2(ac)={r2_ac:+.4f} R2(full)={r2_full:+.4f} Δ={delta:+.4f}\")\n",
    "\n",
    "            fold_cache.append({\n",
    "                \"held\": held,\n",
    "                \"y_te\": y_te.astype(float),\n",
    "                \"yhat_ac_te\": yhat_ac_te.astype(float),\n",
    "                \"resid_tr\": resid_tr.astype(float),\n",
    "                \"Ee_tr\": Ee_tr.astype(np.float32),\n",
    "                \"Ee_te\": Ee_te.astype(np.float32),\n",
    "                \"g_tr\": g_tr.astype(str),\n",
    "                \"g_te\": te[cfg.SUB_COL].astype(str).values,\n",
    "                \"alpha_eeg\": float(alpha_eeg),\n",
    "                \"gamma\": float(gamma),\n",
    "            })\n",
    "\n",
    "            # --- EEG deviation task (EEG only) ---\n",
    "            tr_sound_mean = tr.groupby(cfg.SOUND_COL)[tgt].mean().to_dict()\n",
    "            mean_te = te[cfg.SOUND_COL].map(tr_sound_mean).astype(float).values\n",
    "            # fallback（万一 unseen sound があってもクラッシュしない）\n",
    "            if np.isnan(mean_te).any():\n",
    "                mean_te[np.isnan(mean_te)] = float(np.nanmean(y_tr))\n",
    "\n",
    "            ydev_tr = y_tr - tr[cfg.SOUND_COL].map(tr_sound_mean).astype(float).values\n",
    "            ydev_te = y_te - mean_te\n",
    "\n",
    "            alpha_dev = tune_alpha_ridge(Ee_tr, ydev_tr, g_tr, cfg.ALPHAS, cfg.INNER_SPLITS)\n",
    "            ydev_hat = fit_predict_ridge(Ee_tr, ydev_tr, Ee_te, alpha_dev)\n",
    "            r2_dev = float(r2_score(ydev_te, ydev_hat))\n",
    "\n",
    "            dev_rows.append({\n",
    "                \"target\": tgt,\n",
    "                \"fold\": k,\n",
    "                \"held_out\": held,\n",
    "                \"r2_eeg_dev\": r2_dev,\n",
    "                \"alpha_eeg_dev\": float(alpha_dev),\n",
    "                \"n_test\": int(te_mask.sum()),\n",
    "            })\n",
    "\n",
    "        folds_df = pd.DataFrame([r for r in all_rows if r[\"target\"] == tgt])\n",
    "\n",
    "        stat, pval = safe_wilcoxon_zero_test(folds_df[\"delta_r2_full\"].values)\n",
    "        L.log(f\"[STAT][{tgt}] Wilcoxon ΔR²_full vs 0: p={pval:.4g}, stat={stat}\")\n",
    "\n",
    "        obs_mean = float(folds_df[\"delta_r2_full\"].mean())\n",
    "        count_ge = 0\n",
    "        perm_means = []\n",
    "\n",
    "        L.log(f\"[PERM] start n_perm={cfg.N_PERM} target={tgt} | obs mean Δ={obs_mean:+.4f}\")\n",
    "        for t in range(1, cfg.N_PERM + 1):\n",
    "            deltas = []\n",
    "            for fc in fold_cache:\n",
    "                Ee_tr_p = permute_rows_within_group(fc[\"Ee_tr\"], fc[\"g_tr\"], rng_perm)\n",
    "                Ee_te_p = permute_rows_within_group(fc[\"Ee_te\"], fc[\"g_te\"], rng_perm)\n",
    "\n",
    "                rhat_te_p = fit_predict_ridge(Ee_tr_p, fc[\"resid_tr\"], Ee_te_p, fc[\"alpha_eeg\"])\n",
    "                yhat_full_p = fc[\"yhat_ac_te\"] + fc[\"gamma\"] * rhat_te_p\n",
    "\n",
    "                r2_ac_p = float(r2_score(fc[\"y_te\"], fc[\"yhat_ac_te\"]))\n",
    "                r2_full_p = float(r2_score(fc[\"y_te\"], yhat_full_p))\n",
    "                deltas.append(r2_full_p - r2_ac_p)\n",
    "\n",
    "            m = float(np.mean(deltas))\n",
    "            perm_means.append(m)\n",
    "            if abs(m) >= abs(obs_mean):\n",
    "                count_ge += 1\n",
    "            if t in {50, 100, 150, 200}:\n",
    "                L.log(f\"  [PERM] t={t}/{cfg.N_PERM} count_ge_abs={count_ge}\")\n",
    "\n",
    "        p_two = float((count_ge + 1) / (cfg.N_PERM + 1))\n",
    "        perm_rows.append({\n",
    "            \"target\": tgt,\n",
    "            \"obs_mean_delta_r2_full\": obs_mean,\n",
    "            \"perm_mean\": float(np.mean(perm_means)),\n",
    "            \"p_two_sided\": p_two,\n",
    "            \"count_ge_abs\": int(count_ge),\n",
    "            \"n_perm\": int(cfg.N_PERM),\n",
    "        })\n",
    "        L.log(f\"[STAT][{tgt}] Permutation p(two-sided)={p_two:.4g} | obs mean Δ={obs_mean:+.4f}\")\n",
    "\n",
    "    return pd.DataFrame(all_rows), pd.DataFrame(dev_rows), pd.DataFrame(perm_rows)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Figures + Summary\n",
    "# =========================================================\n",
    "def save_moduleC_figs(cfg: Cfg, folds: pd.DataFrame, perm: pd.DataFrame, fig_dir: Path) -> None:\n",
    "    ensure_dir(fig_dir)\n",
    "\n",
    "    for tgt in sorted(folds[\"target\"].unique()):\n",
    "        d = folds[folds[\"target\"] == tgt].copy().sort_values(\"held_out\")\n",
    "\n",
    "        # R² by subject\n",
    "        x = np.arange(len(d))\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(x, d[\"r2_acoustic\"].values, marker=\"o\", label=\"Acoustic\")\n",
    "        plt.plot(x, d[\"r2_acoustic_plus_bias\"].values, marker=\"o\", label=\"Acoustic+Bias\")\n",
    "        plt.plot(x, d[\"r2_full\"].values, marker=\"o\", label=\"Full(+EEG residual)\")\n",
    "        plt.axhline(0, linewidth=1)\n",
    "        plt.xticks(x, d[\"held_out\"].astype(str).tolist(), rotation=45, ha=\"right\")\n",
    "        plt.ylabel(\"R² (held-out subject)\")\n",
    "        plt.title(f\"Module C: R² by subject ({tgt})\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fig_dir / f\"C_r2_by_subject_{tgt}.png\", dpi=cfg.SAVE_DPI, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "        # Δ histogram\n",
    "        p = float(perm.loc[perm[\"target\"] == tgt, \"p_two_sided\"].iloc[0])\n",
    "        obs = float(perm.loc[perm[\"target\"] == tgt, \"obs_mean_delta_r2_full\"].iloc[0])\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.hist(d[\"delta_r2_full\"].values, bins=12)\n",
    "        plt.axvline(0, linewidth=1)\n",
    "        plt.xlabel(\"ΔR² (Full − Acoustic)\")\n",
    "        plt.ylabel(\"Count (folds)\")\n",
    "        plt.title(f\"{tgt} ΔR²  mean={obs:+.3f}  perm p={p:.3f}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fig_dir / f\"C_delta_hist_{tgt}.png\", dpi=cfg.SAVE_DPI, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "        # Scatter\n",
    "        plt.figure(figsize=(5.2, 5.2))\n",
    "        plt.scatter(d[\"r2_acoustic\"].values, d[\"r2_full\"].values)\n",
    "        mn = float(np.nanmin(np.r_[d[\"r2_acoustic\"].values, d[\"r2_full\"].values]))\n",
    "        mx = float(np.nanmax(np.r_[d[\"r2_acoustic\"].values, d[\"r2_full\"].values]))\n",
    "        plt.plot([mn, mx], [mn, mx], linewidth=1)\n",
    "        plt.axhline(0, linewidth=1)\n",
    "        plt.axvline(0, linewidth=1)\n",
    "        for _, r in d.iterrows():\n",
    "            plt.text(float(r[\"r2_acoustic\"]), float(r[\"r2_full\"]), str(r[\"held_out\"]), fontsize=8)\n",
    "        plt.xlabel(\"R² Acoustic\")\n",
    "        plt.ylabel(\"R² Full\")\n",
    "        plt.title(f\"{tgt}: Acoustic vs Full\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fig_dir / f\"C_scatter_acoustic_vs_full_{tgt}.png\", dpi=cfg.SAVE_DPI, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def make_moduleC_summary(folds: pd.DataFrame, perm: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for tgt, d in folds.groupby(\"target\"):\n",
    "        dr = d[\"delta_r2_full\"].to_numpy(dtype=float)\n",
    "        rows.append({\n",
    "            \"target\": tgt,\n",
    "            \"n_folds\": int(len(d)),\n",
    "            \"mean_r2_acoustic\": float(np.mean(d[\"r2_acoustic\"])),\n",
    "            \"mean_r2_acoustic_plus_bias\": float(np.mean(d[\"r2_acoustic_plus_bias\"])),\n",
    "            \"mean_r2_full\": float(np.mean(d[\"r2_full\"])),\n",
    "            \"mean_delta_full\": float(np.mean(dr)),\n",
    "            \"median_delta_full\": float(np.median(dr)),\n",
    "            \"n_delta_pos\": int(np.sum(dr > 0)),\n",
    "            \"n_delta_neg\": int(np.sum(dr < 0)),\n",
    "            \"best_subject\": str(d.loc[d[\"delta_r2_full\"].idxmax(), \"held_out\"]),\n",
    "            \"best_delta\": float(d[\"delta_r2_full\"].max()),\n",
    "            \"worst_subject\": str(d.loc[d[\"delta_r2_full\"].idxmin(), \"held_out\"]),\n",
    "            \"worst_delta\": float(d[\"delta_r2_full\"].min()),\n",
    "        })\n",
    "    return pd.DataFrame(rows).merge(perm, on=\"target\", how=\"left\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Encoding: Acoustic -> EEG (sound-mean)  [LEAKAGE-SAFE]\n",
    "# =========================================================\n",
    "def build_X_pipe_fold(cfg: Cfg, n_train: int, n_features: int) -> Pipeline:\n",
    "    \"\"\"\n",
    "    LOOの各fold内でfitする前処理パイプライン。\n",
    "    PCAは fold内の訓練サンプル数・特徴数を超えないように自動でクリップする。\n",
    "    \"\"\"\n",
    "    steps = [\n",
    "        (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scale\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    ]\n",
    "    if cfg.ACOUSTIC_USE_PCA:\n",
    "        # PCAは n_components <= min(n_train-1, n_features) 必須\n",
    "        max_comp = min(int(cfg.ACOUSTIC_PCA_NCOMP), max(1, n_train - 1), int(n_features))\n",
    "        # n_trainが極端に小さいときはPCAを外す（安全運用）\n",
    "        if max_comp >= 1 and max_comp < n_features:\n",
    "            steps.append((\"pca\", PCA(\n",
    "                n_components=max_comp,\n",
    "                svd_solver=\"randomized\",\n",
    "                random_state=0\n",
    "            )))\n",
    "    return Pipeline(steps=steps)\n",
    "\n",
    "\n",
    "def precompute_loo_transforms(cfg: Cfg, Xraw: np.ndarray) -> List[Dict[str, object]]:\n",
    "    \"\"\"\n",
    "    LOOの各foldで、X前処理（impute/scale/pca）をtrainだけでfitし、\n",
    "    train/testをtransformした行列をキャッシュする（リーク防止 + 高速化）。\n",
    "    \"\"\"\n",
    "    loo = LeaveOneOut()\n",
    "    folds: List[Dict[str, object]] = []\n",
    "    n, p = Xraw.shape\n",
    "    for tr, te in loo.split(np.arange(n)):\n",
    "        Xpipe = build_X_pipe_fold(cfg, n_train=len(tr), n_features=p)\n",
    "        Ztr = Xpipe.fit_transform(Xraw[tr])\n",
    "        Zte = Xpipe.transform(Xraw[te])\n",
    "        folds.append({\n",
    "            \"tr\": tr,\n",
    "            \"te\": te,\n",
    "            \"Ztr\": Ztr,\n",
    "            \"Zte\": Zte,\n",
    "        })\n",
    "    return folds\n",
    "\n",
    "\n",
    "def loo_predict_multioutput_cached(folds: List[Dict[str, object]], Y: np.ndarray, alpha: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    キャッシュ済みの(Ztr, Zte)を使って multi-output Ridge をLOOで予測。\n",
    "    \"\"\"\n",
    "    Yhat = np.full_like(Y, np.nan, dtype=float)\n",
    "    for fd in folds:\n",
    "        tr = fd[\"tr\"]\n",
    "        te = fd[\"te\"]\n",
    "        m = Ridge(alpha=float(alpha), solver=\"svd\")\n",
    "        m.fit(fd[\"Ztr\"], Y[tr])\n",
    "        Yhat[te] = m.predict(fd[\"Zte\"])\n",
    "    return Yhat\n",
    "\n",
    "\n",
    "def tune_alpha_loocv_multioutput_cached(\n",
    "    folds: List[Dict[str, object]],\n",
    "    Y: np.ndarray,\n",
    "    alphas: Tuple[float, ...],\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    LOO（リーク無し）でalphaを選ぶ。目的関数は全要素のMSE平均。\n",
    "    \"\"\"\n",
    "    best_a, best_mse = None, np.inf\n",
    "    for a in alphas:\n",
    "        Yhat = loo_predict_multioutput_cached(folds, Y, float(a))\n",
    "        mse = float(np.mean((Y - Yhat) ** 2))\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_a = float(a)\n",
    "    return float(best_a)\n",
    "\n",
    "\n",
    "def perm_test_topk_multioutput_cached(\n",
    "    folds: List[Dict[str, object]],\n",
    "    Ytop: np.ndarray,\n",
    "    alpha: float,\n",
    "    obs_r2: np.ndarray,\n",
    "    n_perm: int,\n",
    "    seed: int,\n",
    "    L: Logger,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    TopKだけ permutation p を計算（高速版：multi-outputでまとめて回す）。\n",
    "    各permで「各特徴（列）を独立にシャッフル」するので、列ごとのnullになる。\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(int(seed))\n",
    "    topk = Ytop.shape[1]\n",
    "    ge = np.zeros(topk, dtype=int)\n",
    "\n",
    "    for t in range(1, int(n_perm) + 1):\n",
    "        Yp = np.empty_like(Ytop)\n",
    "        # 各列独立にシャッフル（nullをfeatureごとに作る）\n",
    "        for j in range(topk):\n",
    "            Yp[:, j] = rng.permutation(Ytop[:, j])\n",
    "\n",
    "        Yp_hat = loo_predict_multioutput_cached(folds, Yp, float(alpha))\n",
    "        rp = np.array([float(r2_score(Yp[:, j], Yp_hat[:, j])) for j in range(topk)], dtype=float)\n",
    "        ge += (np.abs(rp) >= np.abs(obs_r2)).astype(int)\n",
    "\n",
    "        if t in {50, 100, 200} or t == n_perm:\n",
    "            L.log(f\"  [ENC][PERM] t={t}/{n_perm}\")\n",
    "\n",
    "    pvals = (ge + 1) / (int(n_perm) + 1)\n",
    "    return pvals.astype(float)\n",
    "\n",
    "\n",
    "def run_encoding(\n",
    "    cfg: Cfg, master: pd.DataFrame, sound: pd.DataFrame, eeg_cols: List[str], L: Logger\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Leakage-safe LOO Encoding:\n",
    "    - LOOの各foldでX前処理をtrainだけでfit（impute/scale/pca）\n",
    "    - その上でmulti-output Ridge をfit/predict\n",
    "    \"\"\"\n",
    "    # --- acoustic cols（「音響」だけに寄せて、主観系が紛れないように） ---\n",
    "    num = numeric_cols(sound)\n",
    "    exclude = {cfg.SOUND_COL, \"Unnamed: 0\", \"index\", \"number\"}\n",
    "    exclude |= set(cfg.TARGETS)\n",
    "\n",
    "    # 主観平均や派生列が紛れたときに事故るので、\"_mean\" を除外（Aと同じ思想）\n",
    "    for c in sound.columns:\n",
    "        if str(c).endswith(\"_mean\"):\n",
    "            exclude.add(c)\n",
    "\n",
    "    ac_cols = [c for c in num if c not in exclude]\n",
    "    ac_cols = [c for c in ac_cols if not sound[c].isna().all()]\n",
    "    if len(ac_cols) == 0:\n",
    "        raise ValueError(\"[ENC] No acoustic feature columns after exclusion.\")\n",
    "\n",
    "    Xdf = (\n",
    "        sound[[cfg.SOUND_COL] + ac_cols]\n",
    "        .drop_duplicates(cfg.SOUND_COL)\n",
    "        .set_index(cfg.SOUND_COL)\n",
    "        .replace([np.inf, -np.inf], np.nan)\n",
    "    )\n",
    "\n",
    "    # --- Y: sound-mean EEG ---\n",
    "    Ydf = master.groupby(cfg.SOUND_COL)[eeg_cols].mean()\n",
    "\n",
    "    # 共通soundをXdfの順序で揃える（安定）\n",
    "    common = [sid for sid in Xdf.index.tolist() if sid in Ydf.index]\n",
    "    if len(common) < 10:\n",
    "        raise ValueError(f\"[ENC] Too few common sounds: {len(common)}\")\n",
    "\n",
    "    Xraw = Xdf.loc[common, ac_cols].to_numpy(dtype=np.float64)\n",
    "    Yraw = Ydf.loc[common, eeg_cols].to_numpy(dtype=np.float64)\n",
    "\n",
    "    # EEG列のクリーニング（all-NaN / ほぼ定数は落とす）\n",
    "    keep = []\n",
    "    kept_names = []\n",
    "    for j, name in enumerate(eeg_cols):\n",
    "        col = Yraw[:, j]\n",
    "        if np.all(np.isnan(col)):\n",
    "            continue\n",
    "        if np.nanstd(col) < 1e-12:\n",
    "            continue\n",
    "        keep.append(j)\n",
    "        kept_names.append(name)\n",
    "    keep = np.array(keep, dtype=int)\n",
    "    Y = Yraw[:, keep]\n",
    "\n",
    "    # YのNaNは（ほぼ無いはずだが）列medianで埋める\n",
    "    med = np.nanmedian(Y, axis=0)\n",
    "    inds = np.where(np.isnan(Y))\n",
    "    if len(inds[0]) > 0:\n",
    "        Y = Y.copy()\n",
    "        Y[inds] = np.take(med, inds[1])\n",
    "\n",
    "    L.log(f\"[ENC] n_sounds={len(common)} | X_raw={Xraw.shape} | Y={Y.shape} (kept EEG={len(kept_names)})\")\n",
    "\n",
    "    # LOO変換キャッシュ（リーク無し + 高速化）\n",
    "    folds = precompute_loo_transforms(cfg, Xraw)\n",
    "\n",
    "    # alpha tuning（リーク無しLOO）\n",
    "    alpha = tune_alpha_loocv_multioutput_cached(folds, Y, cfg.ALPHAS)\n",
    "    L.log(f\"[ENC] best alpha={alpha}\")\n",
    "\n",
    "    # LOO予測（リーク無し）\n",
    "    Yhat = loo_predict_multioutput_cached(folds, Y, alpha)\n",
    "\n",
    "    r2s = np.array([float(r2_score(Y[:, j], Yhat[:, j])) for j in range(Y.shape[1])], dtype=float)\n",
    "    res = (\n",
    "        pd.DataFrame({\"eeg_feature\": kept_names, \"r2_loocv\": r2s})\n",
    "        .sort_values(\"r2_loocv\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # --- TopK permutation（multi-outputでまとめて回す） ---\n",
    "    topk = int(min(cfg.ENC_TOPK, len(res)))\n",
    "    top = res.head(topk).copy()\n",
    "\n",
    "    idx_top = top.index.to_numpy(dtype=int)\n",
    "    Ytop = Y[:, idx_top]\n",
    "    Ytop_hat = Yhat[:, idx_top]\n",
    "    obs_r2 = np.array([float(r2_score(Ytop[:, j], Ytop_hat[:, j])) for j in range(topk)], dtype=float)\n",
    "\n",
    "    L.log(f\"[ENC][PERM] TopK={topk} N_PERM={cfg.ENC_N_PERM}\")\n",
    "    pvals = perm_test_topk_multioutput_cached(\n",
    "        folds=folds,\n",
    "        Ytop=Ytop,\n",
    "        alpha=alpha,\n",
    "        obs_r2=obs_r2,\n",
    "        n_perm=cfg.ENC_N_PERM,\n",
    "        seed=cfg.ENC_SEED,\n",
    "        L=L,\n",
    "    )\n",
    "    top[\"p_perm_two_sided\"] = pvals\n",
    "\n",
    "    summary = pd.DataFrame([{\n",
    "        \"n_sounds\": int(len(common)),\n",
    "        \"n_acoustic_features\": int(len(ac_cols)),\n",
    "        \"use_pca\": bool(cfg.ACOUSTIC_USE_PCA),\n",
    "        \"pca_ncomp\": int(cfg.ACOUSTIC_PCA_NCOMP) if cfg.ACOUSTIC_USE_PCA else 0,\n",
    "        \"n_eeg_features_kept\": int(len(kept_names)),\n",
    "        \"alpha\": float(alpha),\n",
    "        \"r2_mean\": float(np.mean(res[\"r2_loocv\"])),\n",
    "        \"r2_median\": float(np.median(res[\"r2_loocv\"])),\n",
    "        \"topk\": int(topk),\n",
    "        \"n_topk_p05\": int((top[\"p_perm_two_sided\"] < 0.05).sum()),\n",
    "    }])\n",
    "\n",
    "    return res, top, summary\n",
    "\n",
    "\n",
    "\n",
    "def save_encoding_figs(cfg: Cfg, res: pd.DataFrame, fig_dir: Path) -> None:\n",
    "    ensure_dir(fig_dir)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(res[\"r2_loocv\"].values, bins=30)\n",
    "    plt.axvline(0, linewidth=1)\n",
    "    plt.xlabel(\"LOO-CV R² (Acoustic → EEG feature)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(\"Encoding: stimulus-driven EEG explained by acoustics\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_dir / \"encoding_r2_hist.png\", dpi=cfg.SAVE_DPI, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    top20 = res.head(20).iloc[::-1]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.barh(top20[\"eeg_feature\"].values, top20[\"r2_loocv\"].values)\n",
    "    plt.axvline(0, linewidth=1)\n",
    "    plt.xlabel(\"LOO-CV R²\")\n",
    "    plt.title(\"Top 20 EEG features explained by acoustics\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fig_dir / \"encoding_top20.png\", dpi=cfg.SAVE_DPI, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# QC link (optional, single OUT style)\n",
    "# =========================================================\n",
    "def run_qc_link_optional(cfg: Cfg, folds: pd.DataFrame, L: Logger) -> Optional[pd.DataFrame]:\n",
    "    if cfg.MODULEB_TRIAL_EEG is None:\n",
    "        L.log(\"[QC] Skip: MODULEB_TRIAL_EEG is None.\")\n",
    "        return None\n",
    "    if not cfg.MODULEB_TRIAL_EEG.exists():\n",
    "        L.log(f\"[QC] Skip: file not found: {cfg.MODULEB_TRIAL_EEG}\")\n",
    "        return None\n",
    "\n",
    "    b = pd.read_csv(cfg.MODULEB_TRIAL_EEG)\n",
    "\n",
    "    # subject column auto-detect\n",
    "    sub_col = pick_col(b, [\"subject\", \"subject_id\", \"participant\", \"participant_id\", \"subj\"])\n",
    "    if sub_col is None:\n",
    "        L.log(\"[QC] Skip: could not detect subject column in ModuleB trial EEG CSV.\")\n",
    "        return None\n",
    "\n",
    "    num = numeric_cols(b)\n",
    "    drop_like = {\"sound_id\", \"sound\", \"number\", \"run\", \"trial\", \"epoch\", \"time\"}\n",
    "    feat_cols = [c for c in num if _norm(c) not in {_norm(x) for x in drop_like}]\n",
    "    if len(feat_cols) == 0:\n",
    "        L.log(\"[QC] Skip: no numeric feature columns in ModuleB trial EEG CSV.\")\n",
    "        return None\n",
    "\n",
    "    grp = b.groupby(b[sub_col].astype(str))\n",
    "    qc = pd.DataFrame({\n",
    "        \"subject\": grp.size().index.astype(str),\n",
    "        \"n_trials\": grp.size().values.astype(int),\n",
    "        \"nan_rate\": [float(np.isnan(df[feat_cols].to_numpy(dtype=float)).mean()) for _, df in grp],\n",
    "    })\n",
    "\n",
    "    c = folds.rename(columns={\"held_out\": \"subject\"}).copy()\n",
    "    c[\"subject\"] = c[\"subject\"].astype(str)\n",
    "    merged = c.merge(qc, on=\"subject\", how=\"left\")\n",
    "    return merged\n",
    "\n",
    "\n",
    "def save_qc_figs(cfg: Cfg, merged: pd.DataFrame, fig_dir: Path) -> None:\n",
    "    ensure_dir(fig_dir)\n",
    "    for tgt, d in merged.groupby(\"target\"):\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.scatter(d[\"nan_rate\"].values, d[\"delta_r2_full\"].values)\n",
    "        for _, r in d.iterrows():\n",
    "            if pd.notna(r[\"nan_rate\"]) and pd.notna(r[\"delta_r2_full\"]):\n",
    "                plt.text(float(r[\"nan_rate\"]), float(r[\"delta_r2_full\"]), str(r[\"subject\"]), fontsize=8)\n",
    "        plt.axhline(0, linewidth=1)\n",
    "        plt.xlabel(\"NaN rate in trial-level EEG features\")\n",
    "        plt.ylabel(\"ΔR² (Full − Acoustic) in Module C\")\n",
    "        plt.title(f\"QC link: {tgt}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fig_dir / f\"qc_nan_vs_delta_{tgt}.png\", dpi=cfg.SAVE_DPI, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Reports (貼って終わり用)\n",
    "# =========================================================\n",
    "def write_reports(cfg: Cfg, summary: pd.DataFrame, report_dir: Path) -> None:\n",
    "    ensure_dir(report_dir)\n",
    "\n",
    "    lines = []\n",
    "    lines.append(\"# Module C（Finalize）— 結果要約（貼って終わり版）\\n\")\n",
    "    lines.append(\"## 位置づけ（教授対策の定義）\")\n",
    "    lines.append(\"- **B/F**：EEG→主観のデコード（本丸）\")\n",
    "    lines.append(\"- **C**：音響代理（confound）を厳密に統制し、EEGの“追加説明力”の上限を定量化する（盾）\\n\")\n",
    "    lines.append(\"## 観察された事実（数値）\")\n",
    "    for _, r in summary.iterrows():\n",
    "        lines.append(f\"- {r['target']}: mean ΔR²_full={r['mean_delta_full']:+.4f}（perm p={r.get('p_two_sided', np.nan):.3f}）\")\n",
    "    lines.append(\"\\n## 解釈（言い方）\")\n",
    "    lines.append(\"音刺激が主観を強く規定する状況では、音響で説明可能な成分を統制すると、残差EEGの未知被験者一般化（LOSO）での追加説明力は限定的だった。\")\n",
    "    lines.append(\"これは『EEGが弱い』という結論ではなく、『音響代理を差し引いた上での厳密な上限評価』であり、Cは解析の妥当性・頑健性を担保する役割を持つ。\")\n",
    "    (report_dir / \"ModuleC_task1_summary.md\").write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "\n",
    "    rep = []\n",
    "    rep.append(\"# Encoding（Acoustic → EEG）— 書き方テンプレ\\n\")\n",
    "    rep.append(\"## 主張（短く強く）\")\n",
    "    rep.append(\"- 音響特徴量から、音ごとのEEG平均（刺激駆動成分）の一部は説明可能（Encoding）。\")\n",
    "    rep.append(\"- その一方で、音響で説明可能な成分を統制した残差EEGは、未知被験者一般化で主観PCへの追加説明力が限定的。\")\n",
    "    rep.append(\"\\n## 本文に貼って通る版（日本語）\")\n",
    "    rep.append(\"音刺激が共通にもたらす脳波表現を評価するため、音ごとのEEG平均（stimulus-driven component）を目的変数とし、音響特徴量からのエンコーディング解析（LOO-CV）を行った。\")\n",
    "    rep.append(\"その結果、一部のEEG特徴量は正の決定係数を示し、音刺激の物理構造が脳波特徴として反映されることが示唆された。\")\n",
    "    rep.append(\"一方、音響で説明可能な成分を統制した残差EEGは、未知被験者外挿（LOSO）における主観PC予測への寄与が限定的であった。\")\n",
    "    (report_dir / \"Encoding_text_template.md\").write_text(\"\\n\".join(rep), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# CLI / Main\n",
    "# =========================================================\n",
    "def parse_args() -> argparse.Namespace:\n",
    "    ap = argparse.ArgumentParser()\n",
    "\n",
    "    # Jupyter/ipykernel 直実行でも動くように default を設定（required を外す）\n",
    "    ap.add_argument(\"--root_dir\", type=str, default=\"/Users/shunsuke/EEG_48sounds\")\n",
    "    ap.add_argument(\"--out_dir_name\", type=str, default=\"moduleC_outputs\")\n",
    "    ap.add_argument(\"--wipe_outdir\", type=int, default=1, help=\"1: delete OUT_DIR then run; 0: keep\")\n",
    "    ap.add_argument(\"--moduleb_trial_csv\", type=str,\n",
    "                    default=\"moduleB_outputs/tables/moduleB_trial_eeg_features.csv\")\n",
    "\n",
    "    ap.add_argument(\"--n_perm\", type=int, default=200)\n",
    "    ap.add_argument(\"--enc_n_perm\", type=int, default=300)\n",
    "    ap.add_argument(\"--enc_topk\", type=int, default=50)\n",
    "\n",
    "    # ipykernel が付ける unknown args（例: -f xxxx）を握りつぶす\n",
    "    args, _unknown = ap.parse_known_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    # warning はログが汚れるので必要最低限だけ抑える（処理自体は続行）\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Singular matrix.*\")\n",
    "    warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "    args = parse_args()\n",
    "\n",
    "    root = Path(args.root_dir)\n",
    "    out_dir = root / args.out_dir_name\n",
    "\n",
    "    cfg = Cfg(\n",
    "        ROOT_DIR=root,\n",
    "        OUT_DIR=out_dir,\n",
    "        MASTER_PS=root / \"derivatives/master_tables/master_participant_sound_level_with_PC.csv\",\n",
    "        MASTER_SOUND=root / \"derivatives/master_tables/master_sound_level_with_PC.csv\",\n",
    "        EEG_FEATURES_LIST=root / \"derivatives/eeg_features_participant_sound.csv\",\n",
    "        MODULEB_TRIAL_EEG=(root / args.moduleb_trial_csv) if args.moduleb_trial_csv else None,\n",
    "    )\n",
    "    cfg.N_PERM = int(args.n_perm)\n",
    "    cfg.ENC_N_PERM = int(args.enc_n_perm)\n",
    "    cfg.ENC_TOPK = int(args.enc_topk)\n",
    "\n",
    "    L = Logger()\n",
    "\n",
    "    # wipe (single OUT style)\n",
    "    if int(args.wipe_outdir) == 1:\n",
    "        safe_wipe_outdir(cfg.ROOT_DIR, cfg.OUT_DIR)\n",
    "\n",
    "    tab_dir = cfg.OUT_DIR / \"tables\"\n",
    "    fig_dir = cfg.OUT_DIR / \"figures\"\n",
    "    log_dir = cfg.OUT_DIR / \"logs\"\n",
    "    rep_dir = cfg.OUT_DIR / \"reports\"\n",
    "    ensure_dir(tab_dir); ensure_dir(fig_dir); ensure_dir(log_dir); ensure_dir(rep_dir)\n",
    "\n",
    "    L.log(\"=== Module C FINALIZE (Single OUT + Wipe) START ===\")\n",
    "    L.log(f\"[CFG] ROOT_DIR={cfg.ROOT_DIR}\")\n",
    "    L.log(f\"[CFG] OUT_DIR ={cfg.OUT_DIR}\")\n",
    "    L.log(f\"[CFG] EEG_DECONFOUND_WITH_ACOUSTICS={cfg.EEG_DECONFOUND_WITH_ACOUSTICS}\")\n",
    "    L.log(f\"[CFG] ACOUSTIC_USE_PCA={cfg.ACOUSTIC_USE_PCA} ncomp={cfg.ACOUSTIC_PCA_NCOMP}\")\n",
    "    L.log(f\"[CFG] N_PERM={cfg.N_PERM} | ENC_TOPK={cfg.ENC_TOPK} ENC_N_PERM={cfg.ENC_N_PERM}\")\n",
    "\n",
    "    # load\n",
    "    eeg_cols = load_eeg_feature_names(cfg, L)\n",
    "    master = load_master_minimal(cfg, eeg_cols, L)\n",
    "    sound = load_sound(cfg, L)\n",
    "    ac_cols = choose_acoustic_cols(cfg, sound, L)\n",
    "\n",
    "    df, ac_use, eeg_use = assemble_df(cfg, master, sound, ac_cols, eeg_cols, L)\n",
    "    L.log(f\"[INFO] n_acoustic_use={len(ac_use)} n_eeg_use={len(eeg_use)}\")\n",
    "\n",
    "    # run Module C complete\n",
    "    L.log(\"\\n--- Run: Module C Complete (LOSO + Perm + Deviation) ---\")\n",
    "    folds, dev, perm = run_moduleC_complete(cfg, df, ac_use, eeg_use, L)\n",
    "\n",
    "    folds_path = tab_dir / \"moduleC_complete_folds.csv\"\n",
    "    dev_path = tab_dir / \"moduleC_eeg_deviation_folds.csv\"\n",
    "    perm_path = tab_dir / \"moduleC_complete_permutation_summary.csv\"\n",
    "    folds.to_csv(folds_path, index=False, encoding=\"utf-8-sig\")\n",
    "    dev.to_csv(dev_path, index=False, encoding=\"utf-8-sig\")\n",
    "    perm.to_csv(perm_path, index=False, encoding=\"utf-8-sig\")\n",
    "    L.log(f\"[SAVE] {folds_path}\")\n",
    "    L.log(f\"[SAVE] {dev_path}\")\n",
    "    L.log(f\"[SAVE] {perm_path}\")\n",
    "\n",
    "    # figs + summary\n",
    "    L.log(\"\\n--- Make: Module C Summary + Figures ---\")\n",
    "    save_moduleC_figs(cfg, folds, perm, fig_dir)\n",
    "    summary = make_moduleC_summary(folds, perm)\n",
    "    summary_path = tab_dir / \"moduleC_summary.csv\"\n",
    "    summary.to_csv(summary_path, index=False, encoding=\"utf-8-sig\")\n",
    "    L.log(f\"[SAVE] {summary_path}\")\n",
    "\n",
    "    # encoding\n",
    "    L.log(\"\\n--- Run: Encoding (Acoustic -> EEG sound-mean) ---\")\n",
    "    enc_res, enc_top, enc_sum = run_encoding(cfg, master, sound, eeg_use, L)\n",
    "    enc_res_path = tab_dir / \"encoding_feature_r2.csv\"\n",
    "    enc_top_path = tab_dir / \"encoding_topk_with_p.csv\"\n",
    "    enc_sum_path = tab_dir / \"encoding_summary.csv\"\n",
    "    enc_res.to_csv(enc_res_path, index=False, encoding=\"utf-8-sig\")\n",
    "    enc_top.to_csv(enc_top_path, index=False, encoding=\"utf-8-sig\")\n",
    "    enc_sum.to_csv(enc_sum_path, index=False, encoding=\"utf-8-sig\")\n",
    "    save_encoding_figs(cfg, enc_res, fig_dir)\n",
    "    L.log(f\"[SAVE] {enc_res_path}\")\n",
    "    L.log(f\"[SAVE] {enc_top_path}\")\n",
    "    L.log(f\"[SAVE] {enc_sum_path}\")\n",
    "\n",
    "    # QC link optional\n",
    "    L.log(\"\\n--- Optional: QC link (ModuleB trial EEG) ---\")\n",
    "    merged = run_qc_link_optional(cfg, folds, L)\n",
    "    if merged is not None:\n",
    "        qc_path = tab_dir / \"qc_subject_qc_with_moduleC.csv\"\n",
    "        merged.to_csv(qc_path, index=False, encoding=\"utf-8-sig\")\n",
    "        save_qc_figs(cfg, merged, fig_dir)\n",
    "        L.log(f\"[SAVE] {qc_path}\")\n",
    "    else:\n",
    "        L.log(\"[QC] skipped.\")\n",
    "\n",
    "    # reports\n",
    "    L.log(\"\\n--- Write: Reports ---\")\n",
    "    write_reports(cfg, summary, rep_dir)\n",
    "    L.log(f\"[SAVE] {rep_dir / 'ModuleC_task1_summary.md'}\")\n",
    "    L.log(f\"[SAVE] {rep_dir / 'Encoding_text_template.md'}\")\n",
    "\n",
    "    # log\n",
    "    log_path = log_dir / \"moduleC_finalize_run.log\"\n",
    "    L.save(log_path)\n",
    "    L.log(f\"[SAVE] {log_path}\")\n",
    "\n",
    "    L.log(\"=== Module C FINALIZE END ===\")\n",
    "    L.log(f\"Outputs saved under: {cfg.OUT_DIR}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a669292-ae36-4823-bec7-7c10c1f643bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
