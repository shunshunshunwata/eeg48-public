{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f684b79-b63c-409e-aed9-230e299a26e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS: /Users/shunsuke/EEG_48sounds/derivatives/epochs_all/epochs_all-epo.fif\n",
      "MASTER: /Users/shunsuke/EEG_48sounds/derivatives/master_tables/master_participant_sound_level_with_PC.csv\n",
      "TRIAL_FEAT: /Users/shunsuke/EEG_48sounds/moduleB_outputs/tables/moduleB_trial_eeg_features.csv\n",
      "OUT: /Users/shunsuke/EEG_48sounds/moduleB_outputs/figs/ERP_onset_under1000ms_suite\n",
      "Loaded epochs: 1728\n",
      "NaN rate meta keys:\n",
      " subject_id      0.0\n",
      "run_id          0.0\n",
      "trial_in_run    0.0\n",
      "number          0.0\n",
      "dtype: float64\n",
      "NaN rate tf keys:\n",
      " subject_id      0.0\n",
      "run_id          0.0\n",
      "trial_in_run    0.0\n",
      "number          0.0\n",
      "dtype: float64\n",
      "Replacing existing metadata with 32 columns\n",
      "Aligned epochs: 1728 / 1728 (run_off=0, trial_off=0)\n",
      "align_info: {'aligned': True, 'run_off': 0, 'trial_off': 0, 'n_aligned': 1728}\n",
      "Attached label NaN rate:\n",
      " emo_approach         0.0\n",
      "emo_approach_high    0.0\n",
      "is_ambiguous         0.0\n",
      "category_3           0.0\n",
      "dtype: float64\n",
      "Attached label value_counts (binary-ish):\n",
      "  emo_approach_high {1: np.int64(999), 0: np.int64(729)}\n",
      "  is_ambiguous {False: np.int64(1584), True: np.int64(144)}\n",
      "Replacing existing metadata with 36 columns\n",
      "Attached cols: ['emo_approach', 'emo_approach_high', 'is_ambiguous', 'category_3']\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "After normalize/pick EEG19 ch_names: ['C3', 'C4', 'Cz', 'F3', 'F4', 'F7', 'F8', 'Fp1', 'Fp2', 'Fz', 'O1', 'O2', 'P3', 'P4', 'Pz']\n",
      "Applying baseline correction (mode: mean)\n",
      "After crop/baseline: -0.2 1.0 n= 1728\n",
      "Available CONTRASTS: ['emo_approach_high', 'is_ambiguous']\n",
      "emo_approach_high value_counts: {1: np.int64(999), 0: np.int64(729)}\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "is_ambiguous value_counts: {False: np.int64(1584), True: np.int64(144)}\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "[SAVED] /Users/shunsuke/EEG_48sounds/moduleB_outputs/figs/ERP_onset_under1000ms_suite/tables/ERP_onset_under1000ms_perm_ALLCONDS.csv\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "[SAVED] /Users/shunsuke/EEG_48sounds/moduleB_outputs/figs/ERP_onset_under1000ms_suite/figs/ERP_emo_approach_high_frontal_highlow_-200_1000ms.png\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "[SAVED] /Users/shunsuke/EEG_48sounds/moduleB_outputs/figs/ERP_onset_under1000ms_suite/figs/ERP_emo_approach_high_central_highlow_-200_1000ms.png\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "[SAVED] /Users/shunsuke/EEG_48sounds/moduleB_outputs/figs/ERP_onset_under1000ms_suite/figs/ERP_emo_approach_high_parietal_highlow_-200_1000ms.png\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "[SAVED] /Users/shunsuke/EEG_48sounds/moduleB_outputs/figs/ERP_onset_under1000ms_suite/figs/ERP_emo_approach_high_occipital_highlow_-200_1000ms.png\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "[SAVED] /Users/shunsuke/EEG_48sounds/moduleB_outputs/figs/ERP_onset_under1000ms_suite/figs/ERP_is_ambiguous_frontal_highlow_-200_1000ms.png\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "[SAVED] /Users/shunsuke/EEG_48sounds/moduleB_outputs/figs/ERP_onset_under1000ms_suite/figs/ERP_is_ambiguous_central_highlow_-200_1000ms.png\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "[SAVED] /Users/shunsuke/EEG_48sounds/moduleB_outputs/figs/ERP_onset_under1000ms_suite/figs/ERP_is_ambiguous_parietal_highlow_-200_1000ms.png\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "[SAVED] /Users/shunsuke/EEG_48sounds/moduleB_outputs/figs/ERP_onset_under1000ms_suite/figs/ERP_is_ambiguous_occipital_highlow_-200_1000ms.png\n",
      "[SAVED] /Users/shunsuke/EEG_48sounds/moduleB_outputs/figs/ERP_onset_under1000ms_suite/figs/TopoDiff_emo_approach_high_highminuslow_0-80ms.png\n",
      "[SAVED] /Users/shunsuke/EEG_48sounds/moduleB_outputs/figs/ERP_onset_under1000ms_suite/figs/TopoDiff_emo_approach_high_highminuslow_80-140ms.png\n",
      "[SAVED] /Users/shunsuke/EEG_48sounds/moduleB_outputs/figs/ERP_onset_under1000ms_suite/figs/TopoDiff_emo_approach_high_highminuslow_140-220ms.png\n",
      "[SAVED] /Users/shunsuke/EEG_48sounds/moduleB_outputs/figs/ERP_onset_under1000ms_suite/figs/TopoDiff_is_ambiguous_highminuslow_0-80ms.png\n",
      "[SAVED] /Users/shunsuke/EEG_48sounds/moduleB_outputs/figs/ERP_onset_under1000ms_suite/figs/TopoDiff_is_ambiguous_highminuslow_80-140ms.png\n",
      "[SAVED] /Users/shunsuke/EEG_48sounds/moduleB_outputs/figs/ERP_onset_under1000ms_suite/figs/TopoDiff_is_ambiguous_highminuslow_140-220ms.png\n",
      "\n",
      "DONE.\n",
      "Tables: /Users/shunsuke/EEG_48sounds/moduleB_outputs/figs/ERP_onset_under1000ms_suite/tables\n",
      "Figs  : /Users/shunsuke/EEG_48sounds/moduleB_outputs/figs/ERP_onset_under1000ms_suite/figs\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ModuleB: Onset ERP (<1000ms) FULL PIPELINE (FIXED ch_names)\n",
    "# - Keep alignment epochs <-> trial_feat by KEYS\n",
    "# - Attach labels from MASTER (robust)\n",
    "# - Normalize EEG channel names: \"EEG Fp1-Ref\" -> \"Fp1\"\n",
    "# - Keep only 19 EEG channels for ROI/topomap\n",
    "# - ROI x window sign-flip permutation\n",
    "# - ROI ERP plots + early inset + significant bands\n",
    "# - Topomaps for early windows\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========================\n",
    "# 0) CONFIG（あなたのパス）\n",
    "# =========================\n",
    "EPOCHS_PATH = Path(\"/Users/shunsuke/EEG_48sounds/derivatives/epochs_all/epochs_all-epo.fif\")\n",
    "MASTER_PATH = Path(\"/Users/shunsuke/EEG_48sounds/derivatives/master_tables/master_participant_sound_level_with_PC.csv\")\n",
    "TRIAL_FEAT_PATH = Path(\"/Users/shunsuke/EEG_48sounds/moduleB_outputs/tables/moduleB_trial_eeg_features.csv\")\n",
    "\n",
    "OUT_DIR = Path(\"/Users/shunsuke/EEG_48sounds/moduleB_outputs/figs/ERP_onset_under1000ms_suite\")\n",
    "OUT_FIG = OUT_DIR / \"figs\"\n",
    "OUT_TAB = OUT_DIR / \"tables\"\n",
    "OUT_FIG.mkdir(parents=True, exist_ok=True)\n",
    "OUT_TAB.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "N_PERM = 9999\n",
    "SEED = 0\n",
    "SCALE_TO_uV = True\n",
    "\n",
    "# 教授対応：0–1000ms（加えて0–220msを強調）\n",
    "WINDOWS_MS = [(0,80),(80,140),(140,220),(220,350),(350,500),(500,800),(800,1000)]\n",
    "EARLY_WINDOWS_MS = [(0,80),(80,140),(140,220)]\n",
    "TOPO_WINDOWS_MS  = [(0,80),(80,140),(140,220)]\n",
    "\n",
    "# ROI（19ch）\n",
    "ROI_DEF = {\n",
    "    \"frontal\":  [\"Fp1\",\"Fp2\",\"F7\",\"F3\",\"Fz\",\"F4\",\"F8\"],\n",
    "    \"central\":  [\"C3\",\"Cz\",\"C4\"],\n",
    "    \"parietal\": [\"P7\",\"P3\",\"Pz\",\"P4\",\"P8\"],\n",
    "    \"occipital\":[\"O1\",\"O2\"],\n",
    "}\n",
    "EEG19 = sorted({ch for v in ROI_DEF.values() for ch in v})\n",
    "\n",
    "# MASTERがPC列しかない場合の既定割当（必要なら変更）\n",
    "PC_FALLBACK_MAP = {\"emo_arousal\":\"PC1\",\"emo_approach\":\"PC2\",\"emo_valence\":\"PC3\"}\n",
    "\n",
    "KEYS = [\"subject_id\",\"run_id\",\"trial_in_run\",\"number\"]\n",
    "\n",
    "# =========================\n",
    "# 1) Utils\n",
    "# =========================\n",
    "def _standardize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    rename = {}\n",
    "    cols = set(df.columns)\n",
    "\n",
    "    if \"subject_id\" not in cols:\n",
    "        for c in [\"subject\",\"participant\",\"subj\",\"subj_id\"]:\n",
    "            if c in cols:\n",
    "                rename[c] = \"subject_id\"; break\n",
    "    if \"run_id\" not in cols:\n",
    "        for c in [\"run\",\"runid\",\"run_idx\"]:\n",
    "            if c in cols:\n",
    "                rename[c] = \"run_id\"; break\n",
    "    if \"trial_in_run\" not in cols:\n",
    "        for c in [\"trial\",\"trial_idx\",\"trialIndex\"]:\n",
    "            if c in cols:\n",
    "                rename[c] = \"trial_in_run\"; break\n",
    "    if \"number\" not in cols:\n",
    "        for c in [\"sound_number\",\"soundNo\",\"sound_no\",\"stim_number\"]:\n",
    "            if c in cols:\n",
    "                rename[c] = \"number\"; break\n",
    "    return df.rename(columns=rename) if rename else df\n",
    "\n",
    "def _require_cols(df: pd.DataFrame, required: list[str], name: str):\n",
    "    miss = [c for c in required if c not in df.columns]\n",
    "    if miss:\n",
    "        raise RuntimeError(f\"[{name}] Missing columns: {miss}\\ncols={list(df.columns)}\")\n",
    "\n",
    "def _to_int_from_any(s: pd.Series) -> pd.Series:\n",
    "    def conv(x):\n",
    "        if pd.isna(x): return np.nan\n",
    "        if isinstance(x, (int, np.integer)): return int(x)\n",
    "        if isinstance(x, (float, np.floating)) and np.isfinite(x): return int(x)\n",
    "        st = str(x).strip()\n",
    "        m = re.search(r\"(\\d+)\", st)\n",
    "        return int(m.group(1)) if m else np.nan\n",
    "    return s.apply(conv).astype(\"Int64\")\n",
    "\n",
    "def benjamini_hochberg(pvals: np.ndarray) -> np.ndarray:\n",
    "    p = np.asarray(pvals, dtype=float)\n",
    "    n = p.size\n",
    "    order = np.argsort(p)\n",
    "    ranked = p[order]\n",
    "    q = ranked * n / (np.arange(n) + 1)\n",
    "    q = np.minimum.accumulate(q[::-1])[::-1]\n",
    "    q = np.clip(q, 0, 1)\n",
    "    out = np.empty_like(q)\n",
    "    out[order] = q\n",
    "    return out\n",
    "\n",
    "def signflip_perm_t(diff_by_sub: np.ndarray, n_perm: int = 9999, seed: int = 0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    x = np.asarray(diff_by_sub, float)\n",
    "    x = x[~np.isnan(x)]\n",
    "    n = x.size\n",
    "    if n < 3:\n",
    "        return np.nan, np.nan\n",
    "    mu = x.mean()\n",
    "    sd = x.std(ddof=1)\n",
    "    t_obs = mu / (sd / np.sqrt(n)) if sd > 0 else np.inf\n",
    "    flips = rng.choice([-1, 1], size=(n_perm, n))\n",
    "    xp = flips * x[None, :]\n",
    "    mu_p = xp.mean(axis=1)\n",
    "    sd_p = xp.std(axis=1, ddof=1)\n",
    "    t_p = mu_p / (sd_p / np.sqrt(n))\n",
    "    p_perm = (np.sum(np.abs(t_p) >= np.abs(t_obs)) + 1) / (n_perm + 1)\n",
    "    return t_obs, p_perm\n",
    "\n",
    "def dz_effect(diff_by_sub: np.ndarray) -> float:\n",
    "    x = np.asarray(diff_by_sub, float)\n",
    "    x = x[~np.isnan(x)]\n",
    "    if x.size < 2:\n",
    "        return np.nan\n",
    "    sd = x.std(ddof=1)\n",
    "    return (x.mean() / sd) if sd > 0 else np.nan\n",
    "\n",
    "def ensure_montage(epochs: mne.Epochs) -> mne.Epochs:\n",
    "    epochs = epochs.copy()\n",
    "    montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
    "    epochs.set_montage(montage, on_missing=\"ignore\")\n",
    "    return epochs\n",
    "\n",
    "def _pick_col_by_keywords(df: pd.DataFrame, patterns: list[str], prefer_exact: list[str] | None = None):\n",
    "    cols = list(df.columns)\n",
    "    if prefer_exact:\n",
    "        for c in prefer_exact:\n",
    "            if c in df.columns:\n",
    "                return c\n",
    "    pat = re.compile(\"|\".join(patterns), flags=re.IGNORECASE)\n",
    "    hits = [c for c in cols if pat.search(str(c))]\n",
    "    if not hits:\n",
    "        return None\n",
    "    hits = sorted(hits, key=lambda x: (len(x), x))\n",
    "    return hits[0]\n",
    "\n",
    "# =========================\n",
    "# 2) FIX: EEGチャンネル名正規化＋19ch抽出\n",
    "# =========================\n",
    "def normalize_and_pick_eeg19(epochs: mne.Epochs):\n",
    "    \"\"\"\n",
    "    epochs に POL等が混在していても、\n",
    "    'EEG Fp1-Ref' -> 'Fp1' にリネームし、19ch（ROI対象）のみを残す。\n",
    "    \"\"\"\n",
    "    epochs = epochs.copy()\n",
    "\n",
    "    # まず EEG を含むチャンネルだけ候補として残す（POL除外）\n",
    "    eeg_like = [ch for ch in epochs.ch_names if str(ch).startswith(\"EEG \")]\n",
    "    if len(eeg_like) == 0:\n",
    "        # すでにFp1形式ならそのまま\n",
    "        eeg_like = [ch for ch in epochs.ch_names if ch in EEG19]\n",
    "\n",
    "    if len(eeg_like) == 0:\n",
    "        raise RuntimeError(\"EEGチャンネルが見つかりません（ch_namesに 'EEG ' も EEG19 も無い）。\")\n",
    "\n",
    "    epochs = epochs.pick_channels(eeg_like)\n",
    "\n",
    "    # 'EEG Fp1-Ref' -> 'Fp1'\n",
    "    rename = {}\n",
    "    for ch in epochs.ch_names:\n",
    "        s = str(ch)\n",
    "        m = re.match(r\"EEG\\s+([A-Za-z0-9]+)(?:-Ref)?$\", s)\n",
    "        if m:\n",
    "            rename[ch] = m.group(1)\n",
    "        else:\n",
    "            # それ以外も最後のトークンで拾う\n",
    "            # 例: \"EEG Fp1-Ref\"以外が混じった場合の保険\n",
    "            s2 = s.replace(\"EEG\", \"\").strip()\n",
    "            s2 = re.sub(r\"-Ref$\", \"\", s2)\n",
    "            rename[ch] = s2\n",
    "\n",
    "    epochs.rename_channels(rename)\n",
    "\n",
    "    # ROIに必要な19chだけ残す\n",
    "    keep = [ch for ch in EEG19 if ch in epochs.ch_names]\n",
    "    if len(keep) < 10:\n",
    "        raise RuntimeError(f\"19chが十分に揃っていません。keep={keep}, all={epochs.ch_names}\")\n",
    "\n",
    "    epochs = epochs.pick_channels(keep)\n",
    "\n",
    "    # 参照電極などが残っていれば削除（念のため）\n",
    "    drop = [ch for ch in epochs.ch_names if ch not in EEG19]\n",
    "    if drop:\n",
    "        epochs = epochs.drop_channels(drop)\n",
    "\n",
    "    return epochs\n",
    "\n",
    "# =========================\n",
    "# 3) Align epochs <-> trial_feat\n",
    "# =========================\n",
    "def align_epochs_to_trial_feat(epochs: mne.Epochs, trial_feat_csv: Path):\n",
    "    if trial_feat_csv is None or (not trial_feat_csv.exists()):\n",
    "        print(\"[WARN] TRIAL_FEAT not found. skip alignment.\")\n",
    "        return epochs, {\"aligned\": False, \"reason\": \"trial_feat missing\"}\n",
    "\n",
    "    if epochs.metadata is None:\n",
    "        print(\"[WARN] epochs.metadata is None. skip alignment.\")\n",
    "        return epochs, {\"aligned\": False, \"reason\": \"epochs.metadata None\"}\n",
    "\n",
    "    tf = pd.read_csv(trial_feat_csv)\n",
    "    tf = _standardize_columns(tf)\n",
    "    _require_cols(tf, KEYS, \"trial_feat\")\n",
    "\n",
    "    meta = _standardize_columns(epochs.metadata.copy())\n",
    "    _require_cols(meta, KEYS, \"epochs.metadata\")\n",
    "\n",
    "    for k in KEYS:\n",
    "        meta[k] = _to_int_from_any(meta[k])\n",
    "        tf[k]   = _to_int_from_any(tf[k])\n",
    "\n",
    "    print(\"NaN rate meta keys:\\n\", meta[KEYS].isna().mean())\n",
    "    print(\"NaN rate tf keys:\\n\", tf[KEYS].isna().mean())\n",
    "\n",
    "    meta = meta.dropna(subset=KEYS).copy()\n",
    "    tf   = tf.dropna(subset=KEYS).copy()\n",
    "\n",
    "    for k in KEYS:\n",
    "        meta[k] = meta[k].astype(int)\n",
    "        tf[k]   = tf[k].astype(int)\n",
    "\n",
    "    meta = meta.reset_index(drop=True)\n",
    "    meta[\"_eidx\"] = np.arange(len(meta))\n",
    "    keep = tf[KEYS].drop_duplicates().copy()\n",
    "    keep[\"_keep\"] = True\n",
    "\n",
    "    m = meta.merge(keep, on=KEYS, how=\"inner\")\n",
    "    roff_best, toff_best, best_n = 0, 0, len(m)\n",
    "\n",
    "    if len(m) == 0:\n",
    "        print(\"[WARN] direct merge=0. trying offset search ...\")\n",
    "        for roff in [-2,-1,0,1,2]:\n",
    "            for toff in [-2,-1,0,1,2]:\n",
    "                meta2 = meta.copy()\n",
    "                meta2[\"run_id\"] = meta2[\"run_id\"] + roff\n",
    "                meta2[\"trial_in_run\"] = meta2[\"trial_in_run\"] + toff\n",
    "                mm = meta2.merge(keep, on=KEYS, how=\"inner\")\n",
    "                if len(mm) > best_n:\n",
    "                    best_n = len(mm); roff_best, toff_best = roff, toff\n",
    "        print(f\"[BEST] nmatch={best_n}, run_off={roff_best}, trial_off={toff_best}\")\n",
    "\n",
    "        if best_n == 0:\n",
    "            print(\"[WARN] alignment failed (0 match). Proceed WITHOUT alignment.\")\n",
    "            return epochs, {\"aligned\": False, \"reason\": \"0 match even after offset\", \"run_off\": roff_best, \"trial_off\": toff_best}\n",
    "\n",
    "        meta[\"run_id\"] = meta[\"run_id\"] + roff_best\n",
    "        meta[\"trial_in_run\"] = meta[\"trial_in_run\"] + toff_best\n",
    "        m = meta.merge(keep, on=KEYS, how=\"inner\")\n",
    "\n",
    "    m = m.sort_values(\"_eidx\").reset_index(drop=True)\n",
    "    sel = m[\"_eidx\"].to_numpy()\n",
    "\n",
    "    epochs2 = epochs[sel]\n",
    "    meta2 = meta.loc[sel].drop(columns=[\"_eidx\"]).reset_index(drop=True)\n",
    "    epochs2.metadata = meta2\n",
    "\n",
    "    print(f\"Aligned epochs: {len(epochs2)} / {len(epochs)} (run_off={roff_best}, trial_off={toff_best})\")\n",
    "    return epochs2, {\"aligned\": True, \"run_off\": roff_best, \"trial_off\": toff_best, \"n_aligned\": len(epochs2)}\n",
    "\n",
    "# =========================\n",
    "# 4) Attach labels from MASTER (robust)\n",
    "# =========================\n",
    "def attach_labels_from_master_robust(epochs: mne.Epochs, master_csv: Path,\n",
    "                                    pc_fallback_map: dict | None = None,\n",
    "                                    make_high_by: str = \"median\"):\n",
    "    if epochs.metadata is None:\n",
    "        raise RuntimeError(\"epochs.metadata が None です。\")\n",
    "\n",
    "    master = pd.read_csv(master_csv)\n",
    "    master = _standardize_columns(master)\n",
    "    meta = _standardize_columns(epochs.metadata.copy())\n",
    "\n",
    "    _require_cols(master, [\"subject_id\",\"number\"], \"MASTER\")\n",
    "    _require_cols(meta,   [\"subject_id\",\"number\"], \"epochs.metadata\")\n",
    "\n",
    "    master[\"subject_id\"] = _to_int_from_any(master[\"subject_id\"])\n",
    "    master[\"number\"]     = _to_int_from_any(master[\"number\"])\n",
    "    meta[\"subject_id\"]   = _to_int_from_any(meta[\"subject_id\"])\n",
    "    meta[\"number\"]       = _to_int_from_any(meta[\"number\"])\n",
    "\n",
    "    master = master.dropna(subset=[\"subject_id\",\"number\"]).copy()\n",
    "    meta   = meta.dropna(subset=[\"subject_id\",\"number\"]).copy()\n",
    "    master[\"subject_id\"] = master[\"subject_id\"].astype(int)\n",
    "    master[\"number\"]     = master[\"number\"].astype(int)\n",
    "    meta[\"subject_id\"]   = meta[\"subject_id\"].astype(int)\n",
    "    meta[\"number\"]       = meta[\"number\"].astype(int)\n",
    "\n",
    "    if pc_fallback_map is None:\n",
    "        pc_fallback_map = PC_FALLBACK_MAP\n",
    "\n",
    "    # 既存列を探す\n",
    "    col_approach = _pick_col_by_keywords(master,\n",
    "        patterns=[r\"\\bemo[_ ]?approach\\b\", r\"\\bapproach\\b\", r\"接近\", r\"avoid\", r\"回避\"],\n",
    "        prefer_exact=[\"emo_approach\",\"approach\",\"Approach\"]\n",
    "    )\n",
    "\n",
    "    # PC fallback候補\n",
    "    pc_cols = [c for c in master.columns if re.search(r\"\\bPC\\s*\\d+\\b|\\bPC\\d+\\b|\\bpc\\d+\\b\", str(c))]\n",
    "    pc_cols_sorted = sorted(pc_cols, key=lambda x: (len(str(x)), str(x)))\n",
    "\n",
    "    def resolve_pc(name):\n",
    "        want = pc_fallback_map.get(name, None)\n",
    "        if want and want in master.columns:\n",
    "            return want\n",
    "        for cand in [\"PC1\",\"PC2\",\"PC3\",\"pc1\",\"pc2\",\"pc3\"]:\n",
    "            if cand in master.columns:\n",
    "                return cand\n",
    "        return pc_cols_sorted[0] if pc_cols_sorted else None\n",
    "\n",
    "    if col_approach is None:\n",
    "        pc = resolve_pc(\"emo_approach\")\n",
    "        if pc:\n",
    "            print(f\"[INFO] emo_approach not found -> fallback to {pc}\")\n",
    "            col_approach = pc\n",
    "\n",
    "    if col_approach and col_approach in master.columns:\n",
    "        master[\"emo_approach\"] = pd.to_numeric(master[col_approach], errors=\"coerce\")\n",
    "\n",
    "    # 二値列：既存が無ければmedian splitで作る\n",
    "    if \"emo_approach_high\" not in master.columns and \"emo_approach\" in master.columns:\n",
    "        x = pd.to_numeric(master[\"emo_approach\"], errors=\"coerce\")\n",
    "        thr = float(x.median()) if make_high_by == \"median\" else float(x.mean())\n",
    "        master[\"emo_approach_high\"] = (x >= thr).astype(int)\n",
    "\n",
    "    # is_ambiguous / category_3\n",
    "    col_amb = _pick_col_by_keywords(master,\n",
    "        patterns=[r\"\\bis[_ ]?ambiguous\\b\", r\"ambig\", r\"曖昧\", r\"ambiguity\"],\n",
    "        prefer_exact=[\"is_ambiguous\",\"ambiguous\"]\n",
    "    )\n",
    "    if col_amb and col_amb in master.columns:\n",
    "        master[\"is_ambiguous\"] = master[col_amb].astype(bool)\n",
    "\n",
    "    if \"category_3\" not in master.columns:\n",
    "        col_cat = _pick_col_by_keywords(master, patterns=[r\"\\bcategory\\b\", r\"カテゴリ\", r\"\\bcat\\b\"], prefer_exact=[\"category\"])\n",
    "        if col_cat and col_cat in master.columns:\n",
    "            master[\"category_3\"] = master[col_cat]\n",
    "\n",
    "    want_cols = [c for c in [\"emo_approach\",\"emo_approach_high\",\"is_ambiguous\",\"category_3\"] if c in master.columns]\n",
    "    if len(want_cols) == 0:\n",
    "        raise RuntimeError(\"MASTERからラベル列を検出できませんでした。列名を確認してください。\")\n",
    "\n",
    "    lab = master[[\"subject_id\",\"number\"] + want_cols].drop_duplicates([\"subject_id\",\"number\"])\n",
    "    out = meta.merge(lab, on=[\"subject_id\",\"number\"], how=\"left\")\n",
    "\n",
    "    print(\"Attached label NaN rate:\\n\", out[want_cols].isna().mean().sort_values(ascending=False))\n",
    "    print(\"Attached label value_counts (binary-ish):\")\n",
    "    for c in [\"emo_approach_high\",\"is_ambiguous\"]:\n",
    "        if c in out.columns:\n",
    "            print(\" \", c, dict(pd.Series(out[c]).value_counts(dropna=False)))\n",
    "\n",
    "    epochs2 = epochs.copy()\n",
    "    epochs2.metadata = out.reset_index(drop=True)\n",
    "    return epochs2, want_cols\n",
    "\n",
    "# =========================\n",
    "# 5) Contrast builder\n",
    "# =========================\n",
    "def build_contrasts(epochs):\n",
    "    cand = [\n",
    "        (\"emo_approach_high\", \"Approach High vs Low\", 1, 0),\n",
    "        (\"is_ambiguous\",      \"Ambiguous vs Non\", True, False),\n",
    "    ]\n",
    "    return [c for c in cand if c[0] in epochs.metadata.columns]\n",
    "\n",
    "# =========================\n",
    "# 6) ROI time series (subject-balanced)\n",
    "# =========================\n",
    "def compute_roi_timeseries_by_subject(epochs, cond_col, hi_val, lo_val, roi_name):\n",
    "    meta = epochs.metadata.copy()\n",
    "    _require_cols(meta, [\"subject_id\", cond_col], \"epochs.metadata\")\n",
    "\n",
    "    subs = np.sort(pd.to_numeric(meta[\"subject_id\"], errors=\"coerce\").dropna().astype(int).unique())\n",
    "    times = epochs.times\n",
    "\n",
    "    picks = [ch for ch in ROI_DEF[roi_name] if ch in epochs.ch_names]\n",
    "    if len(picks) == 0:\n",
    "        raise RuntimeError(f\"ROI '{roi_name}' channels not found. ch_names={epochs.ch_names}\")\n",
    "\n",
    "    ep_roi = epochs.copy().pick_channels(picks)\n",
    "\n",
    "    hi_ts, lo_ts = [], []\n",
    "    for sid in subs:\n",
    "        msub = (pd.to_numeric(meta[\"subject_id\"], errors=\"coerce\").astype(\"Int64\") == sid)\n",
    "        m_hi = msub & (meta[cond_col] == hi_val)\n",
    "        m_lo = msub & (meta[cond_col] == lo_val)\n",
    "\n",
    "        if m_hi.sum() == 0 or m_lo.sum() == 0:\n",
    "            hi_ts.append(np.full(times.shape, np.nan))\n",
    "            lo_ts.append(np.full(times.shape, np.nan))\n",
    "            continue\n",
    "\n",
    "        e_hi = ep_roi[m_hi.to_numpy()].average().data.mean(axis=0)\n",
    "        e_lo = ep_roi[m_lo.to_numpy()].average().data.mean(axis=0)\n",
    "        hi_ts.append(e_hi); lo_ts.append(e_lo)\n",
    "\n",
    "    hi_ts = np.vstack(hi_ts)\n",
    "    lo_ts = np.vstack(lo_ts)\n",
    "    diff_ts = hi_ts - lo_ts\n",
    "    return subs, times, hi_ts, lo_ts, diff_ts\n",
    "\n",
    "# =========================\n",
    "# 7) Permutation table\n",
    "# =========================\n",
    "def make_perm_table(epochs, contrasts):\n",
    "    rows = []\n",
    "    for cond_col, contrast_name, hi_val, lo_val in contrasts:\n",
    "        vc = epochs.metadata[cond_col].value_counts(dropna=False)\n",
    "        print(f\"{cond_col} value_counts:\", dict(vc))\n",
    "        if (epochs.metadata[cond_col] == hi_val).sum() == 0 or (epochs.metadata[cond_col] == lo_val).sum() == 0:\n",
    "            print(f\"[SKIP] {cond_col}: hi/lo not both present.\")\n",
    "            continue\n",
    "\n",
    "        for roi in ROI_DEF.keys():\n",
    "            subs, times, hi_ts, lo_ts, diff_ts = compute_roi_timeseries_by_subject(\n",
    "                epochs, cond_col, hi_val, lo_val, roi\n",
    "            )\n",
    "            t_ms = times * 1000.0\n",
    "\n",
    "            for (a,b) in WINDOWS_MS:\n",
    "                mask = (t_ms >= a) & (t_ms < b)\n",
    "                if mask.sum() == 0:\n",
    "                    continue\n",
    "\n",
    "                d = np.nanmean(diff_ts[:, mask], axis=1)\n",
    "                n_sub = int(np.sum(~np.isnan(d)))\n",
    "                if n_sub < 3:\n",
    "                    continue\n",
    "\n",
    "                t_obs, p_perm = signflip_perm_t(d, n_perm=N_PERM, seed=SEED)\n",
    "                dz = dz_effect(d)\n",
    "\n",
    "                hi_m = np.nanmean(np.nanmean(hi_ts[:, mask], axis=1))\n",
    "                lo_m = np.nanmean(np.nanmean(lo_ts[:, mask], axis=1))\n",
    "                md  = np.nanmean(d)\n",
    "                sd  = np.nanstd(d, ddof=1)\n",
    "\n",
    "                if SCALE_TO_uV:\n",
    "                    hi_m *= 1e6; lo_m *= 1e6; md *= 1e6; sd *= 1e6\n",
    "\n",
    "                rows.append({\n",
    "                    \"cond\": cond_col,\n",
    "                    \"contrast\": contrast_name,\n",
    "                    \"roi\": roi,\n",
    "                    \"window_ms\": f\"{a}-{b}\",\n",
    "                    \"n_subjects\": n_sub,\n",
    "                    \"hi_mean_uV\": hi_m,\n",
    "                    \"lo_mean_uV\": lo_m,\n",
    "                    \"mean_diff_uV\": md,\n",
    "                    \"sd_diff_uV\": sd,\n",
    "                    \"T_obs\": t_obs,\n",
    "                    \"p_perm\": p_perm,\n",
    "                    \"dz\": dz\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if len(df) == 0:\n",
    "        raise RuntimeError(\"Permutation table is empty. ラベル/条件/ROIを確認してください。\")\n",
    "\n",
    "    df[\"p_fdr_within_cond\"] = np.nan\n",
    "    for c in df[\"cond\"].unique():\n",
    "        idx = df[\"cond\"] == c\n",
    "        df.loc[idx, \"p_fdr_within_cond\"] = benjamini_hochberg(df.loc[idx, \"p_perm\"].to_numpy())\n",
    "    df[\"p_fdr_all\"] = benjamini_hochberg(df[\"p_perm\"].to_numpy())\n",
    "    return df\n",
    "\n",
    "# =========================\n",
    "# 8) Plots\n",
    "# =========================\n",
    "def plot_roi_waveform_with_inset(times, hi_ts, lo_ts, title, out_png, sig_bands=None):\n",
    "    t_ms = times * 1000.0\n",
    "    hi_mean = np.nanmean(hi_ts, axis=0)\n",
    "    lo_mean = np.nanmean(lo_ts, axis=0)\n",
    "\n",
    "    def sem(x):\n",
    "        n = np.sum(~np.isnan(x), axis=0)\n",
    "        sd = np.nanstd(x, axis=0, ddof=1)\n",
    "        return sd / np.sqrt(np.maximum(n, 1))\n",
    "\n",
    "    hi_sem = sem(hi_ts)\n",
    "    lo_sem = sem(lo_ts)\n",
    "\n",
    "    ylab = \"Amplitude (µV)\" if SCALE_TO_uV else \"Amplitude (V)\"\n",
    "    if SCALE_TO_uV:\n",
    "        hi_mean *= 1e6; lo_mean *= 1e6\n",
    "        hi_sem  *= 1e6; lo_sem  *= 1e6\n",
    "\n",
    "    fig = plt.figure(figsize=(14,5), dpi=180)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "    ax.plot(t_ms, hi_mean, label=\"High\", linewidth=2.0)\n",
    "    ax.plot(t_ms, lo_mean, label=\"Low\", linewidth=2.0)\n",
    "    ax.fill_between(t_ms, hi_mean-hi_sem, hi_mean+hi_sem, alpha=0.18)\n",
    "    ax.fill_between(t_ms, lo_mean-lo_sem, lo_mean+lo_sem, alpha=0.18)\n",
    "\n",
    "    ax.axvline(0, linewidth=1.2)\n",
    "    ax.axhline(0, linewidth=0.8)\n",
    "    ax.set_xlim([-200, 1000])\n",
    "    ax.set_xlabel(\"Time (ms)\")\n",
    "    ax.set_ylabel(ylab)\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True, alpha=0.25)\n",
    "    ax.legend(loc=\"center right\")\n",
    "\n",
    "    if sig_bands:\n",
    "        for (a,b,label) in sig_bands:\n",
    "            ax.axvspan(a, b, alpha=0.12)\n",
    "            ax.text((a+b)/2, ax.get_ylim()[1]*0.92, label, ha=\"center\", va=\"top\", fontsize=9)\n",
    "\n",
    "    axins = fig.add_axes([0.62, 0.58, 0.33, 0.33])\n",
    "    axins.plot(t_ms, hi_mean, linewidth=1.6)\n",
    "    axins.plot(t_ms, lo_mean, linewidth=1.6)\n",
    "    axins.set_xlim([0, 250])\n",
    "    axins.axvline(0, linewidth=1.0)\n",
    "    axins.axhline(0, linewidth=0.6)\n",
    "    axins.grid(True, alpha=0.25)\n",
    "\n",
    "    if sig_bands:\n",
    "        for (a,b,_) in sig_bands:\n",
    "            if b <= 250:\n",
    "                axins.axvspan(a, b, alpha=0.12)\n",
    "\n",
    "    fig.savefig(out_png, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def topomap_subject_balanced(epochs, cond_col, hi_val, lo_val, win_ms, out_png):\n",
    "    meta = epochs.metadata.copy()\n",
    "    _require_cols(meta, [\"subject_id\", cond_col], \"epochs.metadata\")\n",
    "\n",
    "    epochs2 = ensure_montage(epochs)\n",
    "\n",
    "    subs = np.sort(pd.to_numeric(meta[\"subject_id\"], errors=\"coerce\").dropna().astype(int).unique())\n",
    "    a,b = win_ms\n",
    "    tmin = a/1000.0\n",
    "    tmax = (b - 1e-6)/1000.0\n",
    "\n",
    "    diffs = []\n",
    "    info_ref = None\n",
    "\n",
    "    for sid in subs:\n",
    "        msub = (pd.to_numeric(meta[\"subject_id\"], errors=\"coerce\").astype(\"Int64\") == sid)\n",
    "        m_hi = msub & (meta[cond_col] == hi_val)\n",
    "        m_lo = msub & (meta[cond_col] == lo_val)\n",
    "        if m_hi.sum() == 0 or m_lo.sum() == 0:\n",
    "            continue\n",
    "        e_hi = epochs2[m_hi.to_numpy()].average()\n",
    "        e_lo = epochs2[m_lo.to_numpy()].average()\n",
    "        diffs.append(e_hi.data - e_lo.data)\n",
    "        if info_ref is None:\n",
    "            info_ref = e_hi.info\n",
    "\n",
    "    if len(diffs) < 3:\n",
    "        return\n",
    "\n",
    "    diff_mean = np.mean(np.stack(diffs, axis=0), axis=0)\n",
    "    times = epochs2.times\n",
    "    mask = (times >= tmin) & (times < tmax)\n",
    "    topo = diff_mean[:, mask].mean(axis=1)\n",
    "\n",
    "    if SCALE_TO_uV:\n",
    "        topo *= 1e6\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5,4), dpi=180)\n",
    "    mne.viz.plot_topomap(topo, info_ref, axes=ax, show=False, contours=0)\n",
    "    ax.set_title(f\"{cond_col}: High−Low ({a}-{b} ms)\")\n",
    "    fig.savefig(out_png, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "# =========================\n",
    "# 9) RUN\n",
    "# =========================\n",
    "print(\"EPOCHS:\", EPOCHS_PATH)\n",
    "print(\"MASTER:\", MASTER_PATH)\n",
    "print(\"TRIAL_FEAT:\", TRIAL_FEAT_PATH)\n",
    "print(\"OUT:\", OUT_DIR)\n",
    "\n",
    "# Load epochs (preload必須)\n",
    "epochs = mne.read_epochs(EPOCHS_PATH, preload=True, verbose=\"ERROR\")\n",
    "print(\"Loaded epochs:\", len(epochs))\n",
    "\n",
    "# Align to trial_feat\n",
    "epochs, align_info = align_epochs_to_trial_feat(epochs, TRIAL_FEAT_PATH)\n",
    "print(\"align_info:\", align_info)\n",
    "\n",
    "# Attach labels\n",
    "epochs, attached_cols = attach_labels_from_master_robust(epochs, MASTER_PATH, pc_fallback_map=PC_FALLBACK_MAP)\n",
    "print(\"Attached cols:\", attached_cols)\n",
    "\n",
    "# FIX: EEG19だけにして、名前をFp1等に正規化\n",
    "epochs = normalize_and_pick_eeg19(epochs)\n",
    "print(\"After normalize/pick EEG19 ch_names:\", epochs.ch_names)\n",
    "\n",
    "# Onset ERP preprocessing\n",
    "epochs = ensure_montage(epochs)\n",
    "epochs = epochs.copy().crop(-0.2, 1.0).apply_baseline((-0.2, 0.0))\n",
    "print(\"After crop/baseline:\", epochs.tmin, epochs.tmax, \"n=\", len(epochs))\n",
    "\n",
    "# Contrasts\n",
    "contrasts = build_contrasts(epochs)\n",
    "print(\"Available CONTRASTS:\", [c[0] for c in contrasts])\n",
    "if len(contrasts) == 0:\n",
    "    raise RuntimeError(\"使えるコントラストが0です。\")\n",
    "\n",
    "# Permutation table\n",
    "df = make_perm_table(epochs, contrasts)\n",
    "out_csv = OUT_TAB / \"ERP_onset_under1000ms_perm_ALLCONDS.csv\"\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(\"[SAVED]\", out_csv)\n",
    "\n",
    "# Waveform plots\n",
    "df_early = df[df[\"window_ms\"].isin([f\"{a}-{b}\" for a,b in EARLY_WINDOWS_MS])].copy()\n",
    "\n",
    "for cond_col, contrast_name, hi_val, lo_val in contrasts:\n",
    "    for roi in ROI_DEF.keys():\n",
    "        subs, times, hi_ts, lo_ts, diff_ts = compute_roi_timeseries_by_subject(\n",
    "            epochs, cond_col, hi_val, lo_val, roi\n",
    "        )\n",
    "\n",
    "        sig_bands = []\n",
    "        for (a,b) in EARLY_WINDOWS_MS:\n",
    "            w = f\"{a}-{b}\"\n",
    "            hit = df_early[(df_early[\"cond\"]==cond_col) & (df_early[\"roi\"]==roi) & (df_early[\"window_ms\"]==w)]\n",
    "            if len(hit)==1 and float(hit[\"p_perm\"].iloc[0]) < 0.05:\n",
    "                sig_bands.append((a,b,f\"{w} ms (p<.05)\"))\n",
    "\n",
    "        out_png = OUT_FIG / f\"ERP_{cond_col}_{roi}_highlow_-200_1000ms.png\"\n",
    "        plot_roi_waveform_with_inset(\n",
    "            times, hi_ts, lo_ts,\n",
    "            title=f\"{roi.upper()} ROI ERP: {contrast_name} (−200 to 1000 ms)\",\n",
    "            out_png=out_png,\n",
    "            sig_bands=sig_bands\n",
    "        )\n",
    "        print(\"[SAVED]\", out_png)\n",
    "\n",
    "# Topomaps\n",
    "for cond_col, contrast_name, hi_val, lo_val in contrasts:\n",
    "    for (a,b) in TOPO_WINDOWS_MS:\n",
    "        out_png = OUT_FIG / f\"TopoDiff_{cond_col}_highminuslow_{a}-{b}ms.png\"\n",
    "        topomap_subject_balanced(epochs, cond_col, hi_val, lo_val, (a,b), out_png)\n",
    "        if out_png.exists():\n",
    "            print(\"[SAVED]\", out_png)\n",
    "\n",
    "print(\"\\nDONE.\")\n",
    "print(\"Tables:\", OUT_TAB)\n",
    "print(\"Figs  :\", OUT_FIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf2b4be-5105-41a7-bbe0-f0706b71ba7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
